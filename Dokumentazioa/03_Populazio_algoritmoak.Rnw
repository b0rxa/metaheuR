% !TeX spellcheck = eu_ES
\documentclass[eu]{ifirak}

\usepackage{amsmath,latexsym,amssymb,natbib}
\usepackage{listings}
\usepackage{ifcommands,subfigure}
\usepackage[T1]{fontenc}
\usepackage{tcolorbox}

\newcommand{\zkk}{\guillemotleft}
\newcommand{\skk}{\guillemotright}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\eng}[1]{\textit{#1}}
\newcommand{\hgl}[1]{\zkk #1\skk\ }

\begin{document}
%\SweaveOpts{concordance=TRUE}
\ikasturtea{2014/2015}
\irakasgaia{Bilaketa Heuristikoak}
\title{BHLN: Populazioan oinarritutako algoritmoak}
\date{}
\irakaslea{Borja Calvo, Usue Mori}
\author{Borja Calvo, Usue Mori}


\tel{943 01 50 13}
\mail{borja.calvo@ehu.es}

<<echo=FALSE , purl=FALSE>>=
## This code is for wrapping long outputs
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
knitr::opts_chunk$set(linewidth=100) 
knit_theme$set("earendel")
@


\maketitle

\begin{abstract}
Aurreko kapituluan soluzio bakarrean oinarritzen diren zenbait algoritmo ikusi ditugu. Algoritmo hauek oso portaera ezberdina izan arren, badute ezaugarri komun bat: bilaketa prozesua soluzio batetik bestera mugitzen da, soluzioak banan-banan aztertuz. Ezaugarri hau dela eta, algoritmo hauek oso algoritmo egokiak dira bilaketa espazioaren eskualde interesgarriak arakatzeko --bilaketa areagotzeko, alegia--. Alabaina, hainbat kasutan emaitza onak lortzeko bilaketa dibertsifikatzea ere beharrezkoa da. Hau honela izanik, bilaketa lokalean oinarritzen diren algoritmo batzuk dibertsifikatzeko zenbait estrategia darabilte, adibide nabarmenena tabu bilaketaren epe-luzeko memoria izanik.

Kapitulu honetan soluzioen banan-banakako azterketa alde batera utzita, soluzio multzoak erabiltzeari ekingo diogu, horixe baita, hain justu, populazioetan oinarritzen diren algoritmoen filosofia. Algoritmoaren pausu bakoitzean, soluzio bakar bat izan beharrean, soluzio multzo bat izango dugu. Testuinguru batzuetan soluzio multzo honi \hgl{soluzio-populazioa} deritzo eta, hortik, algoritmo hauen izena. Algoritmo hauekin, bilaketa prozesuan zehar, soluzio multzo hori aldatuz joango da helburu funtzioaren gidaritzapean, gelditze irizpide bat bete arte.

Oro har, populazioan oinarritutako algoritmoak bi multzotan banatu ditzakegu: algoritmo ebolutiboak eta \eng{swarm intelligence}-an oinarritutakoak. Lehenengo kategoriako algoritmoek, populazioa eboluzionarazten dute, teknika ezberdinak erabiliz, honek geroz eta soluzio hobeak izan ditzan. Adibiderik ezagunenak algoritmo genetikoak dira. Bigarren motako algoritmoak, berriz, zenbait animalien portaeran oinarritzen dira. Hauen arteko adibiderik ezagunenak, esate baterako, inurriek, janaria eta inurritegiaren arteko distantziarik motzena topatzeko darabilten mekanismoa imitatzen du.

Kapitulua bi zatitan banaturik dago, bakoitza populazioan oinarritutako algoritmo mota bati eskeinita. Lehenengo zatian, algoritmo ebolutiboen eskema orokorra ikusi ondoren, algoritmo genetikoak \cite{holland1975} eta EDAk \cite{larranaga2002,lozano2006} aurkeztuko dira. Bigarren zatian ordea, \eng{swarm intelligence} \cite{blum2008} arloan proposaturiko bi algoritmo aztertuko dira.
\end{abstract}


\section{Algoritmo Ebolutiboak}\label{sec:ebolutiboak}
1859. urtean Charles R. Darwinek \eng{On the Origin of the Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life} liburua argitaratu zuen. Tituluak berak adierazten duen bezala, liburu honetan Darwinek hautespen naturalaren teoria aurkeztu zuen. 

Eboluzioaren teoriak dioenez, belaunalditik belaunaldira zenbait mekanismoen bidez --mutazioak, esate baterako-- aldaketak ematen dira espezieetan. Aldaketa hauetako batzuei esker indibiduoak hobeto egokitzen dira haien ingurunera eta, ondorioz, bizirik mantentzeko eta, batez ere, ugaltzeko probabilitateak handitzen dira. Era berean, noski, aldaketa batzuk kaltegarriak izan daitezke, bizitzeko aukerak murriztuz. Kontutan hartuz aipatutako aldaketak heredatu egiten direla, ezaugarri onak generazioz generazio mantentzen dira; kaltegarriak direnek, ostera, galtzeko joera izaten dute. Prozesu honen bidez, espezieak haien ingurunera geroz eta hobeto egokitzeko gai dira.

Hirurogeigarren hamarkadan ikertzaileek Darwinen lana inspiraziotzat hartu zuten optimizazio metahuristikoak diseinatzeko eta geroztik, konputazio ebolutiboa konputazio zientzien arlo bereizia bilakatu da. Atal honetan bi algoritmo mota aztertuko ditugu, algoritmo genetiko klasikoak \cite{holland1975} eta EDAk (\eng{Estimation of Distribution Algorithms}) \cite{larranaga2002, lozano2006}.


\begin{figure}[t]
\centering
\includegraphics[height=0.2\textheight]{./Irudiak/AEB}
\caption{Algoritmo ebolutiboen eskema orokorra}
\label{fig:alg.evol}
\end{figure}


Diferentziak diferentzia, algoritmo ebolutibo guztiek \ref{fig:alg.evol} irudiko eskema orokorra jarraitzen dute. Eskema orokor honetan, bi dira giltzarri diren elementuak: soluzio berrien sorkuntza eta soluzioen hautespena. Algoritmoaren sarrera-puntua hasierako populazioa izango da; populazio horretatik abiatuz, algoritmoa begizta nagusian sartzen da, non bi pausu txandakatzen diren. Lehenik, uneko populazioko soluzioetatik abiatuz, soluzio berri multzo bat sortuko da. Ondoren, soluzio berri hauek eta uneko populazioko soluzioak kontutan hartuz, naturan bezala, hurrengo belaunaldiara pasatzeko soluzio onak aukeratuko ditugu, eta populazio berri bat sortuko dugu. Begizta nagusia etengabekoa denez, zenbait irizpide ezberdin proposatu dira algoritmoa amaitutzat emateko.

Hurrengo atalean, algoritmo orokor honen urratsak sakonago aztertuko ditugu. Hasteko, algoritmo ebolutibo guztietan antzerakoak diren pausuak azalduko ditugu eta ondoren, bi algoritmo ezberdinen xehetasunetan jarriko dugu arreta. 

\subsection{Urrats orokorrak}

Ondorengo ataletan ikusiko ditugun algoritmoen arteko diferentzia nagusia soluzio berrien sorkuntzan datza. Gaionontzeko urratsak era antzekoan burutzen dira algoritmo ezberdinetan eta horiei buruz hitz egingo dugu atal honetan.

\subsubsection{Populazioaren hasieraketa}

Nahiz eta askotan garrantzi gutxi eman, hasierako populazioa da algoritmoaren abia-puntua eta, hortaz, bere sorkuntza oso pausu garrantzitsua da, eragin handia izaten duelako algoritmoak lortutako azken emaitzan. 

Algoritmoen xedea soluzio onak topatzea izanda, pentsa dezakegu hasierako populazio on bat soluzio onez osatuta egon behar dela; alabaina, dibertsitatea soluzioen kalitatea bezain garrantzitsua da. Nahiz eta onak izan, populazioa oso soluzio antzerakoez osatuta badago, populazioaren eboluzioa oso zaila izango da eta algoritmoak azkarregi konbergitu dezake optimoa ez den soluzio batera. 

Hortaz, hasierako populazioa sortzean bi aspektu izan behar ditugu kontutan: kalitatea eta dibertsitatea. Kasu gehienetan ausazko hasieraketa erabiltzen da lehen populazioa sortzeko, hau da, ausazko soluzioak sortzen dira populazioa osatu arte. Estrategia hau erabiliz dibertsitate handiko populazioa sortuko dugu, baina kalitatea ez da handia izango. 

Ausazko laginketak lortutakoa baina dibertsitate handiagoa bermatu nahi badugu, --sasiausazko-- prozedura batzuk erabil ditzakegu. Hori dela eta, proposatu dira beste prozedura batzuk populazioak sasi-ausaz sortzeko dibertsitatea maximizatuz. Esate baterako, dibertsifikazio sekuentziala aplikatu dezakegu, zeinak soluzio berri bat onartzen duen soilik populazioan dauden soluzioekiko distantzia minimo batera badago. Adibide moduan, demagun 25 tamainako bektore bitarren 10 tamainako populazio bat sortu nahi dugula. Dibertsitatea bermatzeko populazioko soluzioen arteko Hamming distantzia minimoak 10-ekoa izan behar duela inposa dezakegu. 

Jarraian dagoen kodeak horrelako populazioak sortzen ditu. Lehenik, Hamming distantzia neurtzeko eta ausazko bektore bitarrak sortzeko funtzioak sortzen ditugu:

<<ham_dis , prompt=TRUE, echo=-1 , message=FALSE , cache=TRUE>>=
set.seed(1)
hammDistance <- function (v1, v2) {
  d <- sum(v1 != v2)
  return(d)
}

createRndBinary <- function(n) {
  return (runif(n) > 0.5)
}
@

 Gero, soluzioak ausaz sortzen ditugu eta, distantzia minimoko baldintza bete ezean, deusestatu egiten ditugu; prozedura nahi ditugun soluzio kopurua lortu arte exekutatzen da. 

<<seq_divers , prompt=TRUE, message=FALSE, cache=TRUE>>=
sol.size <- 25
pop.size <- 10
min.distance <- 10
population <- list(createRndBinary(sol.size))
while (length(population) < pop.size) {
  new.sol <- createRndBinary(sol.size)
  distances <- lapply(population, 
                      FUN=function(x) {
                        return(hammDistance (x, new.sol))
                      })  
  if (min(unlist(distances)) <= min.distance) {
    population[[length(population) + 1]] <- new.sol
  }
}
@


Prozedura hau ez da batere eraginkorra, zenbait kasutan soluzio asko aztertu beharko baititugu populazioa osatu arte. Hala, beste alternatiba eraginkorrago bat dibertsifikazio paraleloa da. Kasu honetan bilaketa espazioa zatitu egiten da eta azpi-espazio bakoitzetik ausazko soluzio bat erauzten da.

Orain arte dibertsitateari bakarrik erreparatu diogu. Aldiz, hasierako popuazioaren kalitatea hobetu nahi izanez gero, hasieraketa heuristikoak erabil daitezke. Hau lortzeko era sinple bat, GRASP algoritmoetan ausazko soluzioak sortzeko erabiltzen diren prozedurak erabiltzea da. Ondoko lerroetan Bavierako hirien TSP problemarako adibide bat ikus dezakegu. Lehenik, problema kargatuko dugu.

<<heur_init_1 , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE, cache=TRUE>>=
library("metaheuR")
url <- system.file("bays29.xml.zip", package="metaheuR")
cost.matrix <- tsplibParser(url)
@

Orain, \code{tspGreedy} funtzioan oinarrituta, ausazko soluzio onak sortzeko funtzio bat definitzen dugu.

<<heur_init_2 , prompt=TRUE, message=FALSE, cache=TRUE>>=
createRndSolution <- function(cl.size=5) {
  tspGreedy(cmatrix=cost.matrix, cl.size=cl.size)
}
@

Aurreko kapituluetan azaldu bezala, \code{tspGreedy} funtzioak TSP-rako algoritmo eraikitzaile bat inplementatzen du; pausu bakoitzean, uneko hiritik zein hirira mugituko garen erabakitzen da, gertuen dauden \code{cl.size} hirietatik --5, gure kasuan-- bat ausaz aukeratuz. Honetan oinarrituz, populazioa sortzeko funtzio hau erabiliko dugu.

<<heur_init_3 , prompt=TRUE, message=FALSE, cache=TRUE>>=
pop.size <- 25
population <- lapply(1:pop.size, 
                     FUN=function(x) {
                       return(createRndSolution())
                     })
@

Hautagaien zerrendaren tamainari (\code{cl.size}) problemaren tamainaren balioa ezartzen badiogu, pausu bakoitzean, aukera guztietatik bat ausaz hartuko dugu, hots, guztiz ausazkoak diren soluzioak sortuko ditugu. Azken aukera honekin, populazioaren kalitatea goiko kodearekin lortutakoa baino okerragoa izango da:

<<heur_init_4 , prompt=TRUE, message=FALSE, cache=TRUE>>=
rnd.population <- lapply (1:pop.size, 
                          FUN=function(x) {
                            return(createRndSolution(cl.size=ncol(cost.matrix)))
                          })
tsp <- tspProblem(cost.matrix)
eval.heur <- unlist(lapply(population, FUN=tsp$evaluate))
eval.rnd <- unlist(lapply(rnd.population, FUN=tsp$evaluate))
@


Bi populazioen ebaluazioak \eng{boxplot} baten bidez aldera ditzakegu:

<<plot_heur_vs_rnd, echo = -1, cache=TRUE , warning=FALSE, prompt=TRUE , cache=TRUE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=8 , fig.height=4>>=
library("ggplot2")
df <- rbind(data.frame(Method="Heuristic", Evaluation=eval.heur),
            data.frame(Method="Random", Evaluation=eval.rnd))
ggplot(df, aes(x=Method, y=Evaluation)) + geom_boxplot()
@

\begin{figure}[t]
\centering
\includegraphics[height=0.33\textheight]{./Irudiak/plot_heur_vs_rnd-1}
\caption{Ausazko hasieraketa eta hasieraketa heuristikoaren arteko konparaketa. Y ardatzak metodo bakoitzarekin sortutako soluzioen \eng{fitness}-a adierazten du.}\label{fig:heur_vs_rnd_init_pop}
\end{figure}

\ref{fig:heur_vs_rnd_init_pop} irudiak lortutako emaitzak erakusten ditu. Helburua minimizazioa dela kontutan hartuz, argi eta garbi ikus daiteke heuristikoa erabiliz sortutako soluzioak hobeak direla.

Soluzioak sortzeko metodoak ez ezik, populazioaren tamainak ere badu eragin handia azken emaitzan, eta  egokitu beharreko oso parametro garrantzitsua da. Algoritmoak darabiltzan populazioak txikiegiak badira, dibertsitatea mantentzea oso zaila izango da eta, hortaz, belaunaldi gutxitan algoritmoak konbergitu egingo du, ziurrenik optimoa ez den soluzio batera. Beste aldetik, populazioak handiegiak badira, konbergentzia abiadura motelagoa izango da baina, ondorioz, kostu konputazionala ere handiagoa bilakatuko da; hurrengo atalean adibide baten bidez ikusiko dugu hau. Honenbestez, ez dago irizpide finkorik populazioen tamaina ezartzeko eta problema bakoitzerako balio egoki bat bilatu beharko da. Edonola ere, irizpide orokor gisa esan dezakegu populazioak azkar konbergitzen badu --hots, soluzioen arteko distantzia azkar txikitzen bada--, soluzio hobeak lortzeko modua populazioaren tamaina handitzea izan daitekeela. 


\subsubsection{Hautespena}

Algoritmo ebolutibotan populazioko soluzio batzuen aukeraketa urrats garrantzitsua da, populazioaren eboluzioa kontrolatzen duen prozesua baita. Orokorrean, populazioan dauden soluziorik onenak hautatzea da gehien erabiltzen den hautespen irizpidea: hautespen \zkk elitista\skk\. Alabaina, soluzio onak aukeratzea garrantzitsua bada ere, dibertsitatea mantentzearren, tarteka soluzio txarrak sartzea ere komenigarria izaten da. Hau zuzenean egin daiteke, baina badaude aukeraketa metodo egokiago batzuk soluzio txarrak estrategia probabilistikoak erabiliz aukeratzen dituztenak.

Erruleta-hautespena,  (\textit{Roulette Wheel selection}, ingelesez) deritzon estrategian soluzioak erruleta batean kokatzen dira; soluzio bakoitzari, bere ebaluazioarekiko proportzionala den, erruletaren zati bat esleituko zaio. Hau honela, \ref{fig:roulette} irudian ikus daitekeen bezala, erruleta jaurtitzen den bakoitzean indibiduo bat hautatzen da. Hautatua izateko probabilitatea erruleta zatiaren tamaina eta, hortaz, indibiduoen ebaluazioarekiko proportzionala da. Indibiduo bat baino gehiago aukeratu behar baldin badugu, behar adina erruleta jaurtiketa egin ditzakegu. 

Azkenik, esan beharra dago, \eng{fitness}aren magnitudea problema eta, batez ere, instantzien araberakoa dela. Hori dela eta, erruleta banatzeko probabilitateak zuzenean helburu funtzioaren balioak erabiliz kalkulatzen badira, oso distribuzio erradikalak izan ditzakegu. Arazo hau ekiditeko, helburu funtzioaren balioa zuzenean erabili beharrean soluzioen ranking-a erabiltzea posible da.

\begin{figure}[t]
\centering
\includegraphics[width=0.7\linewidth]{./Irudiak/roulette}
\caption{Erruleta-hautespena. Indibiduo bakoitzaren erruletaren zatia bere ebaluazioarekiko proportzionala da. Erruleta jaurtitzen den bakoitzean indibiduo bat aukeratzen da, bere \eng{fitness}arekiko proportzionala den probabilitatearekin. Adibidean, 2. indibiduoa da hautatu dena.}
\label{fig:roulette}
\end{figure}

Beste hautespen probabilistiko mota bat Lehiaketa-hautespena da. Estrategia honekin soluzioen aukeraketa bi pausutan egiten da. Lehenengo urratsean indibiduo guztietatik azpi-multzo bat aukeratzen da, guztiz ausaz (ebaluazioa kontutan hartu barik). Ondoren, azpi-multzo honetatik soluziorik onena hautatzen dugu. Azpi-multzoen eraketa guztiz ausaz egiten denez, hauetako batzuk, oso soluzio txarrez osatuta egon daitezke. Kasu hauetan, nahiz eta onena aukeratu, populazio berrirako gordeko dugun soluzioa ez da ona izango eta, honenbestez, soluzio on eta txarren aukeraketa baimentzen du hautespen metodo honek. 

\subsubsection{Gelditze Irizpideak}

Lehen apiatu bezala, algoritmo ebolutiboen begizta nagusia amaigabea da eta, beraz, gelditzeko irizpideren bat ezarri behar dugu, bilaketak amaiera izan dezan. Hurbilketarik sinpleena irizpide estatikoak erabiltzea da, hala nola, denbora maximoa ezartzea, ebaluazioak mugatzea, etab.

Bestalde, gelditzeko irizpide dinamikoak, hau da, eboluzioaren prozesuari erreparatzen diotenak ere erabili daitezke. Balunaldiz belaunaldi populazioan dauden soluzioak geroz eta hobeak dira eta, aldi berean, populazioaren dibertsitatea murrizten da, soluzio batera konbergitzeko joerarekin. Hau hala izanik, populazioaren dibertsitatea gelditze irizpide dinamikoak eraikitzeko erabil daiteke.

Dibertsitatea soluzioei zein beraien \eng{fitness}-ari erreparatuz neur daiteke. Esate baterako, soluzioen arteko distatzia neurtzerik badago, indibiduoen arteko bataz besteko distantzia minimo bat ezar dezakegu gelditze irizpide gisa.

\subsubsection{Algoritmo Genetikoak}

Atal honetan algoritmo genetikoetan \cite{holland1975} soluzio berriak nola sortzen diren ikusiko dugu. Algoritmo genetikoak naturan espezieen eboluzioarekin gertatzen dena imitatzen dute eta, beraz, fenomeno honekin zenbait paralelismo ezar daitezke:

\begin{itemize}
\item Espezie bateko indibiduoak = Problemaren soluzioak
\item Indibiduoen egokitasuna --\eng{fitness}-a, alegia-- = Soluzioaren ebaluazioa
\item Espeziearen populazioa = Soluzio multzoa/populazioa
\item Ugalketa = Soluzio berrien sorkuntza
\end{itemize}

Beraz, algoritmo genetikoetan soluzio berriak sortzeko estrategiak diseinatzean indibiduen ugalketa prozesuan oinarrituko gara.  Ugalketa prozesuaren xedea zenbait indibiduo emanda --bi, normalean--, indibiduo berriak sortzea da. Ohikoena prozesu hau bi pausutan banatzea da: soluzioen gurutzaketa eta mutazioa. Lehenaren helburua \hgl{guraso}-soluzioek dituzten ezaugarriak soluzio berriei pasatzea da, espezieen gurutzaketan jazotzen den bezala. Bigarrenarena, berriz, sortutako soluzio berriei ezaugarri berriak eranstea da. Jarraian soluzioak maneiatzeko bi operadore hauek aztertuko ditugu.

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\linewidth]{./Irudiak/point_crossover}
\caption{Gurutzatze-operadoreak bektoreen bidezko kodeketarekin erabiltzeko}
\label{fig:point_crossover}
\end{figure}

\subsubsection{Gurutzaketa} 

Bi soluzio --edo gehiago-- gurutzatzen ditugunean euren propietateak sortutako soluzio berriei transmititzea da helburua. Optimizazio arloan, soluzioen arteko gurutzaketak \hgl{gurutzaketa-operadore}-en --\eng{crossover}, ingelesez-- bidez egiten dira. Operadore hauek soluzioen kodeketarekin dihardute eta, beraz, gurutzatze operadore zehatz bat hautatzean soluzioak nola adieratzen ditugun aintzat hartu beharko dugu. 

Badaude kodeketa klasikoekin erabil daitezkeen zenbait oinarrizko gurutzaketa operadore. Ezagunena puntu bakarreko gurutzaketa -- \eng{one-point crossover}, ingelesez -- deritzona da. Demagun soluzioak bektoreen bidez kodetzen ditugula. Bi soluzio, $s_1$ eta $s_2$ hartuz, operadore honek beste bi soluzio berri sortzen ditu. Horretarako, lehenik eta behin, ausazko posizio bat, $i$, aukeratu behar da. Hau egin ahala, lehenengo soluzio berria $s_1$ soluziotik lehenengo $i$ elementuak eta $s_2$ soluziotik gainontzekoak ($i+1$-tik aurrerakoak) kopiatuz sortuko dugu. Era berean, bigarren soluzio berria $s_2$-tik lehenengo $i$ elementuak eta $s_1$-etik $i+1$ posiziotik aurrerako elementuak kopiatuz sortuko dugu.  \ref{fig:point_crossover} irudiaren ezkerraldean \eng{one-point crossover} operazioaren aplikazioaren adibide bat ikus daiteke. Gainera, eskuineko irudiak operadore hau nola orokortu daitekeen erakusten du, puntu bakar bat erabili beharrean bi, hiru, etab. puntu erabiliz. 

Azken operadore orokorrago honi, \eng{k-point crossover} deritzo eta \code{metaheuR} liburutegiko \code{kPointCrossover} funtzioan inplementaturik dago. Ikus ditzagun bere erabileraren adibide batzuk:

<<k_point_cross , prompt=TRUE, echo=-1 , message=FALSE, cache=TRUE>>=
set.seed(666)
A.sol <- rep("A", 10)
B.sol <- rep("B", 10)
A.sol
B.sol
kPointCrossover(A.sol, B.sol, 1)
kPointCrossover(A.sol, B.sol, 5)
kPointCrossover(A.sol, B.sol, 20)
@

Azken adibidean ikus daitekeen bezala, $n$ tamainako bektore bat izanik, gehienez $n-1$ puntuko gurutzaketa aplikatu dezakegu; edonola ere, balio handiago bat aukeratzen badugu funtzioak abisu bat emango du eta puntu kopuruaren parametroa bere balio maximoan ezarriko du. Balio maximoa aukeratuz gero, jatorrizko \hgl{guraso} soluzioen elementuak tartekatuta agertuko dira soluzio berrietan; operadore honi \eng{uniform crossover} deritzo.

Erabiliko dugun puntu kopuruak eragin handia izan dezake algoritmoaren performantzian eta, hortaz, egokitu beharreko algoritmoaren parametroa da. 

\eng{k-point crossover} operadorea nahiko orokorra da, ia edozen bektoreari aplikatu ahal baitzaio. Hala eta guztiz ere, kodeketa batzuetan beste operadore espezifikoagoak erabiltzea egokiagoa izan daiteke\cite{gwiazda2006}. Esate baterako, soluzioak bektore errealen bidez kodetuta badaude, bi soluzio era ezberdin askotan konbina daitezke; adibidez, bataz bestekoa kalkulatuz. Ikus dezagun operadore hau nola inplementa daitekeen R-n:

<<mean_cross , prompt=TRUE, message=FALSE, cache=TRUE>>=
meanCrossover <- function(sol1, sol2) {
  new.solution <- (sol1 + sol2) / 2
  return(new.solution)
}

s1 <- runif(10)
s2 <- runif(10)
s1
s2
meanCrossover(s1, s2)
@

Permutazioak ere bektoreak dira baina, bete beharreko murrizketak direla eta, \eng{k-point crossover} operadorea ezin da erabili kodeketa mota honekin.  Ikus dezagun hau argiago ikusten lagunduko digun adibide bat. Izan bitez bi permutazio, $s_1 = 12345678$ eta $s_2=87654321$, eta gurutzatze puntu bat, $i=3$. Lehenengo soluzio berria lortzeko $s_1$ soluziotik lehendabiziko hiru posizioak kopiatuko ditugu, hau da, $123$, eta besteak $s_2$-tik, hots, $54321$. Hortaz, lortutako soluzioa $s^\prime = 12354321$ izango zen baina, zoritxarrez, hau ez da permutazio bat. Hortaz, permutazioak gurutatzeko operadore bereziak behar ditugu. 

Aukera asko izan arren \cite{talbi2009}, hemen puntu bakarreko gurutzatze operadorearen baliokidea ikusiko dugu. Puntu bateko gurutzaketan bezala, hasteko, puntu bat aukeratuko dugu ausaz, $i$. Ondoren, lehenengo soluzio berria sortzeko, \hgl{guraso} soluzio baten lehenengo $i$ posizioetako balioak zuzenean kopiatuko ditugu; gainontzeko balioak zuzenean beste \hgl{guraso} soluziotik kopiatu beharrean, ordena bakarrik hartuko dugu kontutan. Hau da, aurreko adibidera itzuliz, soluzio berria sortzeko $s_1$-etik lehenengo 3 elementuak zuzenean kopiatuko ditugu, $123$, eta falta direnak, $45678$, $s_2$-an agertzen diren ordenean kopiatuko ditugu, hots, $87654$. Emaitza, beraz, $s^\prime = 12387654$ izango da eta, kasu honetan bai, permutazio bat. Era berean, bigarren soluzio berri bat sor daiteke $s_2$-tik lehenengo hiru posizioak kopiatuz ($876$) eta gainontzekoak $s_1$-n agertzen diren ordenean kopiatuz ($12345$); beste soluzioa, beraz, $87612345$ izango da. Operadore honi \hgl{Order crossover} deritzo eta \code{metaheuR} liburutegian \code{orderCrossover} funtzioan \footnote{Funtzio honetan inplementatuta dagoena \eng{2-point crossover} operadorea da. Hau da, bi puntu erabiltzen dira eta, soluzioak eraikitzeko, bi puntuen artean dagoen soluzio zatia soluzio batetik zuzenean kopiatu ondoren, gainontzeko elementuak beste \hgl{guraso} soluzioan agertzen diren ordenean ezartzen dira.}.
 inplementaturik dago. 

<<order_cross , prompt=TRUE, message=FALSE , echo=-1 , warning=FALSE, cache=TRUE>>=
set.seed(5)
sol1 <- randomPermutation(10)
sol2 <- identityPermutation(10)
as.numeric(sol1)
as.numeric(sol2)
new.solutions <- orderCrossover(sol1, sol2)
as.numeric(new.solutions[[1]])
as.numeric(new.solutions[[2]])
@


\subsubsection{Mutazioa} 

Naturan bezala, gure populazioak eboluzionatu ahal izateko dibertsitatea garrantzitsua da. Hori dela eta, behin gurutzatze-operadorearen bidez soluzio berriak lortuta, hauetan ausazko aldaketak eragin ohi dira mutazio operadorearen bidez. 

Mutazioaren kontzeptua ILS algoritmoko perturbazioaren antzerakoa da eta kasu horretan bezalaxe, operadore ezberdinak erabil daitezke mutazioa burutzeko. Hala nola, ILS-an bezala, algoritmoa diseinatzean erabaki behar dugu zenbateko aldaketak eragingo ditugun soluzioetan. Esate baterako, permutazio bat mutatzeko ausazko trukaketak erabil ditzakegu baina zenbat posizio trukatuko ditugun aldez aurretik erabaki beharko dugu.

Mutazio operadorea era probabilistikoan aplikatzen da; hau da, ez zaie soluzio guztiei aplikatzen. Hortaz, mutazioari lotutako bi parametro izango ditugu: mutazio probabilitatea eta mutazioaren magnitudea.

Mutazio operadorea aukeratzean --eta baita diseinatzean ere-- hainbat gauza hartu behar dira kontuan. Hasteko, soluzioen bideragarritasuna mantentzea garrantzitsua da, hau da, mutazio operadorea bideragarria den soluzio bati aplikatuz gero, emaitzak soluzio bideragarria izan behar du. Bestalde, bilaketa prozesuak soluzio bideragarrien espazio osoa arakatzeko gaitasuna izan behar du eta, hori bermatzeko, mutazio operadoreak edozein soluzio sortzeko gai izan behar du. Hau da, edozein soluzio hartuta, mutazio operadorearen bidez beste edozein soluzio sortzea posible izan behar du. Amaitzeko, lokaltasuna ere mantendu behar da --hau da, mutazioak eragindako aldaketa txikia izan behar da--, gurasoengandik heredatutako ezaugarriak galdu ez daitezen.


\begin{ifalgorithm}[t]
\begin{ifpseudo}{Algoritmo Genetikoak}
\item \In\ \texttt{evaluate}, \texttt{select\_reproduction}, \texttt{select\_replacement}, \texttt{cross}, \texttt{mutate} eta \texttt{!stop\_criterion} operadoreak
\item \In\ \texttt{init\_pop} hasierako populazioa
\item \In\ \texttt{mut\_prob} mutazio probabilitatea
\item \Out\ \texttt{best\_sol}
\item \texttt{pop=init\_pop}
\item \While \texttt{stop\_criterion} \Do
\item \T{\texttt{evaluate(pop)}}
\item \T{\texttt{ind\_rep = select\_reproduction(pop)}}
\item \T{\texttt{new\_ind = reproduce(ind\_rep)}}
\item \T{\textbf{for} \textbf{each} \texttt{n} in \texttt{new\_ind} \Do}
\item \TT{\texttt{mut\_prob} probabilitatearekin egin \texttt{mutate(n)}}
\item \T{\Done}
\item \T{\texttt{evaluate(new\_ind)}}
\item \T{\If \texttt{new\_ind} multzoan \texttt{best\_ind} baino hobea den soluziorik badago}
\item \TT{Eguneratu \texttt{best\_sol}}
\item \T{\EIf}
\item \T{\texttt{pop=select\_replacement(pop,new\_ind)}}
\item \Done
\end{ifpseudo}
\caption{Algoritmo genetikoen sasikodea}\label{alg:algoritmo_genetikoak}
\end{ifalgorithm}

Honenbestez, algoritmo genetiko orokorra \ref{alg:algoritmo_genetikoak} irudian ikus daiteke eta sasikode hay \code{metaheuR} paketeko \code{basicGeneticAlgorithm} funtzioan inplementaturik dago. Ikus dezagun funtzio honen erabilpenaren adibide bat \eng{graph coloring} problemaren instantzia bat ebazteko. Lehenik, ausazko grafo bat sortuko dugu problemaren instantzia sortzeko.

<<ga_graph_col_1 , prompt=TRUE, message=FALSE , echo=-2 , warning=FALSE, cache=TRUE>>=
library(igraph)
set.seed(5)
n <- 50
rnd.graph <- aging.ba.game(n=n, pa.exp=2, aging.exp=0, m=3, directed=FALSE)
gcp <- graphColoringProblem(graph=rnd.graph)
@

Orain zenbait elementu definitu behar ditugu. Lehenengoa, hasierako populazioa izango da eta, sortu ahal izateko, lehenik, bere tamaina ezarri behar dugu. Hau algoritmoaren parametro garrantzitsu bat denez, bi balio ezberdinekin probatuko dugu, emaitzak alderatzeko: $n$ eta $10n$. Behin hasierako populazioaren tamaina definituta bertako soluzioak ausaz sortuko ditugu eta, bideragarriak ez badira, zuzenduko egingo ditugu \code{gcp} objektuaren \code{correct} funtzioa erabiliz.

<<ga_graph_col_2 , prompt=TRUE, message=FALSE , warning=FALSE, cache=TRUE>>=
n.pop.small <- n
n.pop.big <- 10 * n
levels <- paste("C", 1:n, sep="")
createRndSolution <- function(x) {
  sol <- factor(paste("C", sample(1:n, size=n, replace=TRUE), 
                      sep=""), levels=levels)
  return(gcp$correct(sol))
}
pop.small <- lapply(1:n.pop.small, FUN=createRndSolution)
pop.big   <- lapply(1:n.pop.big, FUN=createRndSolution)
@

Hasierako populazioaz gain, ondoko parametro hauek ezarri behar ditugu:

\begin{itemize}
\item Hautespen operadoreak - Hurrengo belaunaldira zuzenean pasatuko diren soluzioak aukeratzeko hautespen elitista erabiliko dugu, populazio erdia aukeratuz; zein soluzio gurutzatuko diren aukeratzeko, berriz, lehiaketa hautespena erabiliko dugu.
\item Mutazioa - Soluzioak mutatzeko \code{factorMutation} funtzioa erabiliko dugu. Funtzio honek zenbait posizio ausaz aukeratzen ditu eta bertako balioak ausaz aldatzen ditu. Funtzioak parametro bat du, \code{ratio}, aldatuko diren posizioen ratioa adierazten duena. Gure kasuan 0.1 balioa erabiliko dugu, alegia, posizioen \%10-a aldatuko da mutazioa aplikatzen denean. Soluzioak zein probabilitatearekin mutatuko ditugun soluzioak ere aurrez finkatu behar da, \code{mutation.rate} parametroaren bidez. Gure kasuan, probabilitatea bat zati populazioaren tamaina izango da.
\item Gurutzaketa - Soluzioak gurutzatzeko \eng{k-point crossover} operadorea erabiliko dugu, $k = 2$ finkatuz. 
\item Beste parametro batzuk - Algoritmo genetikoaren parametroaz gain, beste bi parametro finkatuko ditugu, \code{non.valid = 'discard'}, bideraezina diren soluzioak baztertu behar direla adierazteko, eta \code{resources}, gelditze irizpidea finkatzeko ($5n^2$ ebaluazio kopuru maximoa erabiliko dugu).
\end{itemize}

\begin{figure}[t]
\subfigure[Algoritmo genetikoaren progresioa]{
\includegraphics[width=0.65\textwidth] {./Irudiak/ga_graph_col_3-1}
}\qquad
\subfigure[Lortutako soluzioa]{
\includegraphics[width=0.30\textwidth] {./Irudiak/ga_graph_col_4-1}
}\\
\caption{Definitutako algoritmo genetikoaren progresioa \eng{graph coloring} problemaren instantzia batean batean, bi populazio tamaina ezberdin erabiliz. Ezkerrean, tamaina handiko populazioarekin lortutako soluzioa ikus daiteke.}\label{fig:ga_progress}
\end{figure}

Jarraian parametro hauek erabiliz algoritmo genetikoa exekutatzeko kodea ikus dezakegu.


<<ga_graph_col_3, prompt=TRUE, cache=TRUE, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
args <- list()
args$evaluate             <- gcp$evaluate
args$initial.population   <- pop.small
args$selectSubpopulation  <- elitistSelection
args$selection.ratio      <- 0.5
args$selectCross          <- tournamentSelection
args$mutate               <- factorMutation
args$ratio                <- 0.1
args$mutation.rate        <- 1 / length(args$initial.population)
args$cross                <- kPointCrossover
args$k                    <- 2
args$non.valid            <- "discard"
args$resources            <- cResource(evaluations=5 * n^2)

bga.small <- do.call(basicGeneticAlgorithm, args)

args$initial.population   <- pop.big
args$mutation.rate        <- 1 / length(args$initial.population)

bga.big <- do.call(basicGeneticAlgorithm, args)

plotProgress(list("Big population"=bga.big, "Small population"=bga.small), size=1.1) + 
  labs(y="Average fitness") + aes(linetype=Group)
@


<<ga_graph_col_4, prompt=TRUE, cache=TRUE , echo = FALSE , message=FALSE , warning=FALSE  , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=5 , fig.height=5>>=
best.big <- unlist(getSolution(bga.big)[[1]])
gcp$plot(best.big, node.size=15, label.cex=0.75)
@


\ref{fig:ga_progress} irudian bi populazio tamaina ezberdin erabiliz bilaketaren progresioa ikus daiteke. Populazioa txikia denean algoritmoak oso azkar konbergitzen du 19 kolore darabiltzan soluzio batera. Populazioko soluzio gehienak oso antzerakoak direnean soluzio berriak sortzeko bide bakarra mutazioa da, baina prozesu hori oso motela denez, grafikan ikus daiteke soluzioen bataz besteko \eng{fitness}a ez dela aldatzen. 

Populazioaren tamaina handitzen dugunean konbergentzia zailagoa da eta grafikan ikus daiteke helburu funtzioaren balioaren eboluzioa motelagoa izan arren, lortutako soluzioa hobea dela.

\begin{figure}[t]
\centering
\includegraphics[width=0.75\textwidth] {./Irudiak/ga_mut_rate-1}
\caption{Mutazio probabilitatearen eragina algoritmo genetikoaren azken emaitzan. Irudian ikus daitekeen bezala, soluziorik onena ematen duen mutazio probabilitatearen balioa 0.5 inguruan dago (zehazki, 0.6). }\label{fig:ga_mutrate}
\end{figure}

Populazioaren tamaina ez ezik, beste hainbat parametrok ere eragin handia izan dezakete algoritmoaren emaitzan; esate baterako, mutazioaren probabilitatea. Adibide gisa, populazio tamaina txikia erabiliz mutazio probabilitate ezberdinak probatuko ditugu, eta, bakoitzarekin lortutako emaitzak alderatuko ditugu.

<<ga_mut_rate, prompt=TRUE, cache=TRUE, echo=-1, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
set.seed(10)
args$initial.population   <- pop.small
args$verbose              <- FALSE
args$resources            <- cResource(evaluations=n^2)

testMutProb <- function (rate) {
  args$mutation.rate <- rate
  res <- do.call(basicGeneticAlgorithm, args)
  return(getEvaluation(res))
}

ratios <- seq(0,1,0.2)
evaluations <- sapply(ratios , FUN = testMutProb)

df <- data.frame("Mutation_rate"=ratios, "Fitness"=evaluations)
ggplot(df, aes(x=Mutation_rate, y=Fitness)) + geom_line() + geom_point(size=5) + 
  labs(x="Mutation rate")
@


\ref{fig:ga_mutrate} irudian lortutako emaitzak ikus daitezke. Grafikoak agerian uzten du mutazio probabilitate txikiegiak zein handiegiak ezartzea kaltegarria dela bilaketa prozesuarenzat, probabilitate egokiena 0.5 ingurukoa izanik. Jokabide honen zergatia bilatzen badugu, konturatzen gara probabilitate txikien kasuan emaitzak txarrak direla, populazioaren dibertsitatea txikia delako eta, ondorioz, konbergentzia goiztiarra ematen delako. Probabilitate handiekin berriz, arazoa justo kontrakoa izan daiteke, alegia, bilaketa ia ausazkoa dela eta beraz konbergentzia oso zaila dela. Hau egiaztatzeko, goiko experimentua errepika dezakezu ebaluazio kopuru maximoa handituz.

\subsection{Estimation of Distribution Algorithms}

Algoritmo genetikoetan uneko populazioa indibiduo berriak sortzeko erabiltzen da, naturan inspiratutako gurutzatze eta mutazio operadoreak aplikatuz.  Prozesu honen bitartez, populazioan dauden ezaugarriak mantentzea espero dugu. 

Zenbait ikertzailek ideia hau hartu eta ikuspuntu matematikotik birformulatu zuten. Honela, gurutzatze eta mutazioa erabili beharrean, eredu probabilistikoak erabiltzea proposatu zuten, populazioaren \hgl{esentzia} jasotzeko helburuarekin. Hauxe da, EDA -- \eng{Estimation of Distribution Algorithms} -- algoritmoen ideia nagusia. 

Algoritmo genetikoen eta EDA motako algoritmoen artean dagoen diferentzia bakarra indibiduo berriak sortzeko erabiltzen den estrategia da. Gurutzaketa eta mutazioa erabili beharrean, uneko populazioa eredu probabilistiko bat doitzeko erabiltzen da. Ondoren, eredu hori laginduko dugu behar adina indibiduo sortzeko.

EDA algoritmoen gakoa, beraz, eredu probabilistikoa da. Ildo honetan, esan beharra dago eredua soluzioen kodeketari lotuta dagoela, soluzio adierazpide bakoitzari probabilitate bat esleitu beharko diolako. 

Konplexutasun ezberdineko eredu probabilistikoen erabilera proposatu da literaturan, baina badago hurbilketa sinple bat oso hedatua dagoena: UMDA -- \eng{Univariate Marginal Distribution Algorithm} --. Kasu honetan soluzioaren osagaiak -- bektore bat bada, bere posizioak -- independenteak direla suposatuko dugu eta, hortaz, osagai bakoitzari dagokion probabilitate marjinala estimatuko dugu. Gero, indibiduoak sortzean soluzioaren osagaiak banan-banan aukeratuko ditugu probabilitate hauek jarraituz. 

Probabilitate marjinalak maneiatzeko \code{metaheuR} paketeko \code{UnivariateMarginals} objektua erabil dezakegu. Bere erabilera ikusteko, populazio txiki bat sortuko dugu eta probabilitate marginalak kalkulatuko ditugu. 

<<UMDA_1, cache=TRUE , echo=-1 , prompt=TRUE, message=FALSE , warning=FALSE>>=
set.seed(1)
population <- lapply(1:5, 
                     FUN=function(x) {
                       res <- factor(sample(1:3, 10, replace=TRUE), levels=1:3) 
                       return(res)
                     })
@

Orain, \code{univariateMarginals} funtzioa erabiliz probabilitate marginalak kalkulatuko ditugu:

<<UMDA_2, cache=TRUE, prompt=TRUE, message=FALSE , warning=FALSE>>=
model <- univariateMarginals(data=population)
do.call(rbind, population)
model@prob.table
@

Sortutako soluzioek 10 elementu dituzte (10 posizioko bektore kategorikoak dira) eta populazioak 5 soluzio ditu. Lehenengo elementu edo posizioari erreparatzen badiogu, 5 soluzioetatik lehenengo biak 1 balioa dute, laugarrenak 2 balioa eta beste biak 3 balioa. Hortaz, elementu horretarako, 1 eta 3 balioen probabilitatea 0.4 izango da --$\frac{2}{5}$, alegia-- eta 2 balioaren probabilitatea 0.2 izango da, marginaleen taulan ikus daitekeen bezala.

Ikasitako eredu probabilistikoa soluzio berriak sortzeko erabil daiteke, posizioz-posizio dagokion marginala laginduz; laginketa \code{simulate} funtzioaren bidez egiten da.

<<UMDA_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
simulate(model, nsim=2)
@

UMDA \code{basicEda} funtzioaren bidez exekutatu dezakegu eta, segidan, aurreko ataleko problema ebazteko erabiliko dugu. Horretarako, bakarrik hautespen operadoreak eta ereduak ikasteko funtzioak zehaztu behar ditugu --algoritmo genetikoekin komunak diren parametroez gain--.

<<umda_gc, echo = -1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
set.seed(2)
args <- list()
args$evaluate             <- gcp$evaluate
args$initial.population   <- pop.small
args$selectSubpopulation  <- elitistSelection
args$selection.ratio      <- 0.5
args$learn                <- univariateMarginals
args$non.valid            <- "discard"
args$resources            <- cResource(evaluations = n^2)

umda <- do.call(basicEda, args)

plotProgress(umda, size=1.1) + 
  geom_line(aes(y=Current_sol + Current_sd), col="gray40", linetype=2) +
  geom_line(aes(y=Current_sol - Current_sd), col="gray40", linetype=2) + 
  labs(y="Average fitness")
@

\begin{figure}[t]
\centering
\includegraphics[width=0.75\textwidth] {./Irudiak/umda_gc-1}
\caption{UMDA algoritmoaren progresioa \eng{graph coloring} problemaren istantzia batean aplikatuta. Marra jarraituak populazioko soluzioen bataz-besteko \eng{fitness}a adierazten du; marra etenek, berriz, desbiderazio estandarra adierazten dute. Ikus daiteke populazioak konbergitzen duen heinean soluzioen \eng{fitness}aren aldakortasuna murrizten dela.}\label{fig:umda}
\end{figure}

Bilaketaren progresioa \ref{fig:umda} irudian erakusten da. Marra etenek populazioan dauden soluzioen \eng{fitness}aren desbiderapena erakusten dute eta marra jarraikiak, ordea, populazioko soluzioen fitness-aren batez-bestekoa. Populazioak eboluzionatu ahala, populazioaren dibertsitatea murrizten dela ikus dezakegu desbiderapenaren murrizketan erreparatuz. Amaieran, bilaketak 11 kolore darabiltzan soluzio batera konbergitzen du.

Marjinalak kalkulatzeko estrategia ia edozein bektore motarekin erabil daitezke zuzenean; alabaina, balio errealak baditugu, marjinalak zein probabilitate distribuzioarekin modelatuko ditugun erabaki beharko dugu aurrez. Aukera ezberdin asko daude baina ohiko distribuzio bat distribuzio normala da. Gainera, soluzioek murrizketak dituztenean, permutazioetan kasu, gauzak konplikatu egiten dira. 

Permutazio multzo bat izanik, posible da marjinalak bektore kategorikoekin bezala estimatzea baina, ondoren, eredua lagintzen dugunean ez ditugu halabeharrez permutazioak lortuko, balio errepikatuak ager baitaitezke. Hona hemen adibide bat:

<<UMDA_permu_1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
n <- 5
generateRndPopulation <- lapply(1:50, 
                   FUN=function(x) {
                     res <- factor(as.numeric(randomPermutation(n)), levels=1:n) 
                     return(res)
                   })
perm.umda <- univariateMarginals(generateRndPopulation)
simulate(perm.umda)
@

Arazo hau sahiesteko, soluzio berriak lagintzean, permutazioak dakarzten murrizketak aintzat hartu behar dira. Honela, laginketa prozesuan lehenengo elementua ausaz aukeratuko dugu, zuzenean marjinala erabiliz. 

<<UMDA_permu_2, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=-1>>=
set.seed(10)
marginals <- perm.umda@prob.table
remaining <- 1:n
probabilities <- marginals[,1]
new.element <- sample(remaining, size=1, prob=probabilities)
new.solution <- new.element
@

Ondoren, bigarren elementua aukeratu aurretik, lehenengo posiziorako aukeratu dugun elementua kendu beharko dugu aukera posibleetatik eta marjinalak honen arabera eguneratu--erabili dugun elementuaren probabilitatea kendu eta normalizatu, gelditzen diren elementuen probabilitateen batura 1 izan dadin--:

<<UMDA_permu_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id, ]
probabilities <- marginals[, 2]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining, size=1, prob=probabilities)
new.solution <- c(new.solution, new.element)
@

Estrategia berbera aplikatzen dugu 3. eta 4. elementuak erauzteko.

<<UMDA_permu_4, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id, ]
probabilities <- marginals[, 3]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining, size=1, prob=probabilities)
new.solution <- c(new.solution, new.element)

id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id, ]
probabilities <- marginals[, 3]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining, size=1, prob=probabilities)
new.solution <- c(new.solution, new.element)
@

Amaitzeko, permutazioaren azken elementua definitzeko, soberan geratzen den  elementua aukeratuko dugu zuzenean.

<<UMDA_permu_5, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
new.solution <- c(new.solution, remaining)
new.solution
@

Prozesu honekin probabilitate marjinalak erabil daitezke permutazioak sortzeko baina arazo bat dauka: eredua lagintzen dugun bakoitzean probabilitateak aldatzen ditugu eta, hortaz, lagintzen duguna ez da zehazki populaziotik ikasi dugun eredua. Beste era batean esanda, populaziotik ateratako \hgl{esentzia} galdu dezakegu. Hau ez gertatzeko, permutazio espazioetan definitutako probabilitate distribuzioak erabil ditzakegu; esate baterako, Mallows eredua, \code{metaheuR} paketean dagoen \code{MallowsModel} objektuak inplementatzen duena.


\section{Swarm Intelligence}\label{sec:swarm}

Eboluzioaren bidez naturak indibiduen diseinuak \hgl{optimizatzeko} gai da; alabaina, hau ez da naturak erabiltzen duen estrategia bakarra. Optimizazio algoritmoak inspiratu dituen beste adibidea bat animalia sozialena da. Zenbait espezietan --intsektuak, batik bat-- banan-banan hartuta, indibiduoak oso izaki sinpleak dira baina, multzoka, ataza konplexuak burutzeko gai dira. Esate baterako, inurriek eta erleek elikagai-iturri onenak aukeratzeko gai dira eta, hauek agortzen direnean, ingurunea esploratzen duten indibiduen kopurua handi dezakete iturri berriak lortzeko; era berean, bizitzeko toki berriak bilatzean toki egokienak aukeratzeko gai dira.

Erabaki guzti horiek ez dira era zentralizatuan hartzen --alegia, ez dago agintzen duen \hgl{nagusi}\negthickspace{}rik --. Portaera hauek indibiduoen arau sinplei eta, batez ere, indibiduoen arteko komunikazioari esker agertzen dira. Beste era batean esanda, mekanismo sinplei esker kolonia batean dauden indibiduoak autoantolatzeko gai dira.

Portaera hauek dira \eng{swarm intelligence} deritzon arloaren inspirazioa. Kontzpetua lehenengo aldiz 1988. urtean robotika arloan proposatu zen \cite{beni1988}, baina laister optimizazio mundura hedatu zen. Izan ere, 90. hamarkadan inurri kolonien optimizazioa --\eng{Ant Colony Optimization}, ingelesez-- proposatu zen \cite{dorigo1992, dorigo1996}.

Hurrengo bi ataletan arlo honetan dauden bi algoritmo ezagunenak aztertuko ditugu, inurri kolonien optimizazioa eta \eng{particle swarm optimization}.



\subsection{\eng{Ant Colony Optimization}}

Inurriek, janaria topatzen dutenean, beraien koloniatik janarira biderik motzena topatzeko gaitasuna dute. Inurri bakar batek ezin du horrelakorik egin baina, taldeka, komunikazio mekanismo sinpleei esker ataza burutzeko gai dira. Erabiltzen den komunikabidea zeharkakoa da, darien molekula mota berezi bati esker: feromonak. 

Inurriek mugitzen direnean beste inurriek jarrai dezaketen feromona-lorratz bat uzten dute; geroz eta feromona gehiago, orduan eta probabilitate handiagoa datozen inurriak utzitako lorratza jarraitzeko. 

\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{./Irudiak/ants}
\caption{Feromonaren erabilera. Hasierako egoeran biderik motzena feromonaren bidez markatuta dago. Bidea mozten dugunean, inurriek, eskumara edo ezkerrera joango dira, probabilitate berdinarekin, feromonarik ez baitago ez ezkerrean ez eskuinean. Eskumako bidea luzeagoa da eta, ondorioz, ezkerreko bidearekiko inurri-fluxua txikiagoa da. Denbora igaro ahala, eskumako lorratza ahulduko da; ezkerrekoa, berriz, indartuko da. Honek inurrien erabakia baldintzatuko du, ezkerretik joateko joera handiago sortuz eta, ondorioz, bi bideen arteko diferentziak handituz. Denbora nahiko igarotzen denean eskumako lorratza guztiz galduko da eta inurriak bide motzetik bakarrik joango dira.}
\label{fig:ants}
\end{figure}


Bestaldetik, inurri batek elikagai-iturri bat topatzen duenean, bidetik uzten duen feromona kopurua iturriaren kalitateari egokitzen du; geroz eta kalitate handiagoa, orduan eta feromona gehiago. Horrez gain, feromona lurrunkorra da, alegia, denborarekin baporatu egiten da.

Arau sinple hauek erabiliz inurriek elikagai-iturri onenak aukeratzeko gai dira; are gehiago, elikagai eta inurritegiaren arteko biderik motzena topa dezakete. Mekanismoaren funtzionamendua \ref{fig:ants} irudian ikus daiteke. Hasieran bide motzena feromona lorratzaren bidez markatuta dute inurriek. Bidea mozten badugu, eskuman eta ezkerrean ez dago feromonarik eta, hortaz, inurri batzuk eskumatik eta beste batzuk ezkerretik joango dira, probabilitate berdinarekin. Ezkerreko bidea motzagoa denez, denbora berdinean inurri gehiago igaroko dira, ezkerreko bidean feromona gehiago utziz. Ondorioz, datozen inurriak ezkerretik joateko joera handiago izango dute, bide hori indartuz. Eskumako bidean lorratza apurka-apurka baporatuko da eta, denbora nahiko igarotzen bada, zeharo galduko da. 

Laburbilduz, inurriek ez dituzte bi bideak konparatzen baina, ala eta guztiz ere, bide motza bakarrik erabiltzea lortzen dute. \eng{Ant Colony Optimization} (ACO) deritzon metaheuristika inurrien mekanismoa hartzen du intuiziotzat. Bere ingurunetik pasiatu beharrean, inurri artifizialak soluzio \hgl{sortzaileak} dira. Beraz, inurri artifizialek soluzioak sortuko dituzte, baina ez edonolakoak; soluzioak aurreko inurriek utzitako lorratzak jarraituz eraikitzen dira. 

Lorratzak feromona ereduen bidez adierazten dira eta bi eratan eguneratzen dira. Alde batetik, inurriek sortutako soluzioen kalitatea --hots, helburu funtzioaren balioa-- feromona gehitzeko erabiltzen da. Bestaldetik, iterazioz iterazio feromona kopuruak txikituko ditugu, molekularen baporazioa simulatuz.

Beraz, bi gauza behar dira ACO algoritmo bat diseinatzeko: feromona eredu bat eta soluzioak sortzeko algoritmo bat. Diseinu sinpleena osagaietan oinarritzen den algoritmo eraikitzaile bat erabiltzea da. Ikus dezagun hau adibide baten bidez.

Demagun MIS problema ebatzi nahi dugula. Problema honetarako soluzioak bektore bitarren bidez kodetzen ditugu eta, hortaz, bektorearen posizioak soluzioen osagaitzat har ditzakegu. Posizio bakoitzen bi balio posible daude, 0 edo 1. Inurri batek soluzio bat sortu behar duenenan, lehenik, bektorearen lehenengo posizioko balioa, 0 edo 1, aukeratu beharko du. Horretarako, feromona kopurua hartuko du aintzat, probabilitate handiago esleituz feromona gehiago duen balioari; behin lehenengo posizioko balioa finkaturik, bigarren posiziora pasatuko da eta, era berean, balio bat probabilistikoki esleituko dio. Prozesua soluzio osoa sortu arte errepikatuko da.

Beraz, gure adibidean feromona eredua matrize sinple baten bidez inplementa daiteke non zutabe bakoitzean bektorearen posizio bat izango dugun; matrizeak bi errenkada bakarrik izango ditu, posizio bakoitzeko 0 eta 1 balioek duten feromona kopurua gordetzeko. Feromona eredu mota hau \code{metaheuR} paketean inplementaturik dago, \code{VectorPheromone} klasean. Ereduaren erabilera argitzeko MIS problema erabili beharrean antzerakoa den beste problema bat azalduko dugu: \eng{Minimum Dominating Set} (MDS). Laburki, grafo bat emanda, nodoen azpimultzo bat menderatze-multzoa da --\eng{dominating set}, ingelesez-- baldin eta azpimulzoan ez dauden nodo guztiak, gutxienez, azpimultzoko nodo bati konektatuta badaude; MDS problema, grafo bat emanik, kardinalitate minimoko menderatze-multzoa topatzean datza. \ref{fig:MDS} irudian problema honetarako hiru soluzio ikus daitezke. Lehenik, ausazko grafo bat erakiko dugu MDS problemaren instantzia bat definitzeko.


\begin{figure}[t]
\subfigure[Soluzio hau bideraezina da, menderatze-multzoa ez baita]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_not}
}\qquad
\subfigure[4 tamainako menderatze-multzoa]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_4}
}\qquad
\subfigure[2 tamainako menderatze-multzoa]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_2}
}\\
\caption{Irudiak MDS problemarako 3 soluzio jasotzen ditu --beltzez adierazita dauden nodoak--. Lehenengoa (ezkerrean dagoena), ez da bideragarria, soluzioan ez dagoen nodo bat soluzioan dauden nodoei konektaturik ez baitago. Bigarren soluzioa bideragarria da, baina ez optimoa. Azken soluzioa optimoa da, ez baitago 1 tamainako soluzio bideragarririk.}\label{fig:MDS}
\end{figure}


<<ACO_MDS_1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=-1>>=
set.seed(666)
n <- 10
rnd.graph <- aging.ba.game (n, 0.5, 0, 2, directed=FALSE)
mdsp <- mdsProblem(graph=rnd.graph)
@

Feromona eredua eraikitzeko matrizea hasieratu behar dugu. Ohikoena balio finko batekin hasieratzea da. Era honetan osagai guztiak balio berdina dute eta, beraz, guztien probabilitatea berdina izango da. Gogoratu gure adibidean matrizeak bi errenkada izan behar dituela, soluzioak bektore bitarrak baitira.

<<ACO_MDS_2, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
init.trail <- matrix (rep(1, 2*n), ncol=n)
evaporation <- 0.1
pheromones <- vectorPheromone(binary=TRUE, initial.trail=init.trail,
                              evaporation.factor=evaporation)
pheromones@trail
@

Goiko kodean ikus daitekeen bezala, badago beste parametro bat finkatu behar dena, \code{evaporation.fractor}. Parametro horretan pasatzen den balioa lurrunketa faseetan erabiltzen da, matrizean dauden balio guztiak txikiagotzeko; baporazioa \code{evaporate} funtzioa erabiliz egiten da.

<<ACO_MDS_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
evaporate(pheromones)
pheromones@trail
evaporate(pheromones)
pheromones@trail
@

Esan dugun bezala, inurriek feromona ereduak soluzioak eraikitzeko erabiltzen dute. Soluzioak \code{buildSolution} funtzioaren bitartez egiten da.

<<ACO_MDS_4, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
buildSolution(pheromones, 1)
@

Inurriek ingurunetik ibiltzen diren heinean feromona uzten dute eta, era berean, inurri artifizialek soluzioak eraikitzen dutenean feromona kopurua handitzen dute; ereduaren eguneraketa hau \code{updateTrail} funtzioa erabiliz egiten da.

<<ACO_MDS_5, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
solution <- buildSolution(pheromones, 1)[[1]]
eval <- mdsp$evaluate(solution)
eval
updateTrail(object=pheromones, solution=solution, value=eval)
pheromones@trail
@

Ikus daitekeen bezala, zutabe bakoitzean errenkada bati soluzioaren helburu funtzioaren balioa gehitu zaio, hori baita inurriek utzitako lorratza. Elementu guzti hauek batzen baditugu, ACO sinple bat sor dezakegu. Lehenik, problema berri bat --handiagoa-- sortuko dugu.

<<ACO_MDS_6, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo = -1>>=
set.seed(1)
n <- 100
rnd.graph <- aging.ba.game(n, 0.5, 0, 3, directed=FALSE)
mdsp <- mdsProblem(graph=rnd.graph)
init.trail <- matrix (rep(1, 2*n), ncol=n)
pheromones <- vectorPheromone(binary=TRUE, initial.trail=init.trail,
                              evaporation.factor=evaporation)
@

Orain, 500 inurri simulatuko ditugu; bakoitzak soluzio bat sortuko du eta \hgl{bidetik} feromona utziko du. Inurri bakoitza simulatu ondoren feromona \hgl{lurrundu} egiten dugu.

<<ACO_MDS_7, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
num.ant <- 500
sol.evaluations <- vector()
for (ant in 1:num.ant) {
  solution <- mdsp$correct(buildSolution(pheromones, 1)[[1]])
  eval <- mdsp$evaluate(solution)
  updateTrail(pheromones, solution, eval)
  evaporate(pheromones)
  sol.evaluations <- c(sol.evaluations, eval)
}
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_MDS_8-1}
\caption{ACO sinplearen eboluzioa MDS problema batean.}\label{fig:simple_aco}
\end{figure}

<<ACO_MDS_8, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
plot(sol.evaluations, type="l", 
     xlab="Number of Artificial Ants", ylab="Solution evaluation")
@

\ref{fig:simple_aco} irudiak algoritmoaren eboluzioa erakusten du. Irudian, hasieran sortutako soluzioen helburu funtzioaren balioek oso bariabilidade handia daukatela ikus daiteke. Alabaina, inurri kopurua handitzen den heinean bariabilidadea murrizten da eta, amaieran, prozedura soluzio bakar batera konbergitzen du. Edonola ere, soluzio hori ez da hasierakoak baino hobea. Kontua da, nahiz eta naturan horrela izan, optimizazioaren ikuspegitik inurri guztiek feromona eredua eguneratzea ez dela hurbilketarik onena; algoritmoa hobetzeko hautespen prozesu bat sartzea komenigarria da.

Ikusi dugun algoritmo sinpleak ez du ondo funtzionatzen, inurri guztiek feromona eguneratzen dutelako. Hori dela eta, beste estrategia erabili ohi da. Inurriak banan-banan simulatu ordez, inurri-kolonia tamaina bat definitzen da eta, iterazio bakoitzean, inurritegiko inurri guztiek soluzio bat sortzen dute. Gero, bi estrategia ezberdin erabil daitezke:

\begin{itemize}
\item Iterazioko soluziorik onena erabili - Inurriek uneko iterazioan sortutako soluzioen artean onena aukeratzen da eta soluzio hori bakarrik erabiltzen da feromona eredua eguneratzeko. Kasu honetan helburu funtzioaren arabera egitea ez da beharrezkoa, bakarrik soluziorik onena erabiltzen baita eguneraketan. Hori dela eta, ohikoa da balio finko bat erabiltzea, helburu funtzioaren ordez.
\item Bilaketan topatutako soluziorik onena - Hainbat kasutan bilaketa areagotzea interesatuko zaigu. Kasu horietan, feromonaren eguneraketa bilaketan zehar topatu den soluziorik onena erabiliz egin daiteke. Aurreko puntuan bezala, eguneraketak ez dauka zergatik izan helburu funtzioaren balioarekiko proportzionala.
\end{itemize}


\begin{ifalgorithm}[t]
\begin{ifpseudo}{Inurri-kolonien algoritmoa}
\item \In\ \texttt{build\_solution}, \texttt{evaporate}, \texttt{add\_pheromone }, \texttt{initalize\_matrix} eta \texttt{stop\_criterion} operadoreak
\item \In\ \texttt{k\_size} koloniaren tamaina
\item \Out\ \texttt{opt\_solution}
\item \texttt{pheromone\_matrix} = \texttt{initialize\_matrix()}
\item \While !\texttt{stop\_criterion()}
\item \T{\textbf{for} \texttt{i} \textbf{in} 1:\texttt{k\_size}}
\item \TT{\texttt{solution} = \texttt{build\_solution(pheromone\_matrix)}}
\item \TT{\texttt{pheromone\_matrix} = \texttt{add\_pheromone(pheromone\_matrix,solution)}}
\item \TT{\If \texttt{solution} \texttt{opt\_solution} baino hobea da}
\item \TTT{\texttt{opt\_solution}=\texttt{solution}}
\item \TT{\EIf}
\item \T{\Done}
\item \T{\texttt{pheromone\_matrix} = \texttt{evaporate(pheromone\_matrix)}}
\item \Done
\end{ifpseudo}
\caption{Inurri-kolonien algoritmoaren sasikodea}\label{alg:ant}
\end{ifalgorithm}


Aldaketa honekin oinarrizko ACO algoritmoaren sasikodea defini dezakegu (ikusi \ref{alg:ant} algoritmoa). \code{basicAco} funtzioak Oinarrizko ACO-a inplementatzen du eta, hortaz, lehen sortutako MDS problema ebazteko erabil dezakegu. Ohiko parametroaz gain, \code{basicAco} argumentu hauek zehaztu behar dira.

\begin{itemize}
\item \code{nants} - Zenbat inurri artifizial izango ditugu gure kolonian
\item \code{pheromones} - Feromona eredua.
\item \code{update.sol} - Nola eguneratuko dugu feromona eredua. Hiru aukera daude: \code{'best.it'}, iterazio bakoitzean sortutako soluziorik onena; \code{'best.all'}, bilaketan zehar lortutako soluziorik onena edo \code{'all'}, sortutako soluzio guztiak.
\item \code{update.value} - Balio bat finkatzen bada, eguneraketa guztietan balio hori gehitzen da; \code{NULL} bada, helburu funtzioa erabiltzen da. Kontutan hartu problema batzuetan helburu funtzioak negatiboak direla, baina feromona eredu batzuetan balio positiboak eta negatiboak ezin dira nahastu, bestela arazoak egon daitezke probabilitateak kalkulatzean. Hori dela eta, helburu funtzioaren zeinua kontutan hartu behar da feromona eredua hasieratzeko.
\end{itemize}

<<ACO_MDS_10, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(17)
args <- list()
args$evaluate         <- mdsp$evaluate
args$nants            <- 5

init.value    <- 1
initial.trail <- matrix(rep(init.value, 2*n), nrow=2)
evapor        <- 0.1
pher          <- vectorPheromone(binary=TRUE, initial.trail=initial.trail,
                                 evaporation.factor=evapor)
args$pheromones   <- pher
args$update.sol   <- "best.it"
args$update.value <- init.value / 10
args$non.valid    <- "correct"
args$valid        <- mdsp$is.valid
args$correct      <- mdsp$correct

args$resources    <- cResource(iterations=100)
args$verbose      <- FALSE

results.aco <- do.call(basicAco, args)
plotProgress(results.aco) + labs(y="Average evaluation")
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_MDS_10-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa MDS problema batean.}\label{fig:basic_aco}
\end{figure}

\ref{fig:basic_aco} irudiak oinarrizko ACO algoritmoaren progresioa irudikatzen du. Algoritmo honek, lehen inplementatu dugun ACO sinpleak aztertzen duen soluzio kopuru berdina sortzen du baina, aurrekoa ez bezala, iterazioz iterazio soluzioa hobetuz doa. Grafikoan batazbesteko \eng{fitness}-ak bariabilidade handia duela ikus daiteke. Hau oso kolonia txikia erabili dugulako da --5 inurri bakarrik--. Balio hori handitzen badugu, prograsioa ez da hain zaratatsua izango --eta, ziurrenik, emaitzak hobeak izango dira--, baina ebaluazio gehiago beharko ditugu.

ACO algoritmoen mamia soluzio eraikuntza da eta, hortaz, soluzioen osagaien definizioa oso garrantzitsua da; osagaiek problemaren natura kontutan hartzen ez badute, feromona ereduak ez du soluzioen informazioa behar den bezala jasoko. Hau agerian gelditzen da jarraian dagoen adibidean.

Demagun LOP problema bat ebazteko ACO algoritmo bat erabili nahi dugula. Problema honetarako soluzioak permutazioen bidez kodetzen ditugunez, adierazpide honekin diharduen feromona eredu bat behar dugu. Bektoreekin erabilitako eredua bera erabil dezakegu, soluzioen eraikuntzan permutazioak sortzeko behar diren aldaketak egiten baditugu betiere. Hau da, matrize karratu bat gordeko dugu non posizio bakoitzeko, balio bakoitzari dagokion feromona kopurua gordeko dugu. Gero, soluzioak osatzerakoan, urrats bakoitzean aukeraturik gabe dauden balioetatik bat aukertuko dugu, aukera guztien arteko feromona kopurua kontutan hartuz. Eredu honek UMDA-n ikusi genuen oso matrize antzerakoa erabiltzen du. 

Dena dela, hau ez da aukera bakarra. TSP probleman ikusi genuen permutazioek grafo osoko ziklo Hamiltoniarrak adierazten dituztela. Hau da, $n$ nodoko grafo oso bat badugu, edozein permutazio $n$ nodoak behin eta bakarrik behi bisitatzen dituen ibilbide bat adierazten du. Beraz, permutazioak osatzeko nodoak lotzen dituzten ertzak erabil ditzakegu.

Ideia hau erabiliz beste feromona eredu bat plantea dezakegu. Eredu honek ere matrize karratu bat erabiliko du, baina matrizearen interpretazioa --eta, hortaz, soluzio osaketa-- ezbedina da. Kasu honetan, matrizeak grafoaren ertzak adierazten ditu, alegia, $(i,j)$ posizioan $i$ nodotik $j$ nodora joateari dagokion feromona kopurua izango dugu. Adibidez, 3421 permutazioa badugu, soluzio honi dagozkion matrizeko posizioak $(3,4); (4,2)$ eta $(2,1)$ dira --problemaren arabera, $(1,3)$ posizioa ere erabiltzea interesgarria izan daiteke, baina guk ez dugu aintzat hartuko gure adibidean--.

Bi eredu hauek \code{metaheuR} librutegian inplementaturik daude, \code{PermuPosPheromone} eta  \code{PermuLinkPheromone} objektuetan. Jarraian, bi eredu hauek LOP problema bat ebazteko erabiliko ditugu eta emaitzak alderatuko ditugu.

<<ACO_LOP, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(1)
n <- 100
rnd.mat <- matrix(round(runif(n^2)*100), n)
lop     <- lopProblem(matrix=rnd.mat)

args <- list()
args$evaluate <- lop$evaluate
args$nants    <- 15

init.value    <- 1
initial.trail <- matrix(rep(init.value, n^2 ), n)
evapor        <- 0.9
pher          <- permuLinkPheromone(initial.trail=initial.trail,
                                    evaporation.factor=evapor)
args$pheromones   <- pher
args$update.sol   <- "best.it"
args$update.value <- init.value / 10
args$resources    <- cResource(iterations=250)
args$verbose      <- FALSE

aco.links <- do.call(basicAco, args)

args$pheromones <- permuPosPheromone(initial.trail, evapor)
aco.pos <- do.call(basicAco, args)

plotProgress(list("Position"=aco.pos, "Link"=aco.links))
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_LOP-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa LOP problema batean.}\label{fig:aco_lop}
\end{figure}

\ref{fig:aco_lop} irudiak experimentuaren emaitza erakusten du. Grafikan argi ikus daiteke noden arteko lotruak osagaitzat hartzen direnean, bilaketak ez du aurrera egiten. Osagaiak posizioak direnean, berriz, iterazioz iterazio soluzioa hobetzen da. Honen arrazoia sinplea da: LOP probleman posizio absolutuak dira garrantzitsuena, eta ez zein elementu dagoen zeinen ondoan.

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_TSP-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa TSP problema batean.}\label{fig:aco_tsp}
\end{figure}

TSP problematan, berriz, ertzetan oinarrintzen den ereduak ondo adieraztzen du problemaren informazioa, alegia, zein hiritik zein hirira joan behar dugun. Jarrain experimentu hori egingo dugu; emaitzak \ref{fig:aco_tsp} irudian daude.


<<ACO_TSP, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(1)
url <- system.file("bays29.xml.zip", package="metaheuR")
cost.matrix <- tsplibParser(url)
n <- ncol(cost.matrix)
tsp <- tspProblem(cmatrix=cost.matrix)

args <- list()
args$evaluate <- tsp$evaluate
args$nants    <- 15

init.value    <- 1
initial.trail <- matrix(rep(init.value, n^2 ), n)
evapor        <- 0.9
pher          <- permuLinkPheromone(initial.trail=initial.trail,
                                    evaporation.factor=evapor)
args$pheromones   <- pher
args$update.sol   <- "best.it"
args$update.value <- init.value / 10
args$resources    <- cResource(iterations=250)
args$verbose      <- FALSE

aco.links <- do.call(basicAco, args)

args$pheromones <- permuPosPheromone(initial.trail, evapor)
aco.pos <- do.call(basicAco, args)

plotProgress (list("Position"=aco.pos, "Link"=aco.links))
@

Ikus daitekeen bezala, TSP-aren kasuan bi ereduak problemaren informazioa gordetzeko gai dira eta, hortaz, bilaketak bi kasuetan aurrera egiten du.

Orain arte ikusi ditugun adibide guztietan feromonak bakarrik erabiltzen dira soluzioak eraikitzerakoan. Oinarrizko algoritmoan horrela izan arren, problema konkretu bat ebatzi behar denean, posible bada, informazio heuristikoa ere sartu ohi da. Adibide gisa, TSPrako algoritmo eraikitzaile tipikoan hurrengo hiria hautatzeko hirien arteko distantzia erabiltzen da. Beraz, goiko adibidean hiri batetik bestera joateari dagokion feromona kopurua soilik erabili beharrean, osagaien probabilitiatea kalkulatzerakoan hirien arteko distantzia ere kontutan har dezakegu.


\subsection{Particle Swarm Optimization}

Intsektu sozialen portaera \textit{swarm} adimenaren adibide tipikoa da, baina ez da bakarra; animali handiagotan ere inspirazioa bila daiteke. Esate baterako, txori-saldotan ehunaka indibiduo batera mugitzen dira beraien arteak talka egin gabe. Multzo horietan ez dago indibiduo bat taldea kontrolatzen duena; txori bakoitzak bere inguruneko txorien portaera aztertzen du, berea egokitzeko. Era horretan, arau sinple batzuk\footnote{txori batetik gertuegi banago, urrundu egiten naiz, adibidez} besterik ez dira behar sistema osoa antolatzeko.

\begin{figure}[t]
\centering
\includegraphics[width=0.6\linewidth]{./Irudiak/PSO_1}
\caption{PSO algoritmoak erabiltzen dituen partikulen adibidea. Partikula bakoitzak bere kokapena $(x_i,y_i)$ eta bere abiadura ($\mathbf{v}_i$) du}\label{fig:PSO}
\end{figure}


Animali talde hauen portaera inspiraziotzat hartuz, 1995ean Kennedy eta Eberhart \textit{Particle Swarm Optimization} (PSO) algoritmoa proposatu zuten \cite{kennedy1995}, optimizazio numerikoko problemak ebazteko\footnote{Hau da, atal honetan ikusiko dugun algoritmoak bektore errealekin dihardu. Edonola ere, problema konbinatorialak ebazteko PSO bertsioak ere aurki daitezke.}. Algoritmoaren ideia sinplea da oso; bilaketa espaziotik mugitzen diren partikulak erabiltzen dira bilaketa gauzatzeko. Beraz, algoritmoaren izenak adierazten duen legez, hainbat partikula izango ditugu, partikula bakoitzaren posizioak problemarako soluzio bat adierazten duena. 

Uneoro partikula bakoitzak kokapen eta abiadura zehatz bat izango du, \ref{fig:PSO} irudian erakusten den bezala. Irudiko adibidean bilaketa espazioak bi aldagai besterik ez ditu ($X$ eta $Y$), eta sisteman 5 partikula daude, $P_1$-etik $P_5$-era.

PSO algoritmoan partikulek bilaketa espazioa aztertzen dute, posizio batetik bestera mugituz. Beraz, iterazio bakoitzean partikula guztien kokapena eguneratzen da, beraien abiadura erabiliz. Partikulen abiadurak finko mantentzen baditugu, partikula guztiak infinitura joango dira. Hori ez gertatzeko, iterazio bakoitzean abiadura ere eguneratu behar da; eguneraketa honetan datza, hain zuzen, algoritmoaren gakoa. 

Lehen aipatu bezala, algoritmoaren inspirazioa txori-maldoen portaera da. Txori bakoitzak nora mugitu behar den erabakitzeko bere ingurunean dauden txoriei erreparetzen die. Era berean, algoritmoan partikula baten abiadura eguneratzean partikula horrek duen informazioa ez ezik, inguruneko partikulek duten informazioa ere erabiltzen da. Hain zuzen, $i$. partikularen abiadura eguneratzeko ondoko ekuazioa erabiltzen da:

\begin{align*}
\mathbf{v}_i(t) = \mathbf{v}_i(t-1) +  C_1 \mathbf{\rho}_1 [\mathbf{p}_i - \mathbf{x}_i(t-1)] + C_2 \mathbf{\rho}_2 [\mathbf{p}_g - \mathbf{x}_i(t-1)]
\end{align*}

Ekuazio honetan hiru termino daude:

\begin{itemize}
\item $\mathbf{v}_i(t-1)$ - Partikulak aurreko iterazioan zeukan abiadura; termino honek partikularen inertzia adirazten du.
\item $C_1 {\mathbf \rho_1} [\mathbf{p}_i - \mathbf{x}_i(t-1)]$ - Termino honetan $\mathbf{p}_i$-k partikulak bilaketa prozesuan topatu duen soluziorik onena adierazten du --ingelesez \eng{personal best} deritzona--. Termino honek eguneraketaren alderdi \hgl{kognitiboa}adierazten du, hots, partikulak berak jasotako informazioa. $C_1$ konstantea terminoaren eragina definitzeko erabiltzen da eta $\mathbf{\rho}_1$ soluzioaren tamainako ausazko bektore bat da.
\item $C_2 \mathbf{\rho}_2 [\mathbf{p}_g - \mathbf{x}_i(t-1)]$ - Termino honetan $\mathbf{p}_g$-k partikuluaren inguruan dauden partikulek bilaketa prozesuan topatu duten soluziorik onena adierazten du --ingelesez \eng{global best} deritzona--. Termino honekeguneraketaren alderdi \hgl{soziala} adierazten du, hots, beste partikulek jasotako informazioa. $C_2$ konstantea terminoaren eragina definitzeko erabiltzen da eta $\mathbf{\rho}_2$ soluzioaren tamainako ausazko bektore bat da.
\end{itemize}


Ekuazioaren azken terminoak partikulen arteko elkarekintzak simulatzen ditu. Horretarako, partikuelen ingurune-egitura definitu behar da. Alabaina, ingurune kontzeptua ez da bilaketa lokalean erabiltzen den berdina, partikula bakoitzaren ingurunea aurrez aurretik ezarritakoa baita; ez du partikularen kokapenarekin zerikusirik, alegia. Partikula bakoitzaren ingurunea grafo baten bidez adieraz daiteke, non bi partikula konektatuta dauden baldin eta bakarrik baldin bata bestearen ingurunean badaude. Lehenengo hurbilketa grafo osoa erabiltzea da, hots, edozein partikularen ingurunean beste gainontzeko partikula guztiak egongo dira; grafo osoa erabili beharrean, beste zenbait topologia ere erabil daitezke (eraztunak, izarrak, toroideak, etab.).

Goian dagoen ekuazioa zuzenean erabiltzen bada, abiadurak dibergitzeko joera izango du, alegia, abiaduraren modulua gero eta handiagoa izango da. Arazo hau ekiditeko kalkulatutako abiadurari muga bat ezartzen zaio.

Behin uneko iterazioaren abiadura kalkulatuta, abiadura partikularen kokapena eguneratzeko erabiltzen da:

\begin{align*}
\mathbf{x}_i(t) = \mathbf{x}_i(t-1) + \mathbf{v}_i(t-1)
\end{align*}


\begin{ifalgorithm}[t]\label{alg:pso}
\begin{ifpseudo}{PSO algoritmoa}
\item \In\ \texttt{initialize\_position}, \texttt{initialize\_velocity}, \texttt{update\_velocity}, \texttt{evaluate} eta \texttt{stop\_criterion} operadoreak
\item \In\ \texttt{num\_particles} partikula kopurua
\item \Out\ \texttt{opt\_solution}
\item \texttt{gbest = p[1]}
\item \textbf{for each} \texttt{i} \textbf{in} \texttt{1:num\_particles} \Do
\item \T{\texttt{p[i]=initialize\_position(i)}}
\item \T{\texttt{v[i]=initialize\_velocity(i)}}
\item \T{\texttt{pbest[i]=p[i]}}
\item \T{\If \texttt{evaluate(p[i])<evaluate(gbest)}}
\item \TT{\texttt{gbest = p[i]}}
\item \T{\EIf}
\item \Done
\item \While !\texttt{stop\_criterion()} \Do
\item \T{\textbf{for each} \texttt{i} \textbf{in} \texttt{particle\_set}}
\item \T{\Do}
\item \TT{\texttt{v[i]} = update\_velocity(i)}
\item \TT{\texttt{p[i] = p[i] + v[i]}}
\item \TT{\If \texttt{evaluate(p[i])<evaluate(pbest[i])}}
\item \TTT{\texttt{pbest[i]}=\texttt{p[i]}}
\item \TT{\EIf}
\item \TT{\If \texttt{evaluate(p[i])<evaluate(gbest)}}
\item \TTT{\texttt{gbest}=\texttt{p[i]}}
\item \TT{\EIf}
\item \T{\Done}
\item \Done
\item \texttt{opt\_solution = gbest}
\end{ifpseudo}
\caption{\textit{Particle Swarm Optimization} algoritmoaren sasikodea}
\end{ifalgorithm}


Iterazio bakoitzean lortutako soluzio --hots, posizio-- berriak ebaluatu eta, beharrezkoa bada, partikulen \eng{personal} ($\mathbf{p}_i$) eta \eng{global best} ($\mathbf{p}_g$) eguneratu behar dira. Urrats guzti hauek \ref{alg:pso} algoritmoan biltzen dira.


Algoritmo hau \code{metaheuR} paketeko \code{basicPso} funtzioan inplementaturk dago. Erabilera erakusteko, optimizazio numerikoan \eng{benchmark} gisa erabiltzen den Rosenbrock funtzioa erabiliko dugu; problema sortzeko \code{rosenbrockProblem} funtzioa erabili behar dugu.


<<PSO_1, cache=TRUE , echo = -1 , prompt=TRUE, message=FALSE , warning=FALSE>>=
set.seed(1)
n <- 10
rsb.problem <- rosenbrockProblem(size=n)
@

Algoritmoa aplikatzeko partikula kopurua, hasierako kokapenak eta abiadurak, abiadura maximoa, \eng{personal best} koefizientea eta \eng{global best} koefizientea ezarri behar ditugu:

<<PSO_2, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
nparticles <- 100
ipos <- lapply(1:nparticles, 
               FUN=function (i) {
                 return(runif(n))
               })
args <- list()
args$initial.positions  <- ipos 
args$initial.velocity   <- 0
args$max.velocity       <- 5
args$c.personal         <- 2
args$c.best             <- 4
@

Horrez gain, helburu funtzioa eta baliabide konputazionalak ere finaktu behar ditugu.

<<PSO_3, cache=TRUE , prompt=TRUE , echo = -1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=7 , fig.height=4>>=
args$verbose   <- FALSE
args$evaluate  <- rsb.problem$evaluate
args$resources <- cResource(time=10)

res.pso <- do.call(basicPso, args)

plotProgress(res.pso, x="iterations", y="best") + labs(y="Best Solution")
plotProgress(res.pso, x="iterations") + labs(y="Average Solution")
@

\ref{fig:Rosenbrock} irudiak bilaketaren progresioa erakusten du. Ezkereko grafikoan partikulen batazbesteko ebaluazioa erakusten da, iterazioz iterazio; eskubikoak, berriz, bilaketan zehar topatutako soluziorik onenaren \eng{fitness}-aren progresioa erakusten du. Beste algoritmoetan ez bezala, partikulen helburu funtzioaren balioek ez dute konbergitzen; hala eta gustiz ere, bilaketak aurrera egiten du eta, azkenean, optimotik oso hurbil gelditzen da --Rosenbrock funtzioaren balio minimoa 0 da--.


\begin{figure}[t]
\subfigure[Batazbesteko soluzioaren progresioa]{
\includegraphics[width=0.45\textwidth] {./Irudiak/PSO_3-2}
}\qquad
\subfigure[Soluzio onenaren progresioa]{
\includegraphics[width=0.45\textwidth] {./Irudiak/PSO_3-1}
}\\
\caption{PSO algoritmoaren progresioa Rosenbrock probleman}\label{fig:Rosenbrock}
\end{figure}


\bibliographystyle{plain}
\bibliography{references}

\end{document}