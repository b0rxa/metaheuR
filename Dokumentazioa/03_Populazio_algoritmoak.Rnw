% !TeX spellcheck = eu_ES
\documentclass[eu]{ifirak}

\usepackage{amsmath,latexsym,amssymb,natbib}
\usepackage{listings}
\usepackage{ifcommands,subfigure}
\usepackage[T1]{fontenc}
\usepackage{tcolorbox}

\newcommand{\zkk}{\guillemotleft}
\newcommand{\skk}{\guillemotright}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\eng}[1]{\textit{#1}}
\newcommand{\hgl}[1]{\zkk #1\skk\ }

\begin{document}
\ikasturtea{2014/2015}
\irakasgaia{Bilaketa Heuristikoak}
\title{BHLN: Populazioan oinarritutako algoritmoak}
\date{}
\irakaslea{Borja Calvo, Usue Mori}
\author{Borja Calvo, Usue Mori}


\tel{943 01 50 13}
\mail{borja.calvo@ehu.es}

<<echo=FALSE , purl=FALSE>>=
## This code is for wrapping long outputs
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
knitr::opts_chunk$set(linewidth=100) 
knit_theme$set("earendel")
@


\maketitle

\begin{abstract}
Aurreko kapituluan soluzio bakarrean oinarritzen diren zenbait algoritmo ikusi ditugu. Algoritmo hauek oso portaera ezberdina izan arren, badute ezaugarri komuna: bilaketa prozesua soluzio batetik bestera mugitzen da, soluzioak banan-banan aztertuz. Beraz, oso algoritmo egokiak dira bilaketa espazioaren eskualdea interesgarriak arakatzeko --bilaketa areagotzeko, alegia--. Alabaina, hainbat kasutan emaitza honak lortzeko bilaketa dibertsifikatzea ere beharrezkoa izan liteke. Izan ere, bilaketa lokalean oinarrizen diren algoritmo batzuk dibertsifikatzeko zenbait estrategia darabilte; honen adibide nabarmena tabu bilaketaren epe-luzeko memoria da.

Kapitulu honetan soluzioak banan-banakako azterketa alde batera utzita, multzoka erabiltzeari ekingo diogu, horixe baita, hain juxtu, populazioetan oinarritzen diren algoritmoen filosofia. Une oro, soluzio bakar bat izan beharrean soluzio multzo bat izango dugu. Testu inguru batzuetan multzo horri \hgl{soluzio-populazio} deritzo eta, hortik, algoritmo hauen izena. Bilaketa prozesuan multzo hori aldatuz joango da, helburu funtzioaren gidapean.

Bi dira, nagusiki, populazioetan oinarritzen diren algoritmoen hurbilketak: algoritmo ebolutiboak eta \eng{swarm intelligence}. Lehenengo kategoriako algoritmoek, teknika ezberdinak erabiliz, populazioa eboluzionarazten dute, geroz eta soluzio hobeak izan ditzan. Adibiderik ezagunena algoritmo genetikoak dira. Bigarren algoritmo mota, berriz, zenbait animalien portaeran oinarritzen da. Hauen arteko adibiderik ezagunenaren kasua, esate baterako, inurriek janaria eta inurritegiaren arteko distantziarik motzena topatzeko darabilten mekanismoa imitatu egiten du.

Kapitulua bi zatitan banaturik dago. Lehenengoan algoritmo ebolutioben eskema orokorra ikusi ondoren, algoritmo genetikoak eta EDAk aurkezten dira. Bigarren zatian \eng{swarm intelligence} arloan proposaturiko bi algoritmo aztertuko dira.
\end{abstract}


\section{Algoritmo Ebolutiboak}\label{sec:ebolutiboak}
1859. urtean Charles R. Darwin \eng{On the Origin of the Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life} liburua argitaratu zuen. Tituluak berak adierazten duen bezala, liburu honetan Darwinek hautespen naturalaren teoria aurkeztu zuen. 

Eboluzioaren teoriak dioenez, generazioz generazio zenbait mekanismoen bidez --mutazioak, esate baterako-- aldaketak sortzen dira. Aldaketa batzuei esker indibiduoak hobeto egokitzen dira beraien inguruneari eta, ondorioz, bizirik mantentzeko eta, batez ere, ugaltzeko probabilitateak handitzen dira. Era berean, noski, aldaketa batzuk kaltegarriak izan daitezke, bizitzeko aukerak murriztuz. Kontutan hartuz aipatutako aldaketak heredatu egiten direla, ezaugarri onak generazioz generazio pasatzen dira; kaltegarriak direnek, ostera, galtzeko joera izaten dute. Mekanismo honen bidez, espezieak beraien ingurunera egokitzeko gai dira.

Hirurogeigarren hamarkadan ikertzaileek Darwinaren lana inspiraziotzat hartu zuten optimizazio metahuristikoak diseinatzeko; gaur egun konputazio zientziaren arlo oso bat da konputazio ebolutiboa. Atal honetan bi algoritmo mota aztertuko ditugu, algoritmo genetiko klasikoak eta EDAk (\eng{Estimation of Distribution Algorithms}).

Algoritmo ebolutibotan bi dira giltzarri diren elementuak: hautespena eta soluzio berrien sorkuntza. Naturan bezala, soluzio onak aukeratuko ditugu hurrengo belaunaldiara pasatzeko. Soluzio txarrenak deusestatzen ditugunez, populazioa osatzeko soluzio berriak behark dira; sorkuntza prozesua aukeratu digutu soluzioak hartzen ditu abia-puntutzat.

\begin{figure}[t]
\centering
\includegraphics[height=0.2\textheight]{./Irudiak/AEB}
\caption{Algoritmo ebolutiboen eskema orokorra}
\label{fig:alg.evol}
\end{figure}


Diferentziak diferentzia, algoritmo ebolutiboen eskema orokorra defini daiteke (ikusi \ref{fig:alg.evol} irudia). Algoritmoaren sarrera-puntua hasierako populazioa izango da; populazio horretatik abiatuz, algoritmoa begizta nagusian sartzen da, non bi pausu tartekatzen dira. Lehenik, uneko populazioan dauden soluzioetatik batzuk aukeratzen dira. Ondoren, soluzio horiek erabiliz populazio berri bat sortzen da. Begizta nagusia etengabekoa denez, zanbait irizpide erabiltzen dira algoritmoa amaitutzat emateko.

Hurrengo ataletan eskema orokor hau nola gauzatzen den ikusiko dugu. Dena dela, zenbait pausu orokorrak diren legez, algoritmo konkretuak ikusi aurretik aztertuko digutu. 

\subsection{Urrats orokorrak}

Badaude zenbait pausu algoritmo ezberdinetan oso antzerakoak direnez. Izan ere, ikusiko ditugun algoritmoen arteko diferentzia nagusia soluzio berrien osaketan datza. Atal honetan beste urratsak aztertuko ditugu eta hurrengo ataletan soluzioen sorkuntzari ekingo diogu.

\subsubsection{Populazioaren hasieraketa}

Hasierako populazioa da algoritmoaren abia-puntua eta, hortaz, bere sorkuntza oso pausu garrantzitsua da. Izan ere, askotan garrantzi gutxiegi ematen zaio pausu honi, nahiz eta oso eragin handia izan azken emaitzan.

Algoritmoen xedea soluzio honak topatzea izanda, pentsa dezakegu hasierako populazio on bat sortzeko soluzio onak behar ditugula. Alabaina, dibertsitatea soluzioen kalitatea bezain garrantzitsua da. Izan ere, oso soluzio antzerakoak baldin baditugu, onak izan arren, populazioaren eboluzioa oso zaila izango da eta algoritmoaren konbergentzia goiztiarra gertatuko da. 

Hortaz, hasierako populazioa sortzean bi aspektu izan behar ditugu kontutan: kalitatea eta dibertsitatea. Kasu gehienetan ausazko hasieraketak erabiltzen dira lehen populazioa sortzeko, hau da, ausazko soluzioak sortzen dira populazioa osatu arte. Estrategia hau erabiliz dibertsitate handiko populazioa sortuko dugu, baina kalitatea ez da handia izango. 

Populazioa guztiz ausaz sortzen badugu dibertsitatea handia izan arren ez da optimoa izango. Hori dela eta, proposatu dira beste prozedura batzuk populazioak sasi-ausaz sortzeko dibertsitatea maximizatuz. Esate baterako dibertsifikazio sekuentzialean soluzio berri bat onartzeko populazioan dauden soluzioekiko distantzia minimo batera egon behar da. Adibide moduan, 10 tamainako populazio bat sortu nahi dugula non soluzioak 25 tamainako bektore bitarrak diren. Dibertsitatea bermatzeko beraine arteko Hamming distantzia minimoa 3 izan behar dela inposa dezakegu. Jarraian dagoen kodeak horrelako populazioak sortzen ditu:

<<ham_dis , prompt=TRUE, echo=-1 , message=FALSE>>=
set.seed(1)
hamm.distance <- function (v1 , v2){
  d <- sum(v1!=v2)
  return(d)
}

rnd.binary <- function(n){
  return (runif(n) > 0.5)
}
@

Lehenik, Hamming distantzia neurtzeko eta ausazko bektore bitarrak sortzeko funtzioak sortzen ditugu. Gero, soluzioak asuaz sortzen ditugu eta, distantzia minimoko baldintza bete ezean, deusestatzen dira; prozedura nahi ditugun soluzio kopurua lortu arte exekutatzen da. 

<<seq_divers , prompt=TRUE, message=FALSE>>=
sol.size <- 25
pop.size <- 10
min.distance <- 10
population <- list(rnd.binary (sol.size))
while (length(population) < pop.size){
  new.sol <- rnd.binary(sol.size)
  distances <- lapply(population , FUN = function(x) hamm.distance (x,new.sol))  
  if (min(unlist(distances)) <= min.distance)
    population[[length(population) + 1]] <- new.sol
}

@


Hau prozedura ez da bat ere eraginkorra, zenbait kasutan soluzio asko sortu beharko batitugu populazioa sortu arte. Beste alternatiba bat dibertsifikazio paraleloa da. Kasu honetan bilaketa espazioa zatitu egiten da eta azpi-espazio bakoitzetik ausazko soluzio bat erauzten da.

Orain arte dibertsitateari bakarrik erreparatu diogu. Hasierako popuazioaren kalitatea handitu nahi izanez gero, hasieraketa heuristikoak erabil datezke. Era sinple bat hau egiteko GRASP algoritmoetan ausazko soluzioak sortzeko erabiltzen diren prozedurak erabil daitezke. Ikus dezagun adibide bat TSP problemarako. Lehenik, Bavierako hirien problema kargatzen dugu.

<<heur_init_1 , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE>>=
library("metaheuR")
url <- system.file("bays29.xml.zip" , package = "metaheuR")
cost.matrix <- tsplib.parser(url)
@

Orain, \code{tsp.greedy} funtzioan oinarrituta ausazko soluzio onak sortzeko funtzio bat definitzen dugu.

<<heur_init_2 , prompt=TRUE, message=FALSE>>=
rnd.sol <- function(cl.size = 5){
  tsp.greedy(cmatrix = cost.matrix , cl.size = cl.size)
}
@

Soluzioak sortzeko aurreko kapituluan azaldutako prozedura erabiltzen dugu [REF], hau da, algoritmo eraikitzailea non urrats bakoitzean \code{cl.size} --\eng{candidate list} tamainaren, alegia-- soluzio osagai onenetatik bat ausaz aukeratzen den; Adibide honetan hautagaien zerrendaren tamaina 5-en finkatuko dugu. Populazioa sortzeko funtzio hau erabiliko dugu.

<<heur_init_3 , prompt=TRUE, message=FALSE>>=
pop.size <- 25
population <- lapply (1:pop.size , FUN = function(x) rnd.sol())
@

Hautagaien zerrenda handitzen badugu problemaren tamainaraino pausu bakoitzean aukera guztietatik bat ausaz hartuko dugu, hots, guztiz ausazkoak diren soluzioak sortuko ditugu. Hau eginda populazioaren kalitatea goiko kodearekin lortutakoa baino txarragoa izango da:

<<heur_init_4 , prompt=TRUE, message=FALSE>>=
rnd.population <- lapply (1:pop.size , FUN = function(x) rnd.sol(cl.size = ncol(cost.matrix)))
tsp <- tsp.problem(cost.matrix)
eval.heur <- unlist(lapply(population , FUN = tsp$evaluate))
eval.rnd <- unlist(lapply(rnd.population , FUN = tsp$evaluate))
@


Bi populazioen ebaluazioak \eng{boxplot} baten bidez aldera dezakegu.

<<plot_heur_vs_rnd, prompt=TRUE , cache=TRUE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=8 , fig.height=4>>=
df <- rbind (data.frame (Method = "Heuristic" , Evaluation = eval.heur) , 
             data.frame (Method = "Random" , Evaluation = eval.rnd))
ggplot(df , aes(x = Method , y = Evaluation)) + geom_boxplot()
@

\begin{figure}[t]
\centering
\includegraphics[height=0.33\textheight]{./Irudiak/plot_heur_vs_rnd-1}
\caption{Ausazko hasieraketa eta hasieraketa heuristikoaren helburu funtzioaren distribuzioa}
\label{fig:heur_vs_rnd_init_pop}
\end{figure}

\ref{fig:heur_vs_rnd_init_pop} irudiak bi populazioen dauden soluzioen ebaluazioaren banaketa erakusten du. Argi eta garbi ikus daiteke heuristikoa erabiliz sortutako soluzioak hobeak direla.

Soluzioak sortzeko metodoak ez ezik, populazioaren tamainak ere badu eragin handia azken emaitzan. Izan ere, populazioaren tamaina egokitu behar den oso parametro garrantzitsua izango da. Populazioak txikiegiak badira, dibertsitatea mantentzea oso zaila izango da eta, hortaz, belaunaldi gutxitan algoritmoa konbergituko da. Beste aldetik, populazioa handiegia bada, konbergentzia abiadura motelduko da baina kostu konputazionala handituko da. Ez dago bide finkorik tamaina ezartzeko, problema bakoitzeko egokitu beharko da. Edonola ere, irizpide orokor gisa esa dezakegu populazio azkar konbergitzen badu --hots, soluzioen arteko distantzia azkar txikitzen bada--, irtenbide bat populazioare tamaina handitzea izan daitekeela. 


\subsubsection{Hautespena}

Algoritmo ebolutibotan populazioaren murriztea urrats garrantzitsua da, populazioaren eboluzioa kontrolatzen duen prozesua baita. Orokorrean, populazioan dauden soluziorik onenak hautatzea interesatuko zaigu eta hori da, hain zuzen, gehien erabiltzen den hautespena; bakarrik soluziorik onenak aukeratzen dituenez, hautespen honi \zkk elitista\skk\ deritzo.

Algoritmo ebolutibotan bi dira giltzarri diren elementuak: hautespena eta soluzio berrien osaketa. Naturan bezala, soluzio onak aukeratuko ditugu hurrengo belaunaldira pasatze

\textbf{Erruleta-hautespena},  (\textit{Roulette Wheel selection}, ingelesez) deritzon estrategian soluzioak erruleta batean kokatzen dira; soluzio bakoitzari dagokion erruletaren zatia bere ebaluazioarekiko proportzionala izango da. \ref{fig:roulette} irudian ikus daitekeen bezala, erruleta jaurtitzen den bakoitzean indibiduo bat hautatzen da; hautatua izateko probabilitatea erruleta zatiaren tamaina eta, hortaz, indibiduoen ebaluazioarekiko proportzionala da. 

Indibiduo bat baino gehiago aukeratu behar baldin badugu, behar ditugun erruletaren jaurtiketak egin ditzakegu. Alabaina, honek alborapenak sor ditzake; efektu hau saihesteko erruletan puntu bakar bat markatu beharrean (gezia, \ref{fig:roulette} irudian), behar ditugun puntuak finkatu ahal ditugu, puntutik puntura dagoen distantzia kasu guztietan berdina izanik. Era honetan, jaurtiketa bakar batekin nahikoa da behar ditugun indibiduo guztiak hautatzeko. Teknika hau populazioa murrizteko zein indibiduoak gurutzatzeko hautespenean erabil daiteke.

\eng{Fitness}aren magnitudea problema eta, are gehiago, instantzien araberakoa da. Hori dela eta, probabilitateak zuzenean helburu funtzioaren balioarekiko proportzionalak badira, oso distribuzio radikalak izan ditzakegu. Arazo hau ekiditeko, helburu funtzioaren balioa zuzenean erabili beharrean soluzioen ranking-a erabili ohi da.

%KODEA ADIBIDE BAT JARTZEKO. PROBABILITATEAK KALKULATU BALIOA ETA RANKING-A ERABILIZ

\begin{figure}[t]
\centering
\includegraphics[width=0.7\linewidth]{./Irudiak/roulette}
\caption{Erruleta-hautespena. Indibiduo bakoitzaren erruletaren zatia bere ebaluazioarekiko proportzionala da. Erruleta jaurtitzen den bakoitzean indibiduo bat aukeratzen da, bere \eng{fitness}arekiko proportzionala den probabilitatearekin. Adibidean, 2. indibiduoa da hautatu dena.}
\label{fig:roulette}
\end{figure}

\textbf{Lehiaketa-hautespena}. Estrategia honetan hautespena bi pausutan egiten da. Lehenengo urratsean indibiduo guztietatik azpi-multzo bat aukeratzen da, guztiz ausaz (ebaluazioa kontutan hartu barik). Ondoren, aukeratu ditugun indibiduoetatik onena hautatzen dugu. Azpi-multzoa ausaz aukeratzen denez, bertan oso soluzio txarrak leudeke eta, hortaz, nahiz eta onena hautatu, soluzioa txarra izan daiteke.


\subsubsection{Gelditze Irizpideak}

Lehen apiatu bezala, algoritmo ebolutioben begizta nagusia amaigabea da eta, beraz, algoritmoa gelditzeko irizpideren bat ezarri behar dugu bilaketari amaiera emateko. Hurbilketarik sinpleena irizpide estatikoak erabiltzea da, hala nola, denbora maximoa ezartzea edo algoritmoak egin ahal dituen ebaluazioak mugatzea.

Gelditzeko irizpideak dinamikoak ere izan daitezke, eboluzioaren prozesuari erreparatzen badiogu. Balunaldiz balaundi populazioan dauden soluzioak geroz eta hobeak dira eta, aldi berean, populazioaren dibertsitatea murrizten da. Beste era batean esanda, populazioko soluzioek soluzio bakar batera konbergitzeko joera dute.

Hori gertatzen denean eboluzioa moteltzen da eta, beraz, popluzaioaren dibertsitatea gelditzeko irizpide gisa erabili ahal da. Dibertsitatea soluzioei zein beraien \eng{fitness}-ari erreparatuz neur daiteke. Esate baterako, soluzioen arteko distatzia neurtzerik badago, indibiduoen arteko bataz besteko distantzia minimo bat ezar dezakegu.

\subsubsection{Algoritmo Genetikoak}

Lehen aipatu bezala, atal honetan soluzio berriak algoritmo genetikoetan nola sortzen diren ikusiko dugu. Algoritmo genetikoetan naturan espeziekin gertatzen dena imitatzen saiatzen gara. Era honetan, zenbait paralelismo ezar daitezke:

\begin{itemize}
\item Espezieen indibiduoak = Problemaren soluzioak
\item Indibiduoen egokitasuna = Soluzioaren ebaluazioa
\item Espeziearen populazioa = Soluzio multzoa
\item Ugalketa = Soluzio berrien sorkuntza
\end{itemize}

Beraz, algoritmo genetikoetan soluzio berriak sortzeko indibiduen ugalketan oinarrituko gara. Honek bi elementu nagusi ditu: gurutzatzea eta mutazioa.


Ugalketa prozesuaren xedea zenbait indibiduo emanda -- bi, normalean --, indibiduo gehiago sortzea da. Ohikoena prozesu hau bi pausutan banatzea da: soluzioen gurutzaketa eta mutazioa. Lehenaren helburua \hgl{guraso}-soluzioek duten ezaugarriak osatutako soluzioei pasatzea da. Bigarrenarena, berriz, soluzio berrietan ezaugarri berriak sartzea da. Jarraian soluzioak maneiatzeko bi operadore hauek aztertuko ditugu.

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\linewidth]{./Irudiak/point_crossover}
\caption{Gurutzatze-operadoreak bektoreen bidezko kodeketarekin erabiltzeko}
\label{fig:point_crossover}
\end{figure}

\subsubsection{Gurutzaketa} 

Bi soluzio -- edo gehiago -- gurutzatzen ditugunean euren propietateak sortutako soluzioei transmititzea da gure helburua. Hori lortzeko, soluzioei operadore mota berezi bat aplikatuko diegu, \hgl{gurutze-operadorea} -- \eng{crossover}, ingelesez --. Operadore honek soluzioen kodeketarekin dihardu eta, beraz, operadorea hautatzean soluzioak nola adieratzen dugun aintzat hartu beharko dugu. 

Badaude zenbait operadore kodeketa klasikoekin erabil daitezkeenak. Ezagunena puntu bakarreko gurutzatzea -- \eng{one-point crossover}, ingelesez -- deritzona da. Demagun soluzioak bektoreen bidez kodetzen ditugula. Bi soluzio, $s_1$ eta $s_2$ parametro gisa hartuz, operadore honek beste bi soluzio berri sortzen ditu. Horretarako, lehenik eta behin, ausazko posizio bat $i$ aukeratu behar da. Gero, lehenengo soluzio berria $s_1$ soluziotik lehenengo $i$ elementuak eta $s_2$ soluziotik beste gainontzekoak kopiatuz sortuko dugu. Era berean, bigarren soluzio berria $s_2$-tik lehenengo elementuak eta besteak $s_1$-etik kopiatuz sortuko dugu.  \ref{fig:point_crossover} irudiaren ezkerraldean adibide bat ikus daiteke. Irudiak ideia nola orokor daitekeen ere erakusten du, puntu bakar bat hartuz bi, hiru, etab. puntu hartuz.

Operadore hau \code{metaheuR} liburutegian inplementaturik dago, \code{k.point.crossover} funtzioan. Ikus ditzagun adibide batzuk:

<<k_point_cross , prompt=TRUE, echo=-1 , message=FALSE>>=
set.seed(666)
A.sol <- rep("A" , 10)
B.sol <- rep("B" , 10)
A.sol
B.sol
k.point.crossover(A.sol , B.sol , 1)
k.point.crossover(A.sol , B.sol , 5)
k.point.crossover(A.sol , B.sol , 20)
@

Azken lerroan ikus daitekeen bezala, $n$ tamainako bektore bat izanik gehienez $n-1$ puntu erabil ditzakegu operadore honetan; edonola ere, balio maximoa erabiliz jatorrizko soluzioen elementuak tartekaturik izango ditugu eta, oro har, ez da oso balio erabilgarria izango. Izan ere, erabiliko dugun puntu kopurua eragin handia izan dezake algoritmoaren performantzian eta, hortaz, egokitu behar den algoritmoaren parametrotzat hartu beharko genuke. 

Ikusitako operadorea nahiko orokorra da, ia edozen bektoreari aplikatu ahal baitzaio. Hala eta guztiz ere, kodeketa batzuetan operadore bereziak erabil daitezke(\cite{gwiazda2006}). Esate baterako, bektore errealak baldin baditugu, bi bektore harturik era ezberdinetan konbina daitezke; adibidez, bataz bestekoa kalkulatuz. Ikus dezagun operadore hau nola inplementa daitekeen R-n:

<<mean_cross , prompt=TRUE, message=FALSE>>=
mean.crossover <- function (sol1 , sol2){
  new.solution <- (sol1 + sol2) / 2
  return(new.solution)
}

s1 <- runif(10)
s2 <- runif(10)
s1
s2
mean.crossover(s1 , s2)
@

Permutazioak ere bektoreak dira baina, kasu honetan, \eng{k point crossover} operadorea ezin da erabili, permutazioetan ditugun murrizketak direla eta. Hortaz, permutazioak gurutatzeko operadore bereziak behar digutu. Aukera asko izan arren (\cite[talbi2009]), hemen puntu bakarreko gurutzatze operadorearen baliokidea ikusiko dugu. Lehenik eta behin, ikus dezagun zergatik puntu bakarreko operadorea ezin da zuzenean aplikatu permutazioei. Izan bitez bi permutazio, $s_1 = 12345678$ eta $s_2=87654321$, eta gurutzatze puntu bat, $i=3$. Lehenengo soluzio berria lortzeko $s_1$ soluziotik lehendabiziko hiru posizioak kopiatuko ditugu, hau da, $123$, eta besteak $s_2$-tik, hots, $54321$. Hortaz, lortutako soluzioa $s^\prime = 12354321$ izango zen, baina zoritxarrez hau ez da permutazio bat.

Nola saihestu daiteke arazo hau? Soluzio sinple bat hauxe da: lehenengo posizioak zuzenean soluzio batetik kopiatzea; besteak zuzenean beste soluziotik kopiatu beharrean, ordena bakarrik erabiliko dugu. Hau da, soluzio berria sortzeko $s_1$-etik lehenengo 3 elementuak kopiatuko ditugu, $123$, eta falta direnak, $45678$, $s_2$-an agertzen den ordenean kopiatuko ditugu, hots, $87654$. Emaitza, beraz, $s^\prime = 12387654$ izango da eta beraz, orain bai, permutazio bat lortu dugu. Era berean, beste soluzio berri bat sor daiteke $s_2$-tik lehenengo hiru posizioak kopiatuz ($876$) eta beste gainontzeko guztiak $s_1$-an duten ordenean kopiatuz ($12345$); beste soluzioa, beraz, $87612345$ izango da. Operadore honi \hgl{Order crossover} deritzo eta \code{metaheuR} liburutegian inplementaturik dago, \code{order.crossover} funtzioan.

<<order_cross , prompt=TRUE, message=FALSE , echo=-1 , warning=FALSE>>=
set.seed(5)
sol1 <- random.permutation(10)
sol2 <- identity.permutation(10)
as.numeric(sol1)
as.numeric(sol2)
new.solutions <- order.crossover(sol1 , sol2)
as.numeric(new.solutions[[1]])
as.numeric(new.solutions[[2]])
@


\subsubsection{Mutazioa} 

Naturan bezala, gure populazioa eboluzionatzeko dibertsitatea garrantzitsua da. Hori dela eta, behin soluzio berriak lortuta gurutzatze-operadorearen bidez, soluzio hauetan ausazko aldaketak eragin ohi da; aldaketa hauek mutazio operadorearen bidez sortzen dira. 

Mutazioaren kontzeptua ILS algoritmoan agertu zen perturbazioaren antzerakoa da. Izan ere, operadore berdinak erabil daitezke. Esate baterako, permutazio bat mutatzeko ausazko trukaketak erabil ditzakegu. ILS-an bezala, algoritmoa diseinatzean erabaki behar dugu zenbat aldaketak sortuko ditugun -- adibidean, zenbat posizio trukatuko ditugun --.

Mutazio operadorea aukeratzean --eta baita diseinatzean ere-- hainbat gauza hartu behar dira kontuan. Hasteko, soluzioen bideragarritasuna mantentzea garrantzitsua da, hau da, mutazio operadorea bideragarria den soluzio bati aplikatuz gero, emaitza soluzio bideragarria izan behako luke. Bestaldetik, bilaketa prozesua soluzio bideragarrien espazio osoa arakatzeko gaitasuna izan beharko luke eta hori bermatzeko mutazio operadoreak edozein soluzio sortzeko gai izan behar du. Hau da, edozein soluzio hartuta mutazio operadorearen bidez beste edozein soluzioa sortzea posible izan beharko luke. Amaitzeko, lokaltasuna ere mantendu behar da --alegia, mutazioak eragindako aldaketa txikia izan behar da--, bestela gurasoengandik heredatutako ezaugarriak galdu egingo dira.

Mutazio operadorea era probabilistikoan aplikatzen dela; hau da, ez zaie soluzio guztiei aplikatzen. Hortaz, mutazioari lotutako bi parametro izango ditugu: mutazio probabilitatea eta mutazioaren magnitudea.


\begin{ifalgorithm}[t]\label{alg:algoritmo_genetikoak}
\begin{ifpseudo}{Algoritmo Genetikoak}
\item \In\ \texttt{evaluate}, \texttt{select\_reproduction}, \texttt{select\_replacement}, \texttt{cross}, \texttt{mutate} eta \texttt{!stop\_criterion} operadoreak
\item \In\ \texttt{init\_pop} hasierako populazioa
\item \In\ \texttt{mut\_prob} mutazio probabilitatea
\item \Out\ \texttt{best\_sol}
\item \texttt{pop=init\_pop}
\item \While \texttt{stop\_criterion} \Do
\item \T{\texttt{evaluate(pop)}}
\item \T{\texttt{ind\_rep = select\_reproduction(pop)}}
\item \T{\texttt{new\_ind = reproduce(ind\_rep)}}
\item \T{\textbf{for} \textbf{each} \texttt{n} in \texttt{new\_ind} \Do}
\item \TT{\texttt{mut\_prob} probabilitatearekin egin \texttt{mutate(n)}}
\item \T{\Done}
\item \T{\texttt{evaluate(new\_ind)}}
\item \T{\If \texttt{new\_ind} multzoan \texttt{best\_ind} baino hobea den soluziorik badago}
\item \TT{Eguneratu \texttt{best\_sol}}
\item \T{\EIf}
\item \T{\texttt{pop=select\_replacement(pop,new\_ind)}}
\item \Done
\end{ifpseudo}
\caption{Algoritmo genetikoen sasikodea}
\end{ifalgorithm}

Algoritmo genetiko orokorra \ref{alg:algoritmo_genetikoak} irudian ikus daiteke. Algoritmoan dagoen sasikodea \code{basic.genetic.algorithm} funtzioan inplementaturik dago. Ikus dezagun nola erabil daitekeen funtzio hau \eng{graph coloring} problema bat ebazteko. Lehenik, ausazko grafo bat sortzen dugu problemaren instantzia sortzeko.

<<ga_graph_col_1 , prompt=TRUE, message=FALSE , echo=-2 , warning=FALSE>>=
library(igraph)
set.seed(5)
n <- 50
rnd.graph <- aging.ba.game(n = n , pa.exp = 2 , 
                           aging.exp = 0, m = 3 , directed = F)
gcp <- graph.coloring.problem (graph = rnd.graph)
@

Orain zenbait elementu definitu behar ditugu. Lehenengoa, hasierako populazioa izango da. Populazioa sortzeko bere tamaina ezarri behar dugu. Hau algoritmoaren parametro garrantzitsu bat denez, bi balio erabiliko ditugu, emaitzak alderatzeko: $n$ eta $10n$. Soluzioak ausaz sortuko ditugu eta, gero, bideragarriak ez badira, zuzenduko ditugu.

<<ga_graph_col_2 , prompt=TRUE, message=FALSE , warning=FALSE>>=
n.pop.small <- n
n.pop.big <- 10*n
levels <- paste("C" , 1:n , sep = "")
rnd.sol <- function(x){
  sol <- factor(paste("C" , sample(1:n , size = n , replace = TRUE) , 
                      sep = "") , levels = levels)
  return(gcp$correct(sol))
}
pop.small <- lapply(1:n.pop.small , FUN = rnd.sol)
pop.big   <- lapply(1:n.pop.big , FUN = rnd.sol)
@

Hasierako populazioaz gain, ondoko parametro hauek ezarri behar ditugu:

\begin{itemize}
\item Hautespen operadoreak - Hurrengo belaunaldira pasatuko diren soluzioak aukeratzeko hautespen elitista erabiliko dugu, populazio erdia aukeratuz. Soluzioak berriak sortzean zein soluzio gurutzatuko diren aukeratzeko, berriz, lehiaktea hautespena erabiliko dugu.
\item Mutazioa - Soluzioak mutatzeko \code{factor.mutation} soluzio erabiliko dugu. Funtzio honek zenbait posizio ausaz aukeratzen ditu eta bere balioak ausaz aldatzen ditu. Funtzioak parametro bat du, \code{ratio}, zeinek aldatuko diren posizioen ratioa adierazten duen. Gure kasuan 0.1 balioa erabiliko dugu, alegia, \%10 posizio aldatuko dira mutazioa aplikatzen denean. Zein probabilitatearekin mutatuko ditugun soluzioak ere finkatu behar da \code{mutation.rate} parametroaren bidez; gure kasuan probabilitatea bat zati populazioaren tamaina izango da.
\item Gurutzaketa - Soluzioak gurutzatzeko \eng{k point crossover} erabiliko, $k = 2$ finkatuz. 
\item Beste parametro batzuk - Algoritmo genetikoaren parametroaz gain, beste bi parametro finaktuko ditugu, \code{non.valid = 'discard'}, bideraezina diren soluzioak baztertu behar direla adierazteko, eta \code{resources}, gelditze irizpidea mugatzeko ($5n^2$ ebaluazio kopuru maximoa erabiliko dugu).
\end{itemize}

\begin{figure}[t]
\subfigure[Algoritmo genetikoaren progresioa]{
\includegraphics[width=0.65\textwidth] {./Irudiak/ga_graph_col_3-1}
}\qquad
\subfigure[Lortutako soluzioa]{
\includegraphics[width=0.30\textwidth] {./Irudiak/ga_graph_col_4-1}
}\\
\caption{Algoritmo genetikoaren progresioa \eng{graph coloring} problema batean, bi poulazio tamaina ezberdin erabiliz. Ezkerrean, populazio tamaina handiarekin lortutako soluzioa ikus daiteke.}\label{fig:ga_progress}
\end{figure}

Jarraian parametro hauek erabiliz algoritmo genetikoa exekutatzeko kodea dago.


<<ga_graph_col_3, prompt=TRUE, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
args <- list()
args$evaluate             <- gcp$evaluate
args$initial.population   <- pop.small
args$select.subpopulation <- elitist.selection
args$selection.ratio      <- 0.5
args$select.cross         <- tournament.selection
args$mutate               <- factor.mutation
args$ratio                <- 0.1
args$mutation.rate        <- 1 / length(args$initial.population)
args$cross                <- k.point.crossover
args$k                    <- 2
args$non.valid            <- 'discard'
args$resources            <- cresource(evaluations = 5*n^2)

bga.small <- do.call(basic.genetic.algorithm , args)

args$initial.population   <- pop.big
args$mutation.rate        <- 1 / length(args$initial.population)

bga.big <- do.call(basic.genetic.algorithm , args)
plot.progress(list("Big population" = bga.big , "Small population" = bga.small) , 
              size = 1.1) + labs(y = "Average fitness")
@


<<ga_graph_col_4, prompt=TRUE , echo = FALSE , message=FALSE , warning=FALSE  , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=5 , fig.height=5>>=
best.big <- unlist(optima(bga.big)[[1]])
gcp$plot(best.big,node.size=15,label.cex=0.75)
@


\ref{fig:ga_progress} irduian bi populazio erabiliz bilaketaren progresioa ikus daiteke. Populazioa txikia denean populazioa oso azkar konbergitzen du 19 kolore erabiltzen dituen soluzio batera. Populazioko soluzio gehienak oso antzerakoak direnean soluzio berriak sortzeko bide bakarra mutazioa da, baina prozesu hori oso motela denez, grafikan ikus daiteke soluzioen bataz besteko ebaluazioa ez dela aldatzen. 

Populazioaren tamaina handitzen dugunean konbergentzia zailagoa da eta grafikan ikus daiteke helbur funtzioaren balioaren eboluzioa motelagoa izan arren, lortutako soluzioa hobea dela.


\begin{figure}[t]
\centering
\includegraphics[width=0.75\textwidth] {./Irudiak/ga_mut_rate-1}
\caption{Mutazioaren probabilitatearen eragina algoritmo genetikoaren emaitzan. Irudian ikus daitekeen bezala, soluziorik onenak ematen duen balioa 0.5 inguruan dagoena da (zehazki, 0.6). }\label{fig:ga_mutrate}
\end{figure}


Populazioaren tamaina ez ezik, beste hainbat parametro eragin handia izan dezakete algoritmoaren emaitzan; esate baterako, mutazioaren probabilitatea. Adibide gisa, popluazio tamaina txikia erabiliz mutazio probabilitate ezberdinak erabiliko ditugu, eta, ondoren, bakoitzarekin lortutako emaitzak alderatuko ditugu.


<<ga_mut_rate, prompt=TRUE, echo=-1, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
set.seed(10)
args$initial.population   <- pop.small
args$verbose              <- FALSE
args$resources            <- cresource(evaluations = n^2)

test.mutprob <- function (rate){
  args$mutation.rate        <- rate
  res <- do.call(basic.genetic.algorithm , args)
  evaluation(res)
}

ratios <- seq(0,1,0.2)
evaluations <- sapply(ratios , FUN = test.mutprob)

df <- data.frame("Mutation_rate" = ratios , "Fitness" = evaluations)
ggplot(df , aes(x=Mutation_rate , y = Fitness)) + geom_line() + geom_point(size = 5) + 
  labs(x = "Mutation rate")
@


\ref{fig:ga_mutrate} irudian konparaketaren emaitzak ikus daitezke. Grafikoan agerian dago probabilitate txikiegiak zein handiegiak kaltegarriak direla bilaketarako; izan ere, probabilitate egokiena 0.5 ingurukoa da. Edonola ere, kontutan hartu behar da probabilitate txikien kasuan emaitzak txarrak direla konbergentzia goiztiarra dugulak baina, probabilitate handiekin berrriz, arazoa izan daiteke justo kontrakoa, alegia, jarri dugun muga dela eta populazioa konbergitzen duela. Hau egiaztatzeko, errepika dezakezu goiko kodea ebaluazio kopuru maximoa handituz --izan ere, esperimentu honetarako $5n^2$-tik $n^2$-ra txikitu dugu--.

\subsection{Estimation of Distribution Algorithms}

Algoritmo genetikoetan uneko populazioa indibiduo berriak sortzeko erabiltzen da. Prozesu honetan, naturan inspiratutako operadoreen bidez burutzen dena, populazioan dauden ezaugarriak mantentzea espero dugu. Zenbait ikertzaile ideia hau hartu eta ikuspen matematikotik birformulatu zuten; gurutzatze-operadoreak erabili beharrean, eredu probabilistikoak erabiltzea proposatu zuten, populazioaren \zkk esentzia\skk\ kapturatzeko helburuarekin. Hauxe da EDA -- \textit{Estimation of Distribution Algorithms} -- algoritmotan erabiltzen den ideia.

Algoritmo genetikoen eta EDA motako algoritmoen artean dagoen diferentzia bakarra indibiduo berriak sortzean dago. Gurutzatzea eta mutazioa erabili beharrean, uneko populazioa eredu probabilistiko bat \zkk ikasteko\skk\ erabiltzen da. Ondoren, eredu hori laginduko dugu nahi dugun indibiduo adina sortzeko.

EDA algoritmoen gakoa, beraz, eredu probabilistikoa da. Ildo honetan, esan beharra dago eredua soluzioen kodeketari lotuta dagoela, soluzio adierazpide bakoitzari probabilitate bat esleitu beharko diolako. Partikularki, ikusi ditugun kodeketa estandarretatik badago bat bereziki zaila dena EDAtan erabiltzeko: permutazioak.

Konplexutasun ezberdineko eredu probabilistikoen erabilera proposatu da literaturan, baina badago hurbilketa sinple bat oso hedatua dagoen: UMDA -- \textit{Univariate Marginal Distribution Algorithm} --. Kasu honetan soluzioaren osagaiak -- bektore bat bada, bere posizioak -- independenteak direla suposatuko dugu eta, hortaz, osagai bakoitzari dagokion probabilitate marjinala estimatu beharko dugu. Gero, indibiduoak sortzean osagaiak banan-banan aukeratuko ditugu probabilitate hauek kontutan hartuz. 

Ikus dezagun adibide bat. Demagun $n=4$ tamainako problema bat dugula, non soluzioak bektore bitarren bidez kodetzen diren. Uneko populazioa, bost indibiduo dituena, jarraian dagoen matrizean adierazten da:

\begin{align*}
\left (
\begin{array}{llll}
0 & 1 & 1 & 0\\
1 & 1 & 0 & 0\\
1 & 0 & 0 & 0\\
1 & 1 & 1 & 0\\
0 & 1 & 1 & 0\\
\end{array}\right )
\end{align*}

Populazio honetatik eredu bat sortu behar dugu. UMDA kasuan, eredu horrek bektore posizio bakoitzaren probabilitate marjinalak gordeko ditu. Beraz lau probabilitate izango ditugu, $P(X_1=1), P(X_2=1), P(X_3=1)$ eta $P(X_4=1)$\footnote{Kontutan hartu edozein osagarriarentzat $P(X_i=0) = 1-P(X_n=1)$ betetzen dela}. Lehenengo probabilitatea kalkulatzeko matrizearen lehendabiziko zutabeari erreparatu behar diogu. Bertan bost indibiduoetatik hirutan $X_1=1$ dela ikus daiteke; hortaz, $P(X_1=1)=0.6$ izango da. Era berean, beste probabilitate guztiak estimatuko ditugu: $P(X_2=1)=0.8, P(X_3=1)=0.6$ eta $P(X_4=1)=0$. 

Indibiduo berriak sortzeko lau osagarrien balioak erabaki behar ditugu, estimatu ditugun probabilitateak errespetatuz betiere. Beraz, $X_1$-ek $1$ balioa hartuko du $0.6$ probabilitatearekin, $X_2$-k $0.8$ probabilitatearekin, etab. 



\section{Swarm Intelligence}\label{sec:swarm}

Eboluzioaz gain, badago populazioetan oinarritzen diren algoritmoen artean beste intuizio edo inspirazio nagusia arrakasta handia lortu duena, \textit{swarm intelligence} deritzona. Naturan badaude hainbat espezie zeinen indibiduoen portaera, indibidualki, oso sinplea den baina, taldeka daudenean, ataza zailak burutzeko gai diren. Intsektuak dira, zalantzarik gabe, adibiderik ezagunena. Hauen artean inurriak, erleak eta termitak dira adibide aipagarrienak.

\subsection{Inurri Kolonien Algoritmoak}

Inurriek, janaria topatzen dutenean, beraien koloniatik janarira biderik motzena topatzeko gaitasuna dute. Inurri bakar batek ezin du horrelakorik egin baina, taldeka, komunikazio mekanismo sinpleei esker ataza burutzeko gai dira. Erabiltzen den komunikabidea zeharkakoa da, darien molekula berezi bati esker: feromona. Inurri bakoitza mugitzen denean feromona-lorratz bat uzten du eta, atzetik datozen inurriak lorratz hori jarraitzeko gai dira. Geroz eta feromona gehiago, orduan eta probabilitate handiagoa datozen inurriak utzitako lorratza jarraitzeko. 

\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{./Irudiak/ants}
\caption{Feromonaren erabileraren adibidea. Hasierako egoeran biderik motzena feromonaren bidez markatuta dago. Bidea mozte dugunean, inurriek eskumara edo ezkerrera joango dira, probabilitate berdinarekin feromonarik ez dagoelako. Eskumako bidea luzeagoa da eta, ondorioz, ezkerreko bidearekiko inurrien fluxua txikiagoa da. Denbora igaro ahala eskumako lorratza ahulduko da; ezkerrekoa, berriz, indartuko da. Honek inurrien erabakia baldintzatuko du, ezkerretik joateko joera handiago sortuz eta, ondorioz, bi bideen arteko diferentziak handituz. Denbora nahiko igarotzen denean eskumako lorratza guztiz galduko da; koloniak bide motzena topatu du}
\label{fig:ants}
\end{figure}


Topatutako elikagai-iturriaren kalitatearen arabera, utzitako feromona kopurua ezberdina da; geroz eta kalitate handiagoa, orduan eta feromona gehiago. Kontutan hartuz feromona lurrunkorra dela, hau da, denborarekin baporatzen dela, koloniak komunikazio sistemari esker biderik motzena topatzeko gai dira. 

Mekanismoaren erabilera \ref{fig:ants} irudian ikus daiteke. Hasieran bide motzena feromona lorratzaren bidez markatuta dute inurriek. Bidea mozten dugunean, eskuman eta ezkerrean ez dago feromonarik eta, hortaz, inurri batzuk eskumatik eta beste batzuk ezkerretik joango dira, probabilitate berdinarekin. Ezkerreko bidea motzagoa denez, denbora berdinean ezkerretik inurri gehiago igaroko dira, ezkerreko bidean feromona gehiago utziz. Ondorioz, datozen inurriak ezkerretik joateko joera handiago izango dute, bide hori indartuz. Eskumako bidean lorratza apurka-apurka baporatuko da eta, denbora nahiko igarotzen bada, zeharo galduko da.

Intuizio hau optimizazio problemak ebazteko erabil daiteke. Ikus dezagun adibide bat.

\subsection{Adibidea: \textit{Linear ordering problem}}

\textit{Linear Ordering Problem}, LOP, optimizazio problema klasiko bat da. Matrize karratu bat emanda, honen errenkadak eta zutabeak ordenatu behar dira, aldi berean, diagonaletik gora dauden elementuen batura minimizatzeko. Demagun ondoko matrizea daukagula:

\begin{align*}
\begin{array}{l|llll}
& Z_1 & Z_2 & Z_3 & Z_4\\
\hline
E_1 & 9 & 4 & 2 & 3\\
E_2 & 2 & 4 & 6 & 1\\
E_3 & 1 & 3 & 6 & 3 \\
E_4 & 7 & 4 & 4 & 8 \\
\end{array}
\end{align*}

Edozein ordenazio emanda, matrizeen errenkadak eta zutabeak ordena daitezke, matrize berri bat sortuz. Esate baterako, 2. eta 3. zutabe/errenkada trukatzen baditugu, ondoko matrizea lortuko dugu:

\begin{align*}
\begin{array}{l|llll}
& Z_1 & Z_3 & Z_2 & Z_4\\
\hline
E_1 & 9 & 2 & 4 & 3\\
E_3 & 1 & 6 & 3 & 3\\
E_2 & 2 & 6 & 4 & 1 \\
E_4 & 7 & 4 & 4 & 8 \\
\end{array}
\end{align*}

Ordenazio hau LOP-rako soluzio bat da, $[1324]$ permutazioaren bidez adieraziko duguna. Edozein permutazio problemarako soluzio bat izango da, zeinen ebaluazioa jarraian nabarmendua dauden elementuen batura den.

\begin{align*}
\begin{array}{l|llll}
& Z_1 & Z_3 & Z_2 & Z_4\\
\hline
E_1 & 9 & \mathbf{2} & \mathbf{4} & \mathbf{3}\\
E_3 & 1 & 6 & \mathbf{3} & \mathbf{3}\\
E_2 & 2 & 6 & 4 & \mathbf{1} \\
E_4 & 7 & 4 & 4 & 8 \\
\end{array}
\end{align*}

\noindent hau da, kasu honetan 16. 

Beraz, LOP-rako soluzioak permutazioak dira. $n$ nodoko grafo osoa hartzen badugu, non nodoak zenbatuta dauden, edozein ziklo Hamiltoniarra\footnote{Gogoratu ziklo bat Hamiltoniarra dela erpin guztietatik behin eta bakarrik behin pasatzen bada} permutazio bat da. \ref{fig:ant_builders} irudian adibideko permutazioari dagokion zikloa ikus daiteke.

\begin{figure}
\centering
\includegraphics[width=0.75\linewidth]{./Irudiak/ant_builders}
\caption{Soluzioen eraikuntza. Grafo osotik abiatuta, edozein permutazioa ziklo Hamiltoniar baten bidez adieraz daiteke. Inurrien portaera soluzioak eraikitzeko erabil daiteke, pausu bakoitzean inurria uneko erpinetik zein erpinera mugituko den erabakiz.}
\label{fig:ant_builders}
\end{figure}

Grafoen bidezko permutazioen adierazpidea erabiliz, inurri \zkk artifizialak\skk\ erabil ditzakegu LOP-rako soluzioak eraikitzeko. Demagun 1. nodoan inurri bat kokatzen dugula. Inurriak ziklo bat osatzeko zein nodora mugituko den erabaki beharko du; hau da, 1. nodotik 2., 3. edo 4. nodora joango den erabaki beharko du. Demagun 3. nodora joaten dela, hurrengo urratsean 2. eta 4. nodoen artean bat aukeratu beharko du inurriak. 2. nodoa aukeratzen bada, zikloa osatzeko 4. nodora eta, handik 1. nodora joan beharko da. Prozesu hau jarraituz adibideko permutazioa eraiki dezakegu; \ref{fig:ant_builders} irudiak prozesua erakusten du.

Inurri artifizialen bidez soluzioak eraiki daitezke baina, nola erabaki uneko nodotik nora abiatu?. Galdera honi erantzuteko naturan gertatzen denari erreparatuko diogu. Egiazko inurriek bidea ausaz aukeratzen dute, baina bide bat edo bestea aukeratzeko probabilitatea feromona kopuruarekiko proportzionala da. Era berean, grafoaren ertz bakoitzari feromona kopuru bat esleitzen badiogu, gure inurri artifizialak bidea erabakitzeko feromona erabili ahal izango du.

Hortaz, uneoro ertz bakoitzean zenbat feromona dagoen gorde beharko dugu $F$ matrizean, non $f_{i,j}$ $i$ nodotik $j$ nodora joateari dagokion feromona kopurua den\footnote{Kontutan hartu naturan ez bezala, bidearen noranzkoa garrantzitsua izan daitekeela; hau da, ez da berdina $i$-tik $j$-ra edo $j$-tik $i$-ra joatea}. Feromona kopurua eguneratu barik, inurri-koloniak ez luke bide motzena topatuko. Era berean, gure problema ebazteko feromona matrizea eguneratu beharko dugu. Naturan bezala, feromona kopurua eguneratzeko bi pausu izango ditugu: lurrunketa eta feromona lagatzea. Hasieran matrizearen posizio guztien feromona kopurua berdina izango da; hortik aurrera inurriek erabilitako bideak kontutan hartu beharko ditugu feromona kopurua eguneratzeko. 

Lurrunketa egiteko $F$ matrize posizio guztiak txikiagotuko ditugu, $f_{i,j} = \alpha f_{i,j}$ eginez, non $0<\alpha<1$ izango den. Lagatze prozesuari dagokionez, oso era sinplean egin daiteke, soluzio bakoitza sortzean erabilitako ertzei balio finko bat gehituz. Hau da, inurri bat soluzioa eraikitzeko 2. nodotik 3. nodora joaten bada, $f_{2,3}$ eguneratuko dugu balio finko bat $d$ gehituz. \ref{alg:ant} algoritmoan prozeduraren sasikodea ikus daiteke. Algoritmoa aplikatzeko zenbait funtzio beharko ditugu:

\begin{itemize}
\item \texttt{initialize\_matrix} - Funtzio honek feromona matrizea hasieratzen du, posizio guztiei -- diagonala izan ezik -- balio finko bat esleituz
\item  \texttt{build\_solution(pheromone\_matrix)} - \texttt{pheromone\_matrix} feromona matrizea erabiliz, funtzio honek pausuz pausu soluzio bat eraikitzen du. Lehen pausua nodo bat ausaz aukeratzea da. Gero, urrats bakoitzean uneko nodotik zein nodoetara joan gaitezkeen jakin behar dugu -- bisitatu barik daudenak, alegia --. Aukera guztietatik bat ausaz aukeratuko dugu; aukera bakoitzari dagokion probabilitatea feromona matrizean dauden balioak erabiliz kalkulatuko dugu.
\item \texttt{evaporate(pheromone\_matrix)} - Funtzio honek feromona matrizea hartzen du eta posizio bakoitza eguneratzen du, 0 eta 1 tartean dagoen balio bat biderkatuz.
\item \texttt{add\_pheromone (pheromone\_matrix,solution)} - Funtzio honek, soluzio bat emanda, soluzio hori eraikitzeko jarraitutako bidean dauden ertz guztiei balio finko bat gehitzen die.
\end{itemize}

\subsection{ACO algoritmoak diseinatzen}

Aurreko atalean LOP nola ebatz daitekeen ikusi dugu. Orokorrean, optimizazio problema bat ACO motako algoritmo baten bidez ebatzi nahi badugu, bi elementu nagusi beharko ditugu: soluzioak eraikitzeko prozedura bat\footnote{Hau dela eta, ACO algoritmoak erraz diseina daitezke ebatzi nahi dugun problema ebazteko algoritmo eraikitzaile onak existitzen badira} eta feromona eredu bat. Algoritmo eraikitzaileetan pausu bakoitzean zenbait aukera izaten ditugu; ACO bat diseinatzeko feromona ereduak aukera bakoitzaren feromona kopurua mantenduko du.


\begin{ifalgorithm}[t]\label{alg:ant}
\begin{ifpseudo}{Inurri-kolonien algoritmoa}
\item \In\ \texttt{build\_solution}, \texttt{evaporate}, \texttt{add\_pheromone }, \texttt{initalize\_matrix} eta \texttt{stop\_criterion} operadoreak
\item \In\ \texttt{k\_size} koloniaren tamaina
\item \Out\ \texttt{opt\_solution}
\item \texttt{pheromone\_matrix} = \texttt{initialize\_matrix()}
\item \While !\texttt{stop\_criterion()}
\item \T{\textbf{for} \texttt{i} \textbf{in} 1:\texttt{k\_size}}
\item \TT{\texttt{solution} = \texttt{build\_solution(pheromone\_matrix)}}
\item \TT{\texttt{pheromone\_matrix} = \texttt{add\_pheromone(pheromone\_matrix,solution)}}
\item \TT{\If \texttt{solution} \texttt{opt\_solution} baino hobea da}
\item \TTT{\texttt{opt\_solution}=\texttt{solution}}
\item \TT{\EIf}
\item \T{\Done}
\item \T{\texttt{pheromone\_matrix} = \texttt{evaporate(pheromone\_matrix)}}
\item \Done
\end{ifpseudo}
\caption{Inurri-kolonien algoritmoaren sasikodea}
\end{ifalgorithm}



Aurreko atalaren adibidean inurri guztiek era finkoan eguneratzen zuten feromona eredua; edonola era, aukera hau ez da bakarra. Ereduaren eguneraketa diseinatzean bi gauza hartu behar ditugu aintzat. Alde batetik, zein inurriak eguneratuko du eredua; bestetik, nola eredua nola eguneratu. Lehenengo puntuari dagokionez, hiru aukera ditugu:

\begin{itemize}
\item \textbf{Inurri guztiak} - Soluzio bat eraikitzen den bakoitzean, erabilitako elementuen feromona kopurua handitu.
\item \textbf{Iterazioko soluziorik onena} - Behin koloniako inurri guztiek beraien soluzioak eraiki, guztietatik zein den onena identifikatu eta bakarrik soluzio hori eraikitzeko erabili diren elementuak eguneratu.
\item \textbf{Algoritmoak topatutako soluziorik onena} - Bilaketa areagotu nahi badugu, iterazioko soluziorik onena erabili beharrean, aurreko iterazioetan eraiki den soluziorik onena erabil dezakegu.
\end{itemize}

Adibidean feromona lorratzak eguneratzean inurri guztien ekarpena berdina zen; alabaina, beste zenbait aukera ditugu:

\begin{itemize}
\item \textbf{Soluzioaren ebaluazioaren arabera} - Naturan inurriak utzitako lorratzaren intentsitatea janari iturriaren kalitatearen araberakoa da; era berean, gure algoritmoan soluzioaren ebaluazioa erabil dezakegu soluzio onenen ekarpena handiagoa izan dadin.
\item \textbf{Inurrien ranking-aren arabera} - Ebaluazio funtzioaren magnitudea problemaren eta instantziaren araberakoa da\footnote{TSP-an, adibidez, ez da berdina 10 herri Gipuzkoan izatea edo 100 herri Europan zehar banatuta}. Eskala arazo hauek saihesteko zuzenean ebaluazioa erabili beharrean, soluzioen ranking-a erabil dezakegu; era honetan soluziorik onenaren ekarpena azkenarena baino handiago izango da, baina lehenengo eta azkenaren soluzioen arteko diferentziak murriztuta egongo dira.
\end{itemize}

\subsection{Particle Swarm Optimization}

Intsektu sozialen portaera \textit{swarm} adimenaren adibide tipikoak dira, baina ez dira bakarrak; animali handiagotan ere inspirazioa bila daiteke. Esate baterako, txori-saldotan ehunaka indibiduo batera mugitzen dira beraien arteak talka egin gabe. Multzo horietan ez dago indibiduo bat taldea kontrolatzen duena, txori bakoitzak bere inguruneko txorien portaera aztertzen du, berea egokitzeko. Era horretan, arau sinple batzuk (txori batetik gertuegi banago, urrundu egiten naiz, adibidez) besterik ez dira behar sistema osoa antolatzeko.

\begin{figure}[t]
\centering
\includegraphics[width=0.6\linewidth]{./Irudiak/PSO_1}
\caption{PSO algoritmoak erabiltzen dituen partikulen adibidea. Partikula bakoitzak bere kokapena $(x_i,y_i)$ eta bere abiadura ($\mathbf{v}_i$) du}\label{fig:PSO}
\end{figure}


\textit{Particle Swarm Optimization} (PSO) algoritmoaren inspirazioa animali-talde hauen mugimenduak dira. Gure sisteman bilaketa espazioan mugitzen diren zenbait partikula izango ditugu; partikula bakoitzak kokapen eta abiadura konkretuak izango dituzte. Partikularen kokapenak berak partikulari dagokion soluzioa izango da; abiadurak, hurrengo iterazioan nora mugituko den esango digu. Ikus dezagun adibide sinple bat. \ref{fig:PSO} irudian bi dimentsioko bilaketa espazio bat adierazten da. Bertan, bost partikula ditugu; bakoitzak problemarako soluzio bat adierazten du. Adibidez, $p_1$ partikulak $X=x_1; Y=y_1$ soluzioa adierazten du.

PSO algoritmoan partikulek bilaketa espazioa aztertzen dute, posizio batetik bestera mugituz. Beraz, iterazio bakoitzean partikula guztien kokapena eguneratzen da, beraien abiadura erabiliz. Partikulen abiadurak finko mantentzen baditugu, partikula guztiak infinitura joango dira. Hori ez gertatzeko, iterazio bakoitzean abiadura ere eguneratu behar da; eguneraketa honetan datza, hain zuzen, algoritmoaren gakoa. PSO \textit{swarm intelligence}-ko algoritmo bat denez, indibiduoen arteko (partikulen arteko, kasu honetan) komunikazioa ezinbestekoa da. Komunikazio hau abiadura eguneratze-prozesuan erabiltzen da, partikula bakoitzak bere abiadura eguneratzeko ingurunean dauden partikulak aintzat hartuko baititu. 

Beraz, algoritmoa aplikatzeko ingurune kontzeptua definitu behar dugu. PSO-n, ingurune kontzeptua ez da bilaketa lokalean erabiltzen den berdina, partikula bakoitzaren ingurunea aurrez aurretik ezarritakoa baita; ez du partikularen kokapenarekin zerikusirik, alegia. Partikula bakoitzaren ingurunea grafo baten bidez adieraz daiteke, non bi partikula konektatuta dauden baldin eta bakarrik baldin bata bestearen ingurunean badaude. Lehenengo hurbilketa grafo osoa erabiltzea da, hots, edozein partikularen ingurunean beste gainontzeko partikula guztiak egongo dira; grafo osoa erabili beharrean, beste zenbait topologia ere erabil daitezke (eraztunak, izarrak, toroideak, etab.).

Partikula baten abiadura eguneratzeko bi elementu erabiltzen dira. Alde batetik, partikula horrek bisitatu duen soluziorik onena, hau da, bere \zkk arrakasta pertsonala\skk. Soluzio honi ingelesez \textit{personal best} deritzo, eta $\mathbf{p}_i$ sinboloaren bidez adieraziko dugu. Bestaldetik, ingurunean dauden partikulen arrakasta ere kontutan hartzen da, partikularen ingurunean dauden beste partikulek lortu duten soluziorik onena, alegia. Soluzio honi ingelesez \textit{global best}\footnote{Ingurunea definitzeko grafo osoa erabiltzen ez bada, partikula baten ingurunean lortutako soluziorik onenari \textit{global best} baino \textit{local best} esaten zaio} deritzo, eta $\mathbf{p}_g$ sinboloaren bidez adieraziko dugu.

Hau dena kontutan hartuta, $i$. partikulak $t$ iterazioan erabiliko duen abiadura aurreko iterazioan erabilitakoa ondoko ekuazioaren bidez kalkulatuko dugu:

\begin{align*}
\mathbf{v}_i(t) = \mathbf{v}_i(t-1) + \rho_1 C_1 [\mathbf{p}_i - \mathbf{x}_i(t-1)] + \rho_2 C_2 [\mathbf{p}_g - \mathbf{x}_i(t-1)]
\end{align*}

Ekuazioan bi konstante ditugu, $C_1$ eta $C_2$; balio hauek partikulak eta ingurunean topatutako soluzioen eragina kontrolatzeko erabiltze dira. Konstante hauetaz gain, bi ausazko aldagai ditugu, $\rho_1$ eta $\rho_2$. Bi aldagai hauek ausazko balioak hartzen dituzte $[0,1]$ tartean. 

Lortutako abiadura bektore bat da. Arazoak saihesteko, bektore horren modulua mugatuta dago, aurrez aurretik abiadura maximoa ezarriz. Kalkulatutako abiaduraren modulua handiagoa bada, balio maximora eramaten da.

Behin uneko iterazioaren abiadura kalkulatuta, abiadura partikularen kokapena eguneratzeko erabiltzen da:

\begin{align*}
\mathbf{x}_i(t) = \mathbf{x}_i(t-1) + \mathbf{v}_i(t-1)
\end{align*}

Iterazio bakoitzean lortutako soluzioak ebaluatu eta, beharrezkoa bada, partikulen \textit{personal} eta \textit{global best} eguneratu behar dira. Pasu guzti hauek \ref{alg:pso} algoritmoan biltzen dira.


\begin{ifalgorithm}[t]\label{alg:pso}
\begin{ifpseudo}{PSO algoritmoa}
\item \In\ \texttt{initialize\_position}, \texttt{initialize\_velocity}, \texttt{update\_velocity}, \texttt{evaluate} eta \texttt{stop\_criterion} operadoreak
\item \In\ \texttt{num\_particles} partikula kopurua
\item \Out\ \texttt{opt\_solution}
\item \texttt{gbest = p[1]}
\item \textbf{for each} \texttt{i} \textbf{in} \texttt{1:num\_particles} \Do
\item \T{\texttt{p[i]=initialize\_position(i)}}
\item \T{\texttt{v[i]=initialize\_velocity(i)}}
\item \T{\texttt{pbest[i]=p[i]}}
\item \T{\If \texttt{evaluate(p[i])<evaluate(gbest)}}
\item \TT{\texttt{gbest = p[i]}}
\item \T{\EIf}
\item \Done
\item \While !\texttt{stop\_criterion()} \Do
\item \T{\textbf{for each} \texttt{i} \textbf{in} \texttt{particle\_set}}
\item \T{\Do}
\item \TT{\texttt{v[i]} = update\_velocity(i)}
\item \TT{\texttt{p[i] = p[i] + v[i]}}
\item \TT{\If \texttt{evaluate(p[i])<evaluate(pbest[i])}}
\item \TTT{\texttt{pbest[i]}=\texttt{p[i]}}
\item \TT{\EIf}
\item \TT{\If \texttt{evaluate(p[i])<evaluate(gbest)}}
\item \TTT{\texttt{gbest}=\texttt{p[i]}}
\item \TT{\EIf}
\item \T{\Done}
\item \Done
\item \texttt{opt\_solution = gbest}
\end{ifpseudo}
\caption{\textit{Particle Swarm Optimization} algoritmoaren sasikodea}
\end{ifalgorithm}




%\subsection{Oinarrizko Egiturak}
%\subsubsection{Soluzioen errepresentazioa: Indibiduoak}
%\subsubsection{Populazioaren hasieraketa}
%\subsubsection{Aukeraketa irizpideak}
%Roulette-Wheel, Tournament, Rank-Based Selection...
%\subsubsection{Soluzioen berrien sorrera prozedurak}
%Algoritmoaren menpekoa, GAk mutation and crossover, EDAk learn a model, and sample solutions.
%\subsubsection{Gelditze Irizpideak}


\bibliographystyle{plain}
\bibliography{references}

\end{document}