% !TeX spellcheck = eu_ES
\documentclass[eu]{ifirak}

\usepackage{amsmath,latexsym,amssymb,natbib}
\usepackage{listings}
\usepackage{ifcommands,subfigure}
\usepackage[T1]{fontenc}
\usepackage{tcolorbox}

\newcommand{\zkk}{\guillemotleft}
\newcommand{\skk}{\guillemotright}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\eng}[1]{\textit{#1}}
\newcommand{\hgl}[1]{\zkk #1\skk\ }

\begin{document}
\ikasturtea{2014/2015}
\irakasgaia{Bilaketa Heuristikoak}
\title{BHLN: Populazioan oinarritutako algoritmoak}
\date{}
\irakaslea{Borja Calvo, Usue Mori}
\author{Borja Calvo, Usue Mori}


\tel{943 01 50 13}
\mail{borja.calvo@ehu.es}

<<echo=FALSE , purl=FALSE>>=
## This code is for wrapping long outputs
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
knitr::opts_chunk$set(linewidth=100) 
knit_theme$set("earendel")
@


\maketitle

\begin{abstract}
Aurreko kapituluan soluzio bakarrean oinarritzen diren zenbait algoritmo ikusi ditugu. Algoritmo hauek oso portaera ezberdina izan arren, badute ezaugarri komun bat: bilaketa prozesua soluzio batetik bestera mugitzen da, soluzioak banan-banan aztertuz. Ezaugarri hau dela eta, algoritmo hauek oso algoritmo egokiak dira bilaketa espazioaren eskualde interesgarriak arakatzeko --bilaketa areagotzeko, alegia--. Alabaina, hainbat kasutan emaitza onak lortzeko bilaketa dibertsifikatzea ere beharrezkoa da. Hau honela izanik, bilaketa lokalean oinarritzen diren algoritmo batzuk dibertsifikatzeko zenbait estrategia darabilte, adibide nabarmenena tabu bilaketaren epe-luzeko memoria izanik.

Kapitulu honetan soluzioen banan-banakako azterketa alde batera utzita, soluzio multzoak erabiltzeari ekingo diogu, horixe baita, hain justu, populazioetan oinarritzen diren algoritmoen filosofia. Algoritmoaren pausu bakoitzean, soluzio bakar bat izan beharrean, soluzio multzo bat izango dugu. Testuinguru batzuetan soluzio multzo honi \hgl{soluzio-populazioa} deritzo eta, hortik, algoritmo hauen izena. Algoritmo hauekin, bilaketa prozesuan zehar, soluzio multzo hori aldatuz joango da helburu funtzioaren gidaritzapean, gelditze irizpide bat bete arte.

Oro har, populazioan oinarritutako algoritmoak bi multzotan banatu ditzakegu: algoritmo ebolutiboak eta \eng{swarm intelligence}-an oinarritutakoak. Lehenengo kategoriako algoritmoek, populazioa eboluzionarazten dute, teknika ezberdinak erabiliz, honek geroz eta soluzio hobeak izan ditzan. Adibiderik ezagunenak algoritmo genetikoak dira. Bigarren motako algoritmoak, berriz, zenbait animalien portaeran oinarritzen dira. Hauen arteko adibiderik ezagunenak, esate baterako, inurriek, janaria eta inurritegiaren arteko distantziarik motzena topatzeko darabilten mekanismoa imitatzen du.

Kapitulua bi zatitan banaturik dago, bakoitza populazioan oinarritutako algoritmo mota bati eskeinita. Lehenengo zatian, algoritmo ebolutiboen eskema orokorra ikusi ondoren, algoritmo genetikoak \cite{holland1975} eta EDAk \cite{larranaga2002,lozano2006} aurkeztuko dira. Bigarren zatian ordea, \eng{swarm intelligence} \cite{blum2008} arloan proposaturiko bi algoritmo aztertuko dira.
\end{abstract}


\section{Algoritmo Ebolutiboak}\label{sec:ebolutiboak}
1859. urtean Charles R. Darwinek \eng{On the Origin of the Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life} liburua argitaratu zuen. Tituluak berak adierazten duen bezala, liburu honetan Darwinek hautespen naturalaren teoria aurkeztu zuen. 

Eboluzioaren teoriak dioenez, belaunalditik belaunaldira zenbait mekanismoen bidez --mutazioak, esate baterako-- aldaketak ematen dira espezieetan. Aldaketa hauetako batzuei esker indibiduoak hobeto egokitzen dira haien ingurunera eta, ondorioz, bizirik mantentzeko eta, batez ere, ugaltzeko probabilitateak handitzen dira. Era berean, noski, aldaketa batzuk kaltegarriak izan daitezke, bizitzeko aukerak murriztuz. Kontutan hartuz aipatutako aldaketak heredatu egiten direla, ezaugarri onak generazioz generazio mantentzen dira; kaltegarriak direnek, ostera, galtzeko joera izaten dute. Prozesu honen bidez, espezieak haien ingurunera geroz eta hobeto egokitzeko gai dira.

Hirurogeigarren hamarkadan ikertzaileek Darwinen lana inspiraziotzat hartu zuten optimizazio metahuristikoak diseinatzeko eta geroztik, konputazio ebolutiboa konputazio zientzien arlo bereizia bilakatu da. Atal honetan bi algoritmo mota aztertuko ditugu, algoritmo genetiko klasikoak \cite{holland1975} eta EDAk (\eng{Estimation of Distribution Algorithms}) \cite{larranaga2002, lozano2006}.


\begin{figure}[t]
\centering
\includegraphics[height=0.2\textheight]{./Irudiak/AEB}
\caption{Algoritmo ebolutiboen eskema orokorra}
\label{fig:alg.evol}
\end{figure}


Diferentziak diferentzia, algoritmo ebolutibo guztiek \ref{fig:alg.evol} irudiko eskema orokorra jarraitzen dute. Eskema orokor honetan, bi dira giltzarri diren elementuak: soluzio berrien sorkuntza eta soluzioen hautespena. Algoritmoaren sarrera-puntua hasierako populazioa izango da; populazio horretatik abiatuz, algoritmoa begizta nagusian sartzen da, non bi pausu txandakatzen diren. Lehenik, uneko populazioko soluzioetatik abiatuz, soluzio berri multzo bat sortuko da. Ondoren, soluzio berri hauek eta uneko populazioko soluzioak kontutan hartuz, naturan bezala, hurrengo belaunaldiara pasatzeko soluzio onak aukeratuko ditugu, eta populazio berri bat sortuko dugu. Begizta nagusia etengabekoa denez, zenbait irizpide ezberdin proposatu dira algoritmoa amaitutzat emateko.

Hurrengo atalean, algoritmo orokor honen urratsak sakonago aztertuko ditugu. Hasteko, algoritmo ebolutibo guztietan antzerakoak diren pausuak azalduko ditugu eta ondoren, bi algoritmo ezberdinen xehetasunetan jarriko dugu arreta. 

\subsection{Urrats orokorrak}

Ondorengo ataletan ikusiko ditugun algoritmoen arteko diferentzia nagusia soluzio berrien sorkuntzan datza. Gaionontzeko urratsak era antzekoan burutzen dira algoritmo ezberdinetan eta horiei buruz hitz egingo dugu atal honetan.

\subsubsection{Populazioaren hasieraketa}

Nahiz eta askotan garrantzi gutxi eman, hasierako populazioa da algoritmoaren abia-puntua eta, hortaz, bere sorkuntza oso pausu garrantzitsua da, eragin handia izaten duelako algoritmoak lortutako azken emaitzan. 

Algoritmoen xedea soluzio onak topatzea izanda, pentsa dezakegu hasierako populazio on bat soluzio onez osatuta egon behar dela; alabaina, dibertsitatea soluzioen kalitatea bezain garrantzitsua da. Nahiz eta onak izan, populazioa oso soluzio antzerakoez osatuta badago, populazioaren eboluzioa oso zaila izango da eta algoritmoak azkarregi konbergitu dezake optimoa ez den soluzio batera. 

Hortaz, hasierako populazioa sortzean bi aspektu izan behar ditugu kontutan: kalitatea eta dibertsitatea. Kasu gehienetan ausazko hasieraketa erabiltzen da lehen populazioa sortzeko, hau da, ausazko soluzioak sortzen dira populazioa osatu arte. Estrategia hau erabiliz dibertsitate handiko populazioa sortuko dugu, baina kalitatea ez da handia izango. 

Ausazko laginketak lortutakoa baina dibertsitate handiagoa bermatu nahi badugu, --sasiausazko-- prozedura batzuk erabil ditzakegu. Hori dela eta, proposatu dira beste prozedura batzuk populazioak sasi-ausaz sortzeko dibertsitatea maximizatuz. Esate baterako, dibertsifikazio sekuentziala aplikatu dezakegu, zeinak soluzio berri bat onartzen duen soilik populazioan dauden soluzioekiko distantzia minimo batera badago. Adibide moduan, demagun 25 tamainako bektore bitarren 10 tamainako populazio bat sortu nahi dugula. Dibertsitatea bermatzeko populazioko soluzioen arteko Hamming distantzia minimoak 10-ekoa izan behar duela inposa dezakegu. 

Jarraian dagoen kodeak horrelako populazioak sortzen ditu. Lehenik, Hamming distantzia neurtzeko eta ausazko bektore bitarrak sortzeko funtzioak sortzen ditugu:

<<ham_dis , prompt=TRUE, echo=-1 , message=FALSE , cache=TRUE>>=
set.seed(1)
hamm.distance <- function (v1 , v2){
  d <- sum(v1!=v2)
  return(d)
}

rnd.binary <- function(n){
  return (runif(n) > 0.5)
}
@

 Gero, soluzioak ausaz sortzen ditugu eta, distantzia minimoko baldintza bete ezean, deusestatu egiten ditugu; prozedura nahi ditugun soluzio kopurua lortu arte exekutatzen da. 

<<seq_divers , prompt=TRUE, message=FALSE, cache=TRUE>>=
sol.size <- 25
pop.size <- 10
min.distance <- 10
population <- list(rnd.binary (sol.size))
while (length(population) < pop.size){
  new.sol <- rnd.binary(sol.size)
  distances <- lapply(population , FUN = function(x) hamm.distance (x,new.sol))  
  if (min(unlist(distances)) <= min.distance)
    population[[length(population) + 1]] <- new.sol
}

@


Prozedura hau ez da batere eraginkorra, zenbait kasutan soluzio asko aztertu beharko baititugu populazioa osatu arte. Hala, beste alternatiba eraginkorrago bat dibertsifikazio paraleloa da. Kasu honetan bilaketa espazioa zatitu egiten da eta azpi-espazio bakoitzetik ausazko soluzio bat erauzten da.

Orain arte dibertsitateari bakarrik erreparatu diogu. Aldiz, hasierako popuazioaren kalitatea hobetu nahi izanez gero, hasieraketa heuristikoak erabil daitezke. Hau lortzeko era sinple bat, GRASP algoritmoetan ausazko soluzioak sortzeko erabiltzen diren prozedurak erabiltzea da. Ondoko lerroetan Bavierako hirien TSP problemarako adibide bat ikus dezakegu. Lehenik, problema kargatuko dugu.

<<heur_init_1 , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE, cache=TRUE>>=
library("metaheuR")
url <- system.file("bays29.xml.zip" , package = "metaheuR")
cost.matrix <- tsplib.parser(url)
@

Orain, \code{tsp.greedy} funtzioan oinarrituta ausazko soluzio onak sortzeko funtzio bat definitzen dugu.

<<heur_init_2 , prompt=TRUE, message=FALSE, cache=TRUE>>=
rnd.sol <- function(cl.size = 5){
  tsp.greedy(cmatrix = cost.matrix , cl.size = cl.size)
}
@

\code{tsp.greedy} funtzioak TSP-rako algoritmo eraikitzaile bat inplementatzen du; pausu bakoitzean, uneko hiritik zein hirira mugituko garen erabakitzen da. Hiria aukeratzeko gertuen dauden \code{cl.size} hirietatik --5, gure kasuan-- bat ausaz aukeratzen da. Populazioa sortzeko funtzio hau erabiliko dugu.

<<heur_init_3 , prompt=TRUE, message=FALSE, cache=TRUE>>=
pop.size <- 25
population <- lapply (1:pop.size , FUN = function(x) rnd.sol())
@

Hautagaien zerrenda problemaren tamainaraino handitzen badugu, pausu bakoitzean aukera guztietatik bat ausaz hartuko dugu, hots, guztiz ausazkoak diren soluzioak sortuko ditugu. Hau eginda populazioaren kalitatea goiko kodearekin lortutakoa baino txarragoa izango da:

<<heur_init_4 , prompt=TRUE, message=FALSE, cache=TRUE>>=
rnd.population <- lapply (1:pop.size , 
                          FUN = function(x) rnd.sol(cl.size = ncol(cost.matrix)))
tsp <- tsp.problem(cost.matrix)
eval.heur <- unlist(lapply(population , FUN = tsp$evaluate))
eval.rnd <- unlist(lapply(rnd.population , FUN = tsp$evaluate))
@


Bi populazioen ebaluazioak \eng{boxplot} baten bidez aldera dezakegu.

<<plot_heur_vs_rnd , echo = -1, cache=TRUE , warning=FALSE, prompt=TRUE , cache=TRUE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=8 , fig.height=4>>=
library("ggplot2")
df <- rbind (data.frame (Method = "Heuristic" , Evaluation = eval.heur) , 
             data.frame (Method = "Random" , Evaluation = eval.rnd))
ggplot(df , aes(x = Method , y = Evaluation)) + geom_boxplot()
@

\begin{figure}[t]
\centering
\includegraphics[height=0.33\textheight]{./Irudiak/plot_heur_vs_rnd-1}
\caption{Ausazko hasieraketa eta hasieraketa heuristikoaren arteko konparaketa. Y ardatzak metodo bakoitzarekin sortutako soluzioen \eng{fitness}-a adierazten du.}\label{fig:heur_vs_rnd_init_pop}
\end{figure}

\ref{fig:heur_vs_rnd_init_pop} irudiak lortutako emaitzak erakusten ditu; argi eta garbi ikus daiteke heuristikoa erabiliz sortutako soluzioak hobeak direla.

Soluzioak sortzeko metodoak ez ezik, populazioaren tamainak ere badu eragin handia azken emaitzan. Izan ere, populazioaren tamaina egokitu behar den oso parametro garrantzitsua izango da. Populazioak txikiegiak badira, dibertsitatea mantentzea oso zaila izango da eta, hortaz, belaunaldi gutxitan algoritmoa konbergituko da. Beste aldetik, populazioa handiegia bada, konbergentzia abiadura motelduko da baina kostu konputazionala handituko da; hurrengo atalean adibide baten bidez ikusiko dugu hau. Ez dago irizpide finkorik tamaina ezartzeko, problema bakoitzeko egokitu beharko da. Edonola ere, irizpide orokor gisa esan dezakegu populazio azkar konbergitzen badu --hots, soluzioen arteko distantzia azkar txikitzen bada--, konponbidea populazioare tamaina handitzea izan daitekeela. 


\subsubsection{Hautespena}

Algoritmo ebolutibotan populazioaren murriztea urrats garrantzitsua da, populazioaren eboluzioa kontrolatzen duen prozesua baita. Orokorrean, populazioan dauden soluziorik onenak hautatzea interesatuko zaigu eta hori da, hain zuzen, gehien erabiltzen den hautespena; bakarrik soluziorik onenak aukeratzen dituenez, hautespen honi \zkk elitista\skk\ deritzo. Soluzio onak aukeratzea garrantzitsua da baina, dibertsitatea mantentzearren, tarteka soluzio txarrak ere sartzea komenigarria izan daiteke. Hau zuzenea egiterik egon arren, badaude beste hautespen metodoak era probabilistikoan egiten dutenak.

Erruleta-hautespena,  (\textit{Roulette Wheel selection}, ingelesez) deritzon estrategian soluzioak erruleta batean kokatzen dira; soluzio bakoitzari dagokion erruletaren zatia bere ebaluazioarekiko proportzionala izango da. \ref{fig:roulette} irudian ikus daitekeen bezala, erruleta jaurtitzen den bakoitzean indibiduo bat hautatzen da; hautatua izateko probabilitatea erruleta zatiaren tamaina eta, hortaz, indibiduoen ebaluazioarekiko proportzionala da. 

Indibiduo bat baino gehiago aukeratu behar baldin badugu, behar ditugun erruletaren jaurtiketak egin ditzakegu. Alabaina, honek alborapenak sor ditzake; efektu hau saihesteko erruletan puntu bakar bat markatu beharrean (gezia, \ref{fig:roulette} irudian), behar ditugun puntuak finkatu ahal ditugu. Era honetan, jaurtiketa bakar batekin nahikoa da behar ditugun indibiduo guztiak hautatzeko. Teknika hau populazioa murrizteko zein indibiduoak gurutzatzeko hautespenean erabil daiteke.

\eng{Fitness}aren magnitudea problema eta, are gehiago, instantzien araberakoa da. Hori dela eta, probabilitateak zuzenean helburu funtzioaren balioarekiko proportzionalak badira, oso distribuzio radikalak izan ditzakegu. Arazo hau ekiditeko, helburu funtzioaren balioa zuzenean erabili beharrean soluzioen ranking-a erabili ahal da.

\begin{figure}[t]
\centering
\includegraphics[width=0.7\linewidth]{./Irudiak/roulette}
\caption{Erruleta-hautespena. Indibiduo bakoitzaren erruletaren zatia bere ebaluazioarekiko proportzionala da. Erruleta jaurtitzen den bakoitzean indibiduo bat aukeratzen da, bere \eng{fitness}arekiko proportzionala den probabilitatearekin. Adibidean, 2. indibiduoa da hautatu dena.}
\label{fig:roulette}
\end{figure}

Beste hautespen probabilistiko bat Lehiaketa-hautespena da. Estrategia honetan hautespena bi pausutan egiten da. Lehenengo urratsean indibiduo guztietatik azpi-multzo bat aukeratzen da, guztiz ausaz (ebaluazioa kontutan hartu barik). Ondoren, aukeratu ditugun indibiduoetatik onena hautatzen dugu. Azpi-multzoa ausaz aukeratzen denez, bertan oso soluzio txarrak leudeke eta, hortaz, nahiz eta onena hautatu, soluzioa txarra izan daiteke.


\subsubsection{Gelditze Irizpideak}

Lehen apiatu bezala, algoritmo ebolutioben begizta nagusia amaigabea da eta, beraz, algoritmoa gelditzeko irizpideren bat ezarri behar dugu, bilaketari amaiera emateko. Hurbilketarik sinpleena irizpide estatikoak erabiltzea da, hala nola, denbora maximoa ezartzea, ebaluazioak mugatzea, etab.

Gelditzeko irizpideak dinamikoak ere izan daitezke, eboluzioaren prozesuari erreparatzen badiogu. Balunaldiz balaundi populazioan dauden soluzioak geroz eta hobeak dira eta, aldi berean, populazioaren dibertsitatea murrizten da. Beste era batean esanda, populazioko soluzioek soluzio bakar batera konbergitzeko joera dute.

Hori gertatzen denean eboluzioa moteltzen denez, popluzaioaren dibertsitatea gelditzeko irizpide gisa erabili ahal da. Dibertsitatea soluzioei zein beraien \eng{fitness}-ari erreparatuz neur daiteke. Esate baterako, soluzioen arteko distatzia neurtzerik badago, indibiduoen arteko bataz besteko distantzia minimo bat ezar dezakegu.

\subsubsection{Algoritmo Genetikoak}

Atal honetan algoritmo genetikotan \cite{holland1975} soluzio berriak algoritmo genetikoetan nola sortzen diren ikusiko dugu. Algoritmo hauek naturan espeziekin gertatzen dena imitatzen dute. Era honetan, zenbait paralelismo ezar daitezke:

\begin{itemize}
\item Espezieen indibiduoak = Problemaren soluzioak
\item Indibiduoen egokitasuna --\eng{fitness}-a, alegia-- = Soluzioaren ebaluazioa
\item Espeziearen populazioa = Soluzio multzoa
\item Ugalketa = Soluzio berrien sorkuntza
\end{itemize}

Beraz, algoritmo genetikoetan soluzio berriak sortzeko indibiduen ugalketan oinarrituko gara.  Ugalketa prozesuaren xedea zenbait indibiduo emanda --bi, normalean--, indibiduo gehiago sortzea da. Ohikoena prozesu hau bi pausutan banatzea da: soluzioen gurutzaketa eta mutazioa. Lehenaren helburua \hgl{guraso}-soluzioek duten ezaugarriak soluzio berriei pasatzea da. Bigarrenarena, berriz, sortutako soluzioetan ezaugarri berriak sartzea da. Jarraian soluzioak maneiatzeko bi operadore hauek aztertuko ditugu.

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\linewidth]{./Irudiak/point_crossover}
\caption{Gurutzatze-operadoreak bektoreen bidezko kodeketarekin erabiltzeko}
\label{fig:point_crossover}
\end{figure}

\subsubsection{Gurutzaketa} 

Bi soluzio --edo gehiago-- gurutzatzen ditugunean euren propietateak sortutako soluzioei transmititzea da gure helburua. Hori lortzeko, soluzioei operadore mota berezi bat aplikatuko diegu, \hgl{gurutze-operadorea} --\eng{crossover}, ingelesez--. Operadore honek soluzioen kodeketarekin dihardu eta, beraz, operadorea hautatzean soluzioak nola adieratzen dugun aintzat hartu beharko dugu. 

Badaude zenbait operadore kodeketa klasikoekin erabil daitezkeenak. Ezagunena puntu bakarreko gurutzatzea -- \eng{one-point crossover}, ingelesez -- deritzona da. Demagun soluzioak bektoreen bidez kodetzen ditugula. Bi soluzio, $s_1$ eta $s_2$ parametro gisa hartuz, operadore honek beste bi soluzio berri sortzen ditu. Horretarako, lehenik eta behin, ausazko posizio bat $i$ aukeratu behar da. Gero, lehenengo soluzio berria $s_1$ soluziotik lehenengo $i$ elementuak eta $s_2$ soluziotik beste gainontzekoak kopiatuz sortuko dugu. Era berean, bigarren soluzio berria $s_2$-tik lehenengo elementuak eta besteak $s_1$-etik kopiatuz sortuko dugu.  \ref{fig:point_crossover} irudiaren ezkerraldean adibide bat ikus daiteke. Irudiak ideia nola orokor daitekeen ere erakusten du, puntu bakar bat erabili beharrean bi, hiru, etab. puntu erabiliz.

Operadore hau \code{metaheuR} liburutegian inplementaturik dago, \code{k.point.crossover} funtzioan. Ikus ditzagun adibide batzuk:

<<k_point_cross , prompt=TRUE, echo=-1 , message=FALSE, cache=TRUE>>=
set.seed(666)
A.sol <- rep("A" , 10)
B.sol <- rep("B" , 10)
A.sol
B.sol
k.point.crossover(A.sol , B.sol , 1)
k.point.crossover(A.sol , B.sol , 5)
k.point.crossover(A.sol , B.sol , 20)
@

Azken adibidean ikus daitekeen bezala, $n$ tamainako bektore bat izanik gehienez $n-1$ puntu erabil ditzakegu operadore honetan; edonola ere, balio handiagoa erabiltzen badugu funtzioak abisu bat emango du eta parametroa bere balio maximoan ezarriko du. Balio maximoarekin jatorrizko soluzioen elementuak tartekatuko dira; operadore honi \eng{uniform crossover} deritzo.

Erabiliko dugun puntu kopurua eragin handia izan dezake algoritmoaren performantzian eta, hortaz, egokitu behar den algoritmoaren parametrotzat hartu beharko genuke. 

Ikusitako operadorea nahiko orokorra da, ia edozen bektoreari aplikatu ahal baitzaio. Hala eta guztiz ere, kodeketa batzuetan operadore bereziak erabil daitezke\cite{gwiazda2006}. Esate baterako, bektore errealak baldin baditugu, bi bektore harturik era ezberdinetan konbina daitezke; adibidez, bataz bestekoa kalkulatuz. Ikus dezagun operadore hau nola inplementa daitekeen R-n:

<<mean_cross , prompt=TRUE, message=FALSE, cache=TRUE>>=
mean.crossover <- function (sol1 , sol2){
  new.solution <- (sol1 + sol2) / 2
  return(new.solution)
}

s1 <- runif(10)
s2 <- runif(10)
s1
s2
mean.crossover(s1 , s2)
@

Permutazioak ere bektoreak dira baina, kasu honetan, \eng{k point crossover} operadorea ezin da erabili, permutazioetan ditugun murrizketak direla eta. Hortaz, permutazioak gurutatzeko operadore bereziak behar ditugu. Aukera asko izan arren \cite{talbi2009}, hemen puntu bakarreko gurutzatze operadorearen baliokidea ikusiko dugu. Lehenik eta behin, ikus dezagun zergatik puntu bakarreko operadorea ezin da zuzenean aplikatu permutazioei. Izan bitez bi permutazio, $s_1 = 12345678$ eta $s_2=87654321$, eta gurutzatze puntu bat, $i=3$. Lehenengo soluzio berria lortzeko $s_1$ soluziotik lehendabiziko hiru posizioak kopiatuko ditugu, hau da, $123$, eta besteak $s_2$-tik, hots, $54321$. Hortaz, lortutako soluzioa $s^\prime = 12354321$ izango zen baina, zoritxarrez, hau ez da permutazio bat.

Nola saihestu daiteke arazo hau? Soluzio sinple bat hauxe da: lehenengo posizioak zuzenean soluzio batetik kopiatzea; besteak zuzenean beste soluziotik kopiatu beharrean, ordena bakarrik erabiliko dugu. Hau da, soluzio berria sortzeko $s_1$-etik lehenengo 3 elementuak kopiatuko ditugu, $123$, eta falta direnak, $45678$, $s_2$-an agertzen den ordenean kopiatuko ditugu, hots, $87654$. Emaitza, beraz, $s^\prime = 12387654$ izango da eta beraz, orain bai, permutazio bat lortu dugu. Era berean, beste soluzio berri bat sor daiteke $s_2$-tik lehenengo hiru posizioak kopiatuz ($876$) eta beste gainontzeko guztiak $s_1$-an duten ordenean kopiatuz ($12345$); beste soluzioa, beraz, $87612345$ izango da. Operadore honi \hgl{Order crossover} deritzo eta \code{metaheuR} liburutegian inplementaturik dago, \code{order.crossover} funtzioan \footnote{Funtzio honetan inplementatuta dagoena \eng{2-point crossover} operadorea da. Hau da, bi puntu erabiltzen dira eta, soluzioak eraikitzeko, bi puntuen artean dagoena soluzio batetik kopiatu ondore, beste gainontzeko elementuak beste soluzioan duden ordenean erabiltzen dira.}.

<<order_cross , prompt=TRUE, message=FALSE , echo=-1 , warning=FALSE, cache=TRUE>>=
set.seed(5)
sol1 <- random.permutation(10)
sol2 <- identity.permutation(10)
as.numeric(sol1)
as.numeric(sol2)
new.solutions <- order.crossover(sol1 , sol2)
as.numeric(new.solutions[[1]])
as.numeric(new.solutions[[2]])
@


\subsubsection{Mutazioa} 

Naturan bezala, gure populazioa eboluzionatzeko dibertsitatea garrantzitsua da. Hori dela eta, behin soluzio berriak lortuta gurutzatze-operadorearen bidez, soluzio hauetan ausazko aldaketak eragin ohi da; aldaketa hauek mutazio operadorearen bidez sortzen dira. 

Mutazioaren kontzeptua ILS algoritmoko perturbazioaren antzerakoa da; izan ere, operadore berdinak erabil daitezke. Esate baterako, permutazio bat mutatzeko ausazko trukaketak erabil ditzakegu. ILS-an bezala, algoritmoa diseinatzean erabaki behar dugu zenbat aldaketak sortuko ditugun -- adibidean, zenbat posizio trukatuko ditugun --.

Mutazio operadorea aukeratzean --eta baita diseinatzean ere-- hainbat gauza hartu behar dira kontuan. Hasteko, soluzioen bideragarritasuna mantentzea garrantzitsua da, hau da, mutazio operadorea bideragarria den soluzio bati aplikatuz gero, emaitzak soluzio bideragarria izan behako luke. Bestaldetik, bilaketa prozesua soluzio bideragarrien espazio osoa arakatzeko gaitasuna izan beharko luke eta hori bermatzeko mutazio operadoreak edozein soluzio sortzeko gai izan behar du. Hau da, edozein soluzio hartuta mutazio operadorearen bidez beste edozein soluzioa sortzeak posible izan beharko luke. Amaitzeko, lokaltasuna ere mantendu behar da --alegia, mutazioak eragindako aldaketa txikia izan behar da--, bestela gurasoengandik heredatutako ezaugarriak galdu egingo dira.

Mutazio operadorea era probabilistikoan aplikatzen da; hau da, ez zaie soluzio guztiei aplikatzen. Hortaz, mutazioari lotutako bi parametro izango ditugu: mutazio probabilitatea eta mutazioaren magnitudea.


\begin{ifalgorithm}[t]
\begin{ifpseudo}{Algoritmo Genetikoak}
\item \In\ \texttt{evaluate}, \texttt{select\_reproduction}, \texttt{select\_replacement}, \texttt{cross}, \texttt{mutate} eta \texttt{!stop\_criterion} operadoreak
\item \In\ \texttt{init\_pop} hasierako populazioa
\item \In\ \texttt{mut\_prob} mutazio probabilitatea
\item \Out\ \texttt{best\_sol}
\item \texttt{pop=init\_pop}
\item \While \texttt{stop\_criterion} \Do
\item \T{\texttt{evaluate(pop)}}
\item \T{\texttt{ind\_rep = select\_reproduction(pop)}}
\item \T{\texttt{new\_ind = reproduce(ind\_rep)}}
\item \T{\textbf{for} \textbf{each} \texttt{n} in \texttt{new\_ind} \Do}
\item \TT{\texttt{mut\_prob} probabilitatearekin egin \texttt{mutate(n)}}
\item \T{\Done}
\item \T{\texttt{evaluate(new\_ind)}}
\item \T{\If \texttt{new\_ind} multzoan \texttt{best\_ind} baino hobea den soluziorik badago}
\item \TT{Eguneratu \texttt{best\_sol}}
\item \T{\EIf}
\item \T{\texttt{pop=select\_replacement(pop,new\_ind)}}
\item \Done
\end{ifpseudo}
\caption{Algoritmo genetikoen sasikodea}\label{alg:algoritmo_genetikoak}
\end{ifalgorithm}

Algoritmo genetiko orokorra \ref{alg:algoritmo_genetikoak} irudian ikus daiteke. Algoritmoan dagoen sasikodea \code{basic.genetic.algorithm} funtzioan inplementaturik dago. Ikus dezagun nola erabil daitekeen funtzio hau \eng{graph coloring} problema bat ebazteko. Lehenik, ausazko grafo bat sortuko dugu problemaren instantzia sortzeko.

<<ga_graph_col_1 , prompt=TRUE, message=FALSE , echo=-2 , warning=FALSE, cache=TRUE>>=
library(igraph)
set.seed(5)
n <- 50
rnd.graph <- aging.ba.game(n = n , pa.exp = 2 , 
                           aging.exp = 0, m = 3 , directed = F)
gcp <- graph.coloring.problem (graph = rnd.graph)
@

Orain zenbait elementu definitu behar ditugu. Lehenengoa, hasierako populazioa izango da. Populazioa sortzeko bere tamaina ezarri behar dugu. Hau algoritmoaren parametro garrantzitsu bat denez, bi balio erabiliko ditugu, emaitzak alderatzeko: $n$ eta $10n$. Soluzioak ausaz sortuko ditugu eta, gero, bideragarriak ez badira, zuzenduko ditugu.

<<ga_graph_col_2 , prompt=TRUE, message=FALSE , warning=FALSE, cache=TRUE>>=
n.pop.small <- n
n.pop.big <- 10*n
levels <- paste("C" , 1:n , sep = "")
rnd.sol <- function(x){
  sol <- factor(paste("C" , sample(1:n , size = n , replace = TRUE) , 
                      sep = "") , levels = levels)
  return(gcp$correct(sol))
}
pop.small <- lapply(1:n.pop.small , FUN = rnd.sol)
pop.big   <- lapply(1:n.pop.big , FUN = rnd.sol)
@

Hasierako populazioaz gain, ondoko parametro hauek ezarri behar ditugu:

\begin{itemize}
\item Hautespen operadoreak - Hurrengo belaunaldira pasatuko diren soluzioak aukeratzeko hautespen elitista erabiliko dugu, populazio erdia aukeratuz; zein soluzio gurutzatuko diren aukeratzeko, berriz, lehiaketa hautespena erabiliko dugu.
\item Mutazioa - Soluzioak mutatzeko \code{factor.mutation} soluzio erabiliko dugu. Funtzio honek zenbait posizio ausaz aukeratzen ditu eta bere balioak ausaz aldatzen ditu. Funtzioak parametro bat du, \code{ratio}, zeinek aldatuko diren posizioen ratioa adierazten duen. Gure kasuan 0.1 balioa erabiliko dugu, alegia, \%10 posizio aldatuko dira mutazioa aplikatzen denean. Zein probabilitatearekin mutatuko ditugun soluzioak ere finkatu behar da, \code{mutation.rate} parametroaren bidez; gure kasuan probabilitatea bat zati populazioaren tamaina izango da.
\item Gurutzaketa - Soluzioak gurutzatzeko \eng{k point crossover} erabiliko, $k = 2$ finkatuz. 
\item Beste parametro batzuk - Algoritmo genetikoaren parametroaz gain, beste bi parametro finaktuko ditugu, \code{non.valid = 'discard'}, bideraezina diren soluzioak baztertu behar direla adierazteko, eta \code{resources}, gelditze irizpidea finkatzeko ($5n^2$ ebaluazio kopuru maximoa erabiliko dugu).
\end{itemize}

\begin{figure}[t]
\subfigure[Algoritmo genetikoaren progresioa]{
\includegraphics[width=0.65\textwidth] {./Irudiak/ga_graph_col_3-1}
}\qquad
\subfigure[Lortutako soluzioa]{
\includegraphics[width=0.30\textwidth] {./Irudiak/ga_graph_col_4-1}
}\\
\caption{Algoritmo genetikoaren progresioa \eng{graph coloring} problema batean, bi poulazio tamaina ezberdin erabiliz. Ezkerrean, populazio tamaina handiarekin lortutako soluzioa ikus daiteke.}\label{fig:ga_progress}
\end{figure}

Jarraian parametro hauek erabiliz algoritmo genetikoa exekutatzeko kodea dago.


<<ga_graph_col_3, prompt=TRUE, cache=TRUE, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
args <- list()
args$evaluate             <- gcp$evaluate
args$initial.population   <- pop.small
args$select.subpopulation <- elitist.selection
args$selection.ratio      <- 0.5
args$select.cross         <- tournament.selection
args$mutate               <- factor.mutation
args$ratio                <- 0.1
args$mutation.rate        <- 1 / length(args$initial.population)
args$cross                <- k.point.crossover
args$k                    <- 2
args$non.valid            <- 'discard'
args$resources            <- cresource(evaluations = 5*n^2)

bga.small <- do.call(basic.genetic.algorithm , args)

args$initial.population   <- pop.big
args$mutation.rate        <- 1 / length(args$initial.population)

bga.big <- do.call(basic.genetic.algorithm , args)
plot.progress(list("Big population" = bga.big , "Small population" = bga.small) , 
              size = 1.1) + labs(y = "Average fitness") + aes(linetype = Group)
@


<<ga_graph_col_4, prompt=TRUE, cache=TRUE , echo = FALSE , message=FALSE , warning=FALSE  , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=5 , fig.height=5>>=
best.big <- unlist(optima(bga.big)[[1]])
gcp$plot(best.big,node.size=15,label.cex=0.75)
@


\ref{fig:ga_progress} irduian bi populazio erabiliz bilaketaren progresioa ikus daiteke. Populazioa txikia denean algoritmoak oso azkar konbergitzen du 19 kolore darabiltzan soluzio batera. Populazioko soluzio gehienak oso antzerakoak direnean soluzio berriak sortzeko bide bakarra mutazioa da, baina prozesu hori oso motela denez, grafikan ikus daiteke soluzioen bataz besteko \eng{fitness}a ez dela aldatzen. 

Populazioaren tamaina handitzen dugunean konbergentzia zailagoa da eta grafikan ikus daiteke helbur funtzioaren balioaren eboluzioa motelagoa izan arren, lortutako soluzioa hobea dela.

\begin{figure}[t]
\centering
\includegraphics[width=0.75\textwidth] {./Irudiak/ga_mut_rate-1}
\caption{Mutazioaren probabilitatearen eragina algoritmo genetikoaren emaitzan. Irudian ikus daitekeen bezala, soluziorik onenak ematen duen balioa 0.5 inguruan dagoena da (zehazki, 0.6). }\label{fig:ga_mutrate}
\end{figure}

Populazioaren tamaina ez ezik, beste hainbat parametro eragin handia izan dezakete algoritmoaren emaitzan; esate baterako, mutazioaren probabilitatea. Adibide gisa, popluazio tamaina txikia erabiliz mutazio probabilitate ezberdinak erabiliko ditugu, eta, ondoren, bakoitzarekin lortutako emaitzak alderatuko ditugu.

<<ga_mut_rate, prompt=TRUE, cache=TRUE, echo=-1, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
set.seed(10)
args$initial.population   <- pop.small
args$verbose              <- FALSE
args$resources            <- cresource(evaluations = n^2)

test.mutprob <- function (rate){
  args$mutation.rate        <- rate
  res <- do.call(basic.genetic.algorithm , args)
  evaluation(res)
}

ratios <- seq(0,1,0.2)
evaluations <- sapply(ratios , FUN = test.mutprob)

df <- data.frame("Mutation_rate" = ratios , "Fitness" = evaluations)
ggplot(df , aes(x=Mutation_rate , y = Fitness)) + geom_line() + geom_point(size = 5) + 
  labs(x = "Mutation rate")
@


\ref{fig:ga_mutrate} irudian konparaketaren emaitzak ikus daitezke. Grafikoan agerian dago probabilitate txikiegiak zein handiegiak kaltegarriak direla bilaketarako; izan ere, probabilitate egokiena 0.5 ingurukoa da. Edonola ere, kontutan hartu behar da probabilitate txikien kasuan emaitzak txarrak direla konbergentzia goiztiarra dugulak baina, probabilitate handiekin berrriz, arazoa justo kontrakoa izan daiteke, alegia, jarri dugun muga dela eta populazioa konbergitzen duela. Hau egiaztatzeko, errepika dezakezu goiko experimentua ebaluazio kopuru maximoa handituz.

\subsection{Estimation of Distribution Algorithms}

Algoritmo genetikoetan uneko populazioa indibiduo berriak sortzeko erabiltzen da. Prozesu honetan, naturan inspiratutako operadoreen bidez burutzen dena, populazioan dauden ezaugarriak mantentzea espero dugu. Edonola ere, prozesua korapilatsua izan daiteke. Hori dela eta, zenbait ikertzaile ideia hau hartu eta ikuspen matematikotik birformulatu zuten; gurutzatze-operadoreak eta mutazioa erabili beharrean, eredu probabilistikoak erabiltzea proposatu zuten, populazioaren \hgl{esentzia} kapturatzeko helburuarekin. Hauxe da, EDA -- \eng{Estimation of Distribution Algorithms} -- algoritmotan erabiltzen den ideia.

Algoritmo genetikoen eta EDA motako algoritmoen artean dagoen diferentzia bakarra indibiduo berriak sortzean dago. Gurutzatzea eta mutazioa erabili beharrean, uneko populazioa eredu probabilistiko bat \hgl{ikasteko} erabiltzen da. Ondoren, eredu hori laginduko dugu nahi ditugun indibiduo adina sortzeko.

EDA algoritmoen gakoa, beraz, eredu probabilistikoa da. Ildo honetan, esan beharra dago eredua soluzioen kodeketari lotuta dagoela, soluzio adierazpide bakoitzari probabilitate bat esleitu beharko diolako. 

Konplexutasun ezberdineko eredu probabilistikoen erabilera proposatu da literaturan, baina badago hurbilketa sinple bat oso hedatua dagoena: UMDA -- \eng{Univariate Marginal Distribution Algorithm} --. Kasu honetan soluzioaren osagaiak -- bektore bat bada, bere posizioak -- independenteak direla suposatuko dugu eta, hortaz, osagai bakoitzari dagokion probabilitate marjinala estimatu beharko dugu. Gero, indibiduoak sortzean osagaiak banan-banan aukeratuko ditugu probabilitate hauek kontutan hartuz. 

Probabilitate marjinalak maneiatzeko \code{metaheuR} paketeko \code{UnivariateMarginals} objektua erabil dezakegu. Bere erabilera ikusteko, populazio txiki bat sortuko dugu eta probabilitate marginalak kalkulatuko ditugu. 

<<UMDA_1, cache=TRUE , echo=-1 , prompt=TRUE, message=FALSE , warning=FALSE>>=
set.seed(1)
population <- lapply(1:5 , FUN = function(x) factor(sample(1:3 , 10 , replace = TRUE) ,
                                                    levels = 1:3))
@

Orain, \code{univariateMarginals} funtzioa erabiliz probabilitate marginalak kalkulatuko ditugu:

<<UMDA_2, cache=TRUE, prompt=TRUE, message=FALSE , warning=FALSE>>=
model <- univariateMarginals(data = population)

do.call(rbind , population)
model@prob.table
@

Sortutako soluzioek 10 elementu dituzte eta populazioak 5 soluzio ditu. Lehenengo elementuari erreparatzen badiogu, 5 soluzioetatik lehenengo biak 1 balioa, laugarrenak 2 balioa eta beste biak 3 balioa dute. Hortaz, elementu horretarako 1 eta 3 balioen probabilitatea 0.4 izango da --$\frac{2}{5}$, alegia-- eta 2 balioaren probabilitatea 0.2 izango da, marginaleen taulan ikus daitekeen bezala.

Ikasitako eredu probabilistikoa soluzio berriak sortzeko erabil daiteke, posizioz posizio balioak dagokion marginala laginduz; laginketa \code{simulate} funtzioaren bitartez egiten da.

<<UMDA_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
simulate(model , nsim = 2)
@

UMDA erabiliz aurreko ataleko problema ebatz dezakgu. Horretarako, bakarrik hautespen operadoreak eta ereduak ikasteko funtzioak zehaztu behar ditugu --betiko parametroz gain--.

<<umda_gc, echo = -1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
set.seed(2)
args <- list()
args$evaluate             <- gcp$evaluate
args$initial.population   <- pop.small
args$select.subpopulation <- elitist.selection
args$selection.ratio      <- 0.5
args$learn                <- univariateMarginals
args$non.valid            <- 'discard'
args$resources            <- cresource(evaluations = n^2)

umda <- do.call(basic.eda , args)

plot.progress(umda , size = 1.1) + 
  geom_line(aes(y = Current_sol + Current_sd) , col = "gray40" , linetype = 2) +
  geom_line(aes(y = Current_sol - Current_sd)  , col = "gray40" , linetype = 2) + 
  labs(y = "Average fitness")
@

\begin{figure}[t]
\centering
\includegraphics[width=0.75\textwidth] {./Irudiak/umda_gc-1}
\caption{UMDA algoritmoaren progresioa \eng{graph coloring} adibidean. Marra jarraituak populazioko soluzioen bataz-besteko \eng{fitness}a adierazten du; marra etenek, berriz, desbiderazio estandarra adierazten dute. Ikus daiteke populazioak konbergitzen duen heinean soluzioen \eng{fitness}aren bariabilidadea txikiagotzen dela.}\label{fig:umda}
\end{figure}

Bilaketaren progresioa \ref{fig:umda} irudian erakusten da. Marra etenek populazioan dauden soluzioen \eng{fitness}aren desbiderazioa erakusten dute. Eboluzioak aurrera egiten duen heinean, populazioaren dibertsitatea murrizten da eta hau desbiderazioaren txikiagotzean islatzen da; bilaketak 11 kolore darabiltzan soluzio batera konbergitzen du.

Marjinalak zuzenean edozein bektoreekin erabil daitezke; alabaina, balio errealak baditugu, marjinalak zein probabilitate distribuzioarekin modelatuko ditugun erabaki beharko dugu --distribuzio normala, adibidez--. Dena dela, soluzioek murrizketak dituztenean gauzak konplika daitezke; honen adibidea permutazioak dira. 

Permutazio multzo bat badugu, posible da marjinalak estimatzea, baina eredua lagintzen dugunean ez ditugu permutazioak lortuko, balio errepikatuak ager baitaitezke. Hona hemen adibide bat:

<<UMDA_permu_1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
n <- 5
perm.pop <- lapply (1:50 , FUN = function(x) factor(as.numeric(random.permutation(n)) , 
                                                    levels = 1:n))
perm.umda <- univariateMarginals(perm.pop)
simulate(perm.umda)
@

Arazo hau sahiesteko, soluzio berriak lagintzean permutazioetan ditugun murrizketak aintzat hartu behar dira. Beraz, laginketa prozesuan lehenengo elementua ausaz aukeratuko dugu, marjinala erabiliz. 

<<UMDA_permu_2, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=-1>>=
set.seed(10)
marginals <- perm.umda@prob.table
remaining <- 1:n
probabilities <- marginals[,1]
new.element <- sample(remaining , size = 1 , prob = probabilities)
new.solution <- new.element
@

Orain, bigarren elementua aukeratu aurretik, lehenengo posizioan egongo den elementua kendu behar dugu aukeretatik eta marjinalak eguneratu behar ditugu --erabili dugun elementuaren probabilitatea kendu eta normalizatu, gelditzen diren elementuen probabilitateen batura 1 izan dezan--:

<<UMDA_permu_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id , ]
probabilities <- marginals[ , 2]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining , size = 1 , prob = probabilities)
new.solution <- c(new.solution , new.element)
@

Prozesua 3. eta 4. elementuak erauzteko errepika dezakegu.

<<UMDA_permu_4, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id , ]
probabilities <- marginals[ , 3]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining , size = 1 , prob = probabilities)
new.solution <- c(new.solution , new.element)

id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id , ]
probabilities <- marginals[ , 3]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining , size = 1 , prob = probabilities)
new.solution <- c(new.solution , new.element)
@

Amaitzeko, permutazioaren azken elementua gelditzen den elementu bakarra izango da.

<<UMDA_permu_5, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
new.solution <- c(new.solution , remaining)
new.solution
@

Prozesu honi esker probabilitate marjinalak erabil daitezke permutazioak sortzeko, baina arazo bat dauka; eredua lagintzen dugun bakoitzean probabilitateak aldatzen ditugu eta, hortaz, lagintzen duguna ez da populaziotik ikasi duguna. Beste era batean esanda, populaziotik ateratako \hgl{esentzia} gal genezake. Hau ez gertatzeko, permutazio espazioetan definitutako probabilitate distribuzioak erabil ditzakegu; esate baterako, Mallows eredua, \code{metaheuR} paketean dagoen \code{MallowsModel} objektuak inplementatzen duena.


\section{Swarm Intelligence}\label{sec:swarm}

Eboluzioaren bidez naturak indibiduen diseinuak \hgl{optimizatzeko} gai da; alabaina, hau ez da naturak erabiltzen duen estrategia bakarra. Optimizazio algoritmoak inspiratu dituen beste adibidea bat animalia sozialena da. Zenbait espezietan --intsektuak, batik bat-- banan-banan hartuta, indibiduoak oso izaki sinpleak dira baina, multzoka, ataza konplexuak burutzeko gai dira. Esate baterako, inurriek eta erleek elikagai-iturri onenak aukeratzeko gai dira eta, hauek agortzen direnean, ingurunea esploratzen duten indibiduen kopurua handi dezakete iturri berriak lortzeko; era berean, bizitzeko toki berriak bilatzean toki egokienak aukeratzeko gai dira.

Erabaki guzti horiek ez dira era zentralizatuan hartzen --alegia, ez dago \hgl{nagusi} bat agintzen dunea--. Portaera hauek indibiduoen portaera sinpleen eta, batez ere, indibiduoen arteko komunikazioari esker agertzen dira. Beste era batean esanda, mekanismo sinplei esker kolonia batean dauden indibiduoak autoantolatzen dira.

Portaera hauek dira \eng{swarm intelligence} deritzon arloaren inspirazioa. Kontzpetua lehenengo aldiz robotika arloan proposatu zen \cite{beni1988}, baina laister optimizazio mundura hedatu zen. Izan ere, 90. hamarkadan inurri kolonien optimizazioa --\eng{Ant Colony Optimization}, ingelesez-- proposatu zen \cite{dorigo1992, dorigo1996}.

Hurrengo bi ataletan arlo honetan dauden bi algoritmo ezagunenak aztertuko ditugu, inurri kolonien optimizazioa eta \eng{particle swarm optimization}.



\subsection{\eng{Ant Colony Optimization}}

Inurriek, janaria topatzen dutenean, beraien koloniatik janarira biderik motzena topatzeko gaitasuna dute. Inurri bakar batek ezin du horrelakorik egin baina, taldeka, komunikazio mekanismo sinpleei esker ataza burutzeko gai dira. Erabiltzen den komunikabidea zeharkakoa da, darien molekula mota berezi bati esker: feromonak. Inurriek mugitzen direnean beste inurriek jarrai dezaketen feromona-lorratz bat uzten dute; geroz eta feromona gehiago, orduan eta probabilitate handiagoa datozen inurriak utzitako lorratza jarraitzeko. 

\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{./Irudiak/ants}
\caption{Feromonaren erabilera. Hasierako egoeran biderik motzena feromonaren bidez markatuta dago. Bidea mozten dugunean, inurriek, eskumara edo ezkerrera joango dira, probabilitate berdinarekin, feromonarik ez baitago ez ezkerrean ez eskuinean. Eskumako bidea luzeagoa da eta, ondorioz, ezkerreko bidearekiko inurri-fluxua txikiagoa da. Denbora igaro ahala, eskumako lorratza ahulduko da; ezkerrekoa, berriz, indartuko da. Honek inurrien erabakia baldintzatuko du, ezkerretik joateko joera handiago sortuz eta, ondorioz, bi bideen arteko diferentziak handituz. Denbora nahiko igarotzen denean eskumako lorratza guztiz galduko da eta inurriak bide motzetik bakarrik joango dira.}
\label{fig:ants}
\end{figure}


Bestaldetik, inurri batek elikagai-iturri bat topatzen duenean, bidetik uzten duen feromona kopurua iturriaren kalitateari egokitzen du; geroz eta kalitate handiagoa, orduan eta feromona gehiago. Sistemaren funtzionamendua ulertzeko kontutan hartu behar dugu feromonak molekula lurrunkorrak direla, hots, denborarekin utzitako lorratzak galtzen direla.

Arau sinple hauek erabiliz inurriek elikagai-iturri onenak aukeratzeko gai dira; are gehiago, elikagai eta inurritegiaren arteko biderik motzena topa dezakete. Mekanismoaren funtzionamendua \ref{fig:ants} irudian ikus daiteke. Hasieran bide motzena feromona lorratzaren bidez markatuta dute inurriek. Bidea mozten badugu, eskuman eta ezkerrean ez dago feromonarik eta, hortaz, inurri batzuk eskumatik eta beste batzuk ezkerretik joango dira, probabilitate berdinarekin. Ezkerreko bidea motzagoa denez, denbora berdinean inurri gehiago igaroko dira, ezkerreko bidean feromona gehiago utziz. Ondorioz, datozen inurriak ezkerretik joateko joera handiago izango dute, bide hori indartuz. Eskumako bidean lorratza apurka-apurka baporatuko da eta, denbora nahiko igarotzen bada, zeharo galduko da.

\eng{Ant Colony Optimization} (ACO) deritzon metaheuristika inurrien mekanismoa hartzen du intuiziotzat. Bere ingurunetik pasiatu beharrean, inurri artifizialak soluzio \hgl{sortzaileak} dira. Beraz, inurri artifizialek soluzioak sortuko dituzte, baina ez edonolakoak; soluzioak aurreko inurriek utzitako lorratzak jarraituz eraikitzen dira. 

Lorratzak feromona ereduen bidez adierazten dira eta bi eratan eguneratzen dira. Alde batetik, inurriek sortutako soluzioen kalitatea --hots, helburu funtzioaren balioa-- feromona gehitzeko erabiltzen da. Bestaldetik, iterazioz iterazio feromona kopuruak txikituko ditugu, molekularen baporazioa simulatuz.

Beraz, bi gauza behar dira ACO algoritmo bat diseinatzeko: feromona eredu bat eta soluzioak sortzeko algoritmo bat. Diseinu sinpleena osagaietan oinarritzen den algoritmo eraikitzaile bat erabiltzea da. Ikus dezagun hau adibide baten bidez.

Demagun MIS problema bat ebatzi nahi dugula. Problema honetarako soluzioak bektore bitarren bidez kodetzen ditugu eta, hortaz, bektorearen posizioak soluzioen osagaitzat har ditzakegu. Posizio bakoitzen bi balio posible daude, 0 edo 1. Inurri batek soluzio bat sortu behar duenenan, lehenik, bektorearen lehenengo posizioko balioa, 0 edo 1, aukeratu beharko du. Horretarako, feromona kopurua hartuko du aintzat, probabilitate handiago esleituz feromona gehiago duen balioari; behin lehenengo posizioko balioa finkaturik, bigarren posiziora pasatuko da eta, era antzerakoan, balio bat esleituko dio. Prozesua soluzio osoa sortu arte errepikatuko da.

Beraz, gure adibidean feromona eredua matrize sinple baten bidez inplementa daiteke non zutabe bakoitzean bektorearen posizio bat izango dugun; matrizeak bi errenkada bakarrik izango ditu, posizio bakoitzeko 0 eta 1 balioek duten feromona kopurua gordetzeko. Feromona eredu mota hau \code{metaheuR} paketean inplementaturik dago, \code{VectorPheromone} klasean. Ereduaren erabilera argitzeko \eng{Maximum Dominating Set} (MDS) problema erabiliko dugu. Laburki, grafo bat emanda, nodoen azpimultzo bat menderatze-multzoa da --\eng{dominating set}, ingelesez-- baldin eta azpimulzoan ez dauden nodo guztiak gutxienez azpimultzoko nodo bati konektatuta badaude; MDS probleman, grafo bat emanik, kardinalitate minimoko menderatze-multzoa topatzean datza. \ref{fig:MDS} irudian problema honetarako hiru soluzio ikus daitezke.


\begin{figure}[t]
\subfigure[Soluzio hau ez da menderatze-multzoa]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_not}
}\qquad
\subfigure[4 tamainako menderatze-multzoa]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_4}
}\qquad
\subfigure[2 tamainako menderatze-multzoa]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_2}
}\\
\caption{Irudiak MDS problemarako 3 soluzio jasotzen ditu --beltzez adierazita dauden nodoak--. Lehenengoa (ezkerrean dagoena), ez da bideragarria, soluzioan dagoen nodo bat soluzioan dauden nodoei konektaturik ez baitago. Bigarren soluzioa bideragarria da, baina ez optimoa. Azken soluzioa optimoa da, ez baitago 1 tamainako soluzio bideragarririk.}\label{fig:MDS}
\end{figure}


<<ACO_MDS_1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=-1>>=
set.seed(666)
n <- 10
rnd.graph <- aging.ba.game (n , 0.5 , 0 , 2 , directed = FALSE)
mdsp <- mds.problem(graph = rnd.graph)
@

Feromona eredua sortzeko matrizea hasieratu behar dugu. Ohikoena balio finko batekin hasieratzea da. Era honetan osagai guztiak balio berdina dute eta, beraz, guztien probabilitatea berdina izango da. Gogoratu gure adibidean matrizeak bi errenkada izan behar dituela, soluzioak bektore bitarrak baitira.

<<ACO_MDS_2, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
init.trail <- matrix (rep(1 , 2*n) , ncol = n)
evaporation <- 0.9
pheromones <- vectorPheromone(binary = TRUE , initial.trail = init.trail , 
                              evaporation.factor = evaporation)
pheromones@trail
@

Goiko kodean ikus daitekeen bezala, badago beste parametro bat finkatu behar dena, \code{evaporation.fractor}. Parametro horretan pasatzen den balioa lurrunketa faseetan erabiltzen da, matrizean dauden balio guztiak txikiagotzeko; baporazioa \code{evaporate} funtzioa erabiliz egiten da.

<<ACO_MDS_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
evaporate(pheromones)
pheromones@trail
evaporate(pheromones)
pheromones@trail
@

Esan dugun bezala, inurriek feromona ereduak soluzioak eraikitzeko erabiltzen dute. Soluzioak \code{build.solution} funtzioaren bitartez egiten da.

<<ACO_MDS_4, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
build.solution(pheromones , 1)
@

Inurriek ingurunetik ibiltzen diren heinean feromona uzten dute eta, era berean, inurri artifizialek soluzioak eraikitzen dutenean feromona kopurua handitzen dute; ereduaren eguneraketa hau \code{update.trail} funtzioa erabiliz egiten da.

<<ACO_MDS_5, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
solution <- build.solution(pheromones , 1)[[1]]
eval <- mdsp$evaluate(solution)
eval
update.trail(object = pheromones , solution = solution , value = eval)
pheromones@trail
@

Ikus daitekeen bezala, zutabe bakoitzean errenkada bati soluzioaren helburu funtzioaren balioa gehitu zaio, hori baita inurriek utzitako lorratza. Elementu guzti hauek batzen baditugu, ACO sinple bat sor dezakegu. Lehenik, problema berri bat sortuko dugu.

<<ACO_MDS_6, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo = -1>>=
set.seed(1)
n <- 100
rnd.graph <- aging.ba.game (n , 0.5 , 0 , 3 , directed = FALSE)
mdsp <- mds.problem(graph = rnd.graph)
init.trail <- matrix (rep(1 , 2*n) , ncol = n)
pheromones <- vectorPheromone(binary = TRUE , initial.trail = init.trail , 
                              evaporation.factor = evaporation)
@

Orain, 500 inurri simulatuko ditugu; bakoitzak soluzio bat sortuko du eta \hgl{bidetik} feromona utziko du. Inurri bakoitza simulatu ondoren feromona \hgl{lurrundu} egiten dugu.

<<ACO_MDS_7, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
num.ant <- 500
sol.evaluations <- vector()
for (ant in 1:num.ant){
  solution <- mdsp$correct(build.solution(pheromones , 1)[[1]])
  eval <- mdsp$evaluate(solution)
  update.trail(pheromones , solution , eval)
  evaporate(pheromones)
  sol.evaluations <- c(sol.evaluations , eval)
}
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_MDS_8-1}
\caption{ACO sinplearen eboluzioa MDS problema batean.}\label{fig:simple_aco}
\end{figure}

<<ACO_MDS_8, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
plot(sol.evaluations , type="l" , xlab="Number of Artificial Ants" , ylab = "Solution evaluation")
@

\ref{fig:simple_aco} irudiak algoritmoaren eboluzioa erakusten du. Irudian ikus daiteke hasieran oso bariabilidade handia dagoela sortutako soluzioen helburu funtzioaren balioan. Alabaina, inurri kopurua handitzen den heinean bariabilidadea murrizten da eta, amaieran, prozedura soluzio bakar batera konbergitzen du. Edonola ere, soluzio hori ez da hasierakoak baino hobea. Kontua da, nahiz eta naturan horrela izan, optimizazioaren ikuspegitik inurri guztiek feromona eredua eguneratzea ez dela hurbilketarik onena; algoritmoa hobetzeko hautespen prozesu bat sartzea komenigarria da.

Ikusi dugun algoritmo sinpleak ez du ondo funtzionatzen, inurri guztiek feromona eguneratzen dutelako. Hori dela eta, beste estrategia erabili ohi da. Inurriak banan-banan simulatu ordez, inurri-kolonia tamaina bat definitzen da eta iterazio bakoitzean inurritegiko inurri guztiek soluzio bat sortzen dute. Gero, bi estrategia ezberdin erabil daitezke:

\begin{itemize}
\item Iterazioko soluziorik onena erabili - Inurriek uneko iterazioan sortutako soluzioen artean onena aukeratzen da eta soluzio hori bakarrik erabiltzen da feromona eredua eguneratzeko. Kasu honetan helburu funtzioaren arabera egitea ez da beharrezkoa, bakarrik soluziorik onena erabiltzen baita eguneraketan. Hori dela eta, ohikoa da balio finko bat erabiltzea eguneraketan.
\item Bilaketan topatutako soluziorik onena - Hainbat kasutan bilaketa areagotzea interesatuko zaigu. Kasu horietan, feromonaren eguneraketa bilaketan zehar topatu den soluziorik onena erabiliz egin daiteke. Aurreko puntuan bezala, eguneraketak ez dauka zergatik izan helburu funtzioaren balioarekiko proportzionala.
\end{itemize}


\begin{ifalgorithm}[t]
\begin{ifpseudo}{Inurri-kolonien algoritmoa}
\item \In\ \texttt{build\_solution}, \texttt{evaporate}, \texttt{add\_pheromone }, \texttt{initalize\_matrix} eta \texttt{stop\_criterion} operadoreak
\item \In\ \texttt{k\_size} koloniaren tamaina
\item \Out\ \texttt{opt\_solution}
\item \texttt{pheromone\_matrix} = \texttt{initialize\_matrix()}
\item \While !\texttt{stop\_criterion()}
\item \T{\textbf{for} \texttt{i} \textbf{in} 1:\texttt{k\_size}}
\item \TT{\texttt{solution} = \texttt{build\_solution(pheromone\_matrix)}}
\item \TT{\texttt{pheromone\_matrix} = \texttt{add\_pheromone(pheromone\_matrix,solution)}}
\item \TT{\If \texttt{solution} \texttt{opt\_solution} baino hobea da}
\item \TTT{\texttt{opt\_solution}=\texttt{solution}}
\item \TT{\EIf}
\item \T{\Done}
\item \T{\texttt{pheromone\_matrix} = \texttt{evaporate(pheromone\_matrix)}}
\item \Done
\end{ifpseudo}
\caption{Inurri-kolonien algoritmoaren sasikodea}\label{alg:ant}
\end{ifalgorithm}


Aldaketa honekin oinarrizko ACO algoritmoaren sasikodea defini dezakegu (ikusi \ref{alg:ant} algoritmoa). \code{basic.aco} funtzioak Oinarrizko ACO-a inplementatzen du eta, hortaz, goiko problema ebazteko erabil dezakegu. Ohiko parametroaz gain, argumentu hauek zehaztu behar dira.

\begin{itemize}
\item \code{nants} - Zenbat inurri artifizial izango ditugu gure kolonian
\item \code{pheromones} - Feromona eredua.
\item \code{update.sol} - Nola eguneratuko dugu feromona eredua. Hiru aukera daude: \code{'best.it'}, iterazio bakoitzean sortutako soluziorik onena; \code{'best.all'}, bilaketan zehar lortutako soluziorik onena edo \code{'all'}, sortutako soluzio guztiak.
\item \code{update.value} - Balio bat finkatzen bada, eguneraketa guztietan balio hori gehitzen da; \code{NULL} bada, helburu funtzioa erabiltzen da. Kontutan hartu problema batzuetan helburu funtzioak negatiboak direla, baina feromona eredu batzuetan balio positiboak eta negatiboak ezin dira nahastu, bestela arazoak egon daitezke probabilitateak kalkulatzean. Hori dela eta, helburu funtzioaren zeinua kontutan hartu behar da feromona eredua hasieratzeko.
\end{itemize}

<<ACO_MDS_10, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(17)
args <- list()
args$evaluate         <- mdsp$evaluate
args$nants            <- 5
init.value            <- 1
initial.trail <- matrix(rep(init.value , 2*n ) , nrow=2)
evapor <- 0.9
pher <- vectorPheromone(binary = TRUE , initial.trail = initial.trail , 
                        evaporation.factor = evapor)
args$pheromones       <- pher
args$update.sol       <- 'best.it'
args$update.value     <- init.value / 10
args$non.valid        <- 'correct'
args$valid            <- mdsp$is.valid
args$correct          <- mdsp$correct

args$resources        <- cresource(iterations = 100)
args$verbose          <- FALSE

results.aco <- do.call(basic.aco , args)
plot.progress(results.aco) + labs(y="Average evaluation")
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_MDS_10-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa MDS problema batean.}\label{fig:basic_aco}
\end{figure}

\ref{fig:basic_aco} irudiak oinarrizko ACO algoritmoaren progresioa jasotzen du. Algoritmo honek soluzio kopuru berdina sortu du, baina aurrekoa ez bezala, iterazioz iterazio soluzioa hobetuz doa. Grafikoan batazbesteko \eng{fitness}-ak bariabilidade handia duela ikus daiteke. Hau da oso kolonia txikia erabili dugulako --5 inurri bakarrik--. Balio hori handitzen badugu, prograsioa ez da hain zaratatsua izango --eta, ziurrenik, emaitzak hobeak izango dira--, baina ebaluazio gehiago beharko ditugu.

ACO algoritmoen mamia soluzio eraikuntza da eta, hortaz, soluzioen osagaien definizioa oso garrantzitsua da; osagaiek problemaren natura kontutan hartzen ez badute, feromona ereduak ez du soluzioen informazioa behar den bezala jasoko. Hau agerian gelditzen da jarraian dagoen adibidean.

Demagun LOP problema bat ebazteko ACO algoritmo bat erabili nahi dugula. Problema honetarako soluzioak permutazioen bidez kodetzen ditugunez, adierazpide honekin diharduen feromona eredu bat behar dugu. Soluzioen eraikuntzan permutazioak sortzeko behar diren aldaketak eginez gero, bektoreekin erabilitako eredua permutazioekin ere erabil dezakegu. Hau da, matrize karratu bat gordeko dugu non posizio bakoitzeko, balio bakoitzari dagokion feromona kopurua gordeko dugu. Gero, soluzioak osatzerakoan, urrats bakoitzean aukeraturik gabe dauden balioetatik bat aukertuko dugu, aukera guztien arteko feromona kopurua kontutan hartuz. Eredu honek UMDA-n ikusi genuen oso matrize antzerakoa erabiltzen du. 

Dena dela, hau ez da aukera bakarra. TSP probleman ikusi genuen permutazioek grafo osoko ziklo Hamiltoniarrak adierazten dituztela. Hau da, $n$ nodoko grafo oso bat badugu, edozein permutazio $n$ nodoak behin eta bakarrik behi bisitatzen dituen ibilbide bat adierazten du. Beraz, permutazioak osatzeko nodoak lotzen dituzten ertzak erabil ditzakegu.

Ideia hau erabiliz beste feromona eredu bat plantea dezakegu. Eredu honek ere matrize karratu bat erabiliko du, baina matrizearen interpretazioa --eta, hortaz, soluzio osaketa-- ezbedina da. Kasu honetan, matrizeak grafoaren ertzak adierazten ditu, alegia, $(i,j)$ posizioan $i$ nodotik $j$ nodora joateari lotutako feromona kopurua izango dugu. Adibidez, 3421 permutazioa badugu, soluzio honi dagozkion matrizeko posizioak dira $(3,4); (4,2)$ eta $(2,1)$ --problemaren arabera, $(1,3)$ posizioa ere erabiltzea komenigarria izan daiteke--.

Bi eredu hauek \code{metaheuR} librutegian inplementaturik daude, \code{PermuPosPheromone} eta  \code{PermuLinkPheromone} objektuetan. Jarraian, bi eredu hauek LOP problema bat ebazteko erabiliko dugu eta emaitzak alderatuko ditugu.

<<ACO_LOP, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(1)
n <- 100
rnd.mat <- matrix(round(runif(n^2)*100) , n)
lop <- lop.problem(matrix = rnd.mat)

args <- list()
args$evaluate         <- lop$evaluate
args$nants            <- 15
init.value            <- 1
initial.trail         <- matrix(rep(init.value , n^2 ) , n)
evapor                <- 0.9
pher                  <- permuLinkPheromone(initial.trail = initial.trail , 
                                            evaporation.factor = evapor)
args$pheromones       <- pher
args$update.sol       <- 'best.it'
args$update.value     <- init.value / 10
args$resources        <- cresource(iterations = 250)
args$verbose          <- FALSE

aco.links <- do.call(basic.aco , args)

args$pheromones       <- permuPosPheromone(initial.trail , evapor)
aco.pos <- do.call(basic.aco , args)

plot.progress (list("Position" = aco.pos , "Link" = aco.links))
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_LOP-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa LOP problema batean.}\label{fig:aco_lop}
\end{figure}

\ref{fig:aco_lop} irudiak experimentuaren emaitza erakusten du. Grafikan argi ikus daiteke noden arteko lotruak osagaitzat hartzen direnean, bilaketak ez du aurrera egiten. Osagaiak posizioak direnean, berriz, iterazioz iterazio soluzioa hobetzen da. Honen arrazoia sinplea da: LOP probleman posizio absolutuak dira garrantzitsuena, eta ez zein elementu dagoen zeinen ondoan.

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_TSP-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa TSP problema batean.}\label{fig:aco_tsp}
\end{figure}

TSP probleman justo kontrakoa gertatzen da, hau da, informazio garrantzitsuena da zein hiri dagoen zeinen ondoan. Hori dela eta, printzipioz, ertzetan oinarritzen den feromona ereduak soluzio hobeak lortuko ditu. Jarrain experimentu hori egingo dugu; emaitzak \ref{fig:aco_tsp} irudian daude.


<<ACO_TSP, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(1)
url <- system.file("bays29.xml.zip" , package = "metaheuR")
cost.matrix <- tsplib.parser(url)
n <- ncol(cost.matrix)
tsp <- tsp.problem(cmatrix = cost.matrix)

args <- list()
args$evaluate         <- tsp$evaluate
args$nants            <- 15
init.value            <- 1
initial.trail         <- matrix(rep(init.value , n^2 ) , n)
evapor                <- 0.9
pher                  <- permuLinkPheromone(initial.trail = initial.trail , 
                                            evaporation.factor = evapor)
args$pheromones       <- pher
args$update.sol       <- 'best.it'
args$update.value     <- init.value / 10
args$resources        <- cresource(iterations = 250)
args$verbose          <- FALSE

aco.links <- do.call(basic.aco , args)

args$pheromones       <- permuPosPheromone(initial.trail , evapor)
aco.pos <- do.call(basic.aco , args)

plot.progress (list("Position" = aco.pos , "Link" = aco.links))
@

Orain arte ikusi ditugun adibide guztietan feromonak bakarrik erabiltzen dira soluzioak eraikitzerakoan. Oinarrizko algoritmoan horrela izan arren, problema konkretu bat ebatzi behar denean, posible bada, informazio heuristikoa sartu ohi da. Adibide gisa, TSPrako algoritmo eraikitzaile tipikoan hurrengo hiria hautatzeko hirien arteko distantzia erabiltzen da. Beraz, goiko adibidean hiri batetik bestera joateari dagokion feromona kopurua soilik erabili beharrean, bi hiri horien arteko distantzia ere kontutan har dezakegu.


\subsection{Particle Swarm Optimization}

Intsektu sozialen portaera \textit{swarm} adimenaren adibide tipikoak dira, baina ez dira bakarrak; animali handiagotan ere inspirazioa bila daiteke. Esate baterako, txori-saldotan ehunaka indibiduo batera mugitzen dira beraien arteak talka egin gabe. Multzo horietan ez dago indibiduo bat taldea kontrolatzen duena; txori bakoitzak bere inguruneko txorien portaera aztertzen du, berea egokitzeko. Era horretan, arau sinple batzuk (txori batetik gertuegi banago, urrundu egiten naiz, adibidez) besterik ez dira behar sistema osoa antolatzeko.

\begin{figure}[t]
\centering
\includegraphics[width=0.6\linewidth]{./Irudiak/PSO_1}
\caption{PSO algoritmoak erabiltzen dituen partikulen adibidea. Partikula bakoitzak bere kokapena $(x_i,y_i)$ eta bere abiadura ($\mathbf{v}_i$) du}\label{fig:PSO}
\end{figure}


Animali talde hauen portaera inspiraziotzat hartuz, 1995ean Kennedy eta Eberhart \textit{Particle Swarm Optimization} (PSO) algoritmoa proposatu zuten \cite{kennedy1995}, optimizazio numerikoko problemak ebazteko\footnote{Hau da, atal honetan ikusiko dugun algoritmoak bektore errealekin dihardu. Edonola ere, problema konbinatorialak ebazteko PSO bertsiak aurki daitezke.}. Algoritmoaren ideia sinplea da oso; bilaketa espaziotik mugitzen diren partikulak erabiltzen direa bilaketa egiteko. Beraz, algoritmoaren izenak adierazten duen legez, hainbat partikula izango ditugu; partikula bakoitzaren posizioak problemarako soluzio bat adieraziko du. 

Uneoro partikula bakoitzak kokapen eta abiadura zehatz bat izango du, \ref{fig:PSO} irudian erakusten den bezala. Irudiko adibidean bilaketa espazioak bi aldagai besterik ez ditu ($X$ eta $Y$), eta sisteman 5 partikula daude, $P_1$-etik $P_5$-era.

PSO algoritmoan partikulek bilaketa espazioa aztertzen dute, posizio batetik bestera mugituz. Beraz, iterazio bakoitzean partikula guztien kokapena eguneratzen da, beraien abiadura erabiliz. Partikulen abiadurak finko mantentzen baditugu, partikula guztiak infinitura joango dira. Hori ez gertatzeko, iterazio bakoitzean abiadura ere eguneratu behar da; eguneraketa honetan datza, hain zuzen, algoritmoaren gakoa. 

Lehen esan dugu algoritmoaren inspirazioa txori-maldoen portaera dela. Txori bakoitzak nora mugitu behar den erabakitzeko bere ingurunean dauden txoriei erreparetzen die. Era berean, algoritmoan partikula baten abiadura eguneratzean partikula horrek duen informazioa ez ezik, inguruneko partikulek duten informazioa ere erabiltzen da. Hain zuzen, $i$. partikularen abiadura eguneratzeko ondoko ekuazioa erabiltzen da:

\begin{align*}
\mathbf{v}_i(t) = \mathbf{v}_i(t-1) +  C_1 \mathbf{\rho}_1 [\mathbf{p}_i - \mathbf{x}_i(t-1)] + C_2 \mathbf{\rho}_2 [\mathbf{p}_g - \mathbf{x}_i(t-1)]
\end{align*}

Ekuazio honetan hiru termin daude:

\begin{itemize}
\item $\mathbf{v}_i(t-1)$ - Partikulak aurreko iterazioan zeukan abiadura; termino honek partikularen inertzia adirazten du.
\item $C_1 {\mathbf \rho_1} [\mathbf{p}_i - \mathbf{x}_i(t-1)]$ - Termino honetan $\mathbf{p}_i$-k partikulak bilaketa prozesuan topatu duen soluziorik onena adierazten du --ingelesez \eng{personal best} deritzona--. Termino honek zati \hgl{kognitiboa} adierazten du, hots, partikulak berak jasotako informazioa. $C_1$ terminoaren eragina definitzeko konstante bat da eta $\mathbf{\rho}_1$ soluzioaren tamainako ausazko bektore bat da.
\item $C_2 \mathbf{\rho}_2 [\mathbf{p}_g - \mathbf{x}_i(t-1)]$ - Termino honetan $\mathbf{p}_g$-k partikuluaren inguruan dauden partikulek bilaketa prozesuan topatu duten soluziorik onena adierazten du --ingelesez \eng{global best} deritzona--. Termino honek zati \hgl{soziala} adierazten du, hots, beste partikulek jasotako informazioa. $C_2$ terminoaren eragina definitzeko konstante bat da eta $\mathbf{\rho}_2$ soluzioaren tamainako ausazko bektore bat da.
\end{itemize}


Ekuazioaren azken terminoak partikulen arteko elkarekintzak simulatzen ditu. Horretarako, partikuelen ingurune-egitura definitu behar da. Alabaina, ingurune kontzeptua ez da bilaketa lokalean erabiltzen den berdina, partikula bakoitzaren ingurunea aurrez aurretik ezarritakoa baita; ez du partikularen kokapenarekin zerikusirik, alegia. Partikula bakoitzaren ingurunea grafo baten bidez adieraz daiteke, non bi partikula konektatuta dauden baldin eta bakarrik baldin bata bestearen ingurunean badaude. Lehenengo hurbilketa grafo osoa erabiltzea da, hots, edozein partikularen ingurunean beste gainontzeko partikula guztiak egongo dira; grafo osoa erabili beharrean, beste zenbait topologia ere erabil daitezke (eraztunak, izarrak, toroideak, etab.).

Goian dagoen ekuazioa erabiltzen bada, abiadurak dibergitzeko joera izango du, alegia, abiaduraren modulua gero eta handiagoa izango da. Arazo hau ekiditeko kalkulatutako abiadurari muga bat ezartzen zaio.

Behin uneko iterazioaren abiadura kalkulatuta, abiadura partikularen kokapena eguneratzeko erabiltzen da:

\begin{align*}
\mathbf{x}_i(t) = \mathbf{x}_i(t-1) + \mathbf{v}_i(t-1)
\end{align*}


\begin{ifalgorithm}[t]\label{alg:pso}
\begin{ifpseudo}{PSO algoritmoa}
\item \In\ \texttt{initialize\_position}, \texttt{initialize\_velocity}, \texttt{update\_velocity}, \texttt{evaluate} eta \texttt{stop\_criterion} operadoreak
\item \In\ \texttt{num\_particles} partikula kopurua
\item \Out\ \texttt{opt\_solution}
\item \texttt{gbest = p[1]}
\item \textbf{for each} \texttt{i} \textbf{in} \texttt{1:num\_particles} \Do
\item \T{\texttt{p[i]=initialize\_position(i)}}
\item \T{\texttt{v[i]=initialize\_velocity(i)}}
\item \T{\texttt{pbest[i]=p[i]}}
\item \T{\If \texttt{evaluate(p[i])<evaluate(gbest)}}
\item \TT{\texttt{gbest = p[i]}}
\item \T{\EIf}
\item \Done
\item \While !\texttt{stop\_criterion()} \Do
\item \T{\textbf{for each} \texttt{i} \textbf{in} \texttt{particle\_set}}
\item \T{\Do}
\item \TT{\texttt{v[i]} = update\_velocity(i)}
\item \TT{\texttt{p[i] = p[i] + v[i]}}
\item \TT{\If \texttt{evaluate(p[i])<evaluate(pbest[i])}}
\item \TTT{\texttt{pbest[i]}=\texttt{p[i]}}
\item \TT{\EIf}
\item \TT{\If \texttt{evaluate(p[i])<evaluate(gbest)}}
\item \TTT{\texttt{gbest}=\texttt{p[i]}}
\item \TT{\EIf}
\item \T{\Done}
\item \Done
\item \texttt{opt\_solution = gbest}
\end{ifpseudo}
\caption{\textit{Particle Swarm Optimization} algoritmoaren sasikodea}
\end{ifalgorithm}


Iterazio bakoitzean lortutako soluzioak ebaluatu eta, beharrezkoa bada, partikulen \eng{personal} ($\mathbf{p}_i$) eta \eng{global best} ($\mathbf{p}_g$) eguneratu behar dira. Pasu guzti hauek \ref{alg:pso} algoritmoan biltzen dira.


Algoritmo hau \code{metaheuR} paketeko \code{basic.pso} funtzioan inplementaturk dago. Erabilera erakusteko, optimizazio numerikoan \eng{benchmark} gisa erabiltzen den Rosenbrock funtzioa erabiliko dugu; problema sortzeko \code{rosenbrock.problem} funtzioa erabili behar dugu.


<<PSO_1, cache=TRUE , echo = -1 , prompt=TRUE, message=FALSE , warning=FALSE>>=
set.seed(1)
n <- 10
eval <- rosenbrock.problem(size = n)$evaluate
@

Algoritmoa aplikatzeko partikula kopurua, hasierako kokapenak eta abiadurak, abiadura maximoa, \eng{personal best} koefizientea eta \eng{global best} koefizientea ezarri behar ditugu:

<<PSO_2, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
nparticles <- 100
ipos <- lapply(1:nparticles , FUN = function (i) runif(n))
args <- list()
args$initial.positions  <- ipos 
args$initial.velocity   <- 0
args$max.velocity       <- 5
args$c.personal         <- 2
args$c.best             <- 4
@

Horrez gain, helburu funtzioa eta baliabide konputazionalak ere finaktu behar ditugu.

<<PSO_3, cache=TRUE , prompt=TRUE , echo = -1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=7 , fig.height=4>>=
args$verbose    <- FALSE
args$evaluate   <- eval
args$resources  <- cresource(time=10)

res.pso <- do.call(basic.pso , args)

plot.progress(res.pso , x = 'iterations' , y = 'best') + labs(y="Best Solution")
plot.progress(res.pso , x = 'iterations' ) + labs(y="Average Solution")
@

\ref{fig:Rosenbrock} irudiak bilaketaren progresioa erakusten du. Ezkereko grafikoan partikulen batazbesteko ebaluazioa erakusten da, iterazioz iterazio; eskubikoak, berriz, bilaketan zehar topatutako soluziorik onenaren \eng{fitness}-aren progresioa erakusten du. Beste algoritmoetan ez bezala, partikulen helburu funtzioaren balioek ez dute konbergitzen; hala eta gustiz ere, bilaketak aurrera egiten du eta, azkenean, optimotik oso hurbil gelditzen da --Rosenbrock funtzioaren balio minimoa 0 da--.


\begin{figure}[t]
\subfigure[Batazbesteko soluzioaren progresioa]{
\includegraphics[width=0.45\textwidth] {./Irudiak/PSO_3-2}
}\qquad
\subfigure[Soluzio onenaren progresioa]{
\includegraphics[width=0.45\textwidth] {./Irudiak/PSO_3-1}
}\\
\caption{PSO algoritmoaren progresioa Rosenbrock probleman}\label{fig:Rosenbrock}
\end{figure}


\bibliographystyle{plain}
\bibliography{references}

\end{document}